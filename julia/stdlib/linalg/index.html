
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Linear Algebra - Julia - W3cubDocs</title>
  
  <meta name="description" content=" Linear algebra functions in Julia are largely implemented by calling functions from LAPACK. Sparse factorizations call functions from SuiteSparse. ">
  <meta name="keywords" content="linear, algebra, -, julia">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/julia/stdlib/linalg/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/julia.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/julia/" class="_nav-link" title="" style="margin-left:0;">Julia</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx_simple">
				
<h1 id="stdlib-linalg">Linear Algebra</h1>  <h2 id="standard-functions">Standard Functions</h2> <p id="module-Base.LinAlg">Linear algebra functions in Julia are largely implemented by calling functions from <a class="reference external" href="http://www.netlib.org/lapack/" target="_blank">LAPACK</a>. Sparse factorizations call functions from <a class="reference external" href="http://faculty.cse.tamu.edu/davis/suitesparse.html" target="_blank">SuiteSparse</a>.</p> <dl class="function"> <dt id="Base.*">
<code>*(A, B)</code> </dt> <dd>
<p>Matrix multiplication.</p> </dd>
</dl> <dl class="function"> <dt id="Base.\">
<code>\(A, B)</code> </dt> <dd>
<p>Matrix division using a polyalgorithm. For input matrices <code>A</code> and <code>B</code>, the result <code>X</code> is such that <code>A*X == B</code> when <code>A</code> is square. The solver that is used depends upon the structure of <code>A</code>. If <code>A</code> is upper or lower triangular (or diagonal), no factorization of <code>A</code> is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used.</p> <p>For rectangular <code>A</code> the result is the minimum-norm least squares solution computed by a pivoted QR factorization of <code>A</code> and a rank estimate of <code>A</code> based on the R factor.</p> <p>When <code>A</code> is sparse, a similar polyalgorithm is used. For indefinite matrices, the <code>LDLt</code> factorization does not use pivoting during the numerical factorization and therefore the procedure can fail even for invertible matrices.</p> </dd>
</dl> <dl class="function"> <dt id="Base.dot">
<code>dot(x, y)</code> </dt> <dt id="Base.⋅">
<code>⋅(x, y)</code> </dt> <dd>
<p>Compute the dot product. For complex vectors, the first vector is conjugated.</p> </dd>
</dl> <dl class="function"> <dt id="Base.vecdot">
<code>vecdot(x, y)</code> </dt> <dd>
<p>For any iterable containers <code>x</code> and <code>y</code> (including arrays of any dimension) of numbers (or any element type for which <code>dot</code> is defined), compute the Euclidean dot product (the sum of <code>dot(x[i],y[i])</code>) as if they were vectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.cross">
<code>cross(x, y)</code> </dt> <dt id="Base.×">
<code>×(x, y)</code> </dt> <dd>
<p>Compute the cross product of two 3-vectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.factorize">
<code>factorize(A)</code> </dt> <dd>
<p>Compute a convenient factorization of <code>A</code>, based upon the type of the input matrix. <code>factorize</code> checks <code>A</code> to see if it is symmetric/triangular/etc. if <code>A</code> is passed as a generic matrix. <code>factorize</code> checks every element of <code>A</code> to verify/rule out each property. It will short-circuit as soon as it can rule out symmetry/triangular structure. The return value can be reused for efficient solving of multiple systems. For example: <code>A=factorize(A); x=A\b; y=A\C</code>.</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Properties of <code>A</code>
</th> <th class="head">type of factorization</th> </tr> </thead>  <tr class="row-even">
<td>Positive-definite</td> <td>Cholesky (see <a class="reference internal" href="#Base.cholfact" title="Base.cholfact"><code>cholfact()</code></a>)</td> </tr> <tr class="row-odd">
<td>Dense Symmetric/Hermitian</td> <td>Bunch-Kaufman (see <a class="reference internal" href="#Base.bkfact" title="Base.bkfact"><code>bkfact()</code></a>)</td> </tr> <tr class="row-even">
<td>Sparse Symmetric/Hermitian</td> <td>LDLt (see <a class="reference internal" href="#Base.ldltfact" title="Base.ldltfact"><code>ldltfact()</code></a>)</td> </tr> <tr class="row-odd">
<td>Triangular</td> <td>Triangular</td> </tr> <tr class="row-even">
<td>Diagonal</td> <td>Diagonal</td> </tr> <tr class="row-odd">
<td>Bidiagonal</td> <td>Bidiagonal</td> </tr> <tr class="row-even">
<td>Tridiagonal</td> <td>LU (see <a class="reference internal" href="#Base.lufact" title="Base.lufact"><code>lufact()</code></a>)</td> </tr> <tr class="row-odd">
<td>Symmetric real tridiagonal</td> <td>LDLt (see <a class="reference internal" href="#Base.ldltfact" title="Base.ldltfact"><code>ldltfact()</code></a>)</td> </tr> <tr class="row-even">
<td>General square</td> <td>LU (see <a class="reference internal" href="#Base.lufact" title="Base.lufact"><code>lufact()</code></a>)</td> </tr> <tr class="row-odd">
<td>General non-square</td> <td>QR (see <a class="reference internal" href="#Base.qrfact" title="Base.qrfact"><code>qrfact()</code></a>)</td> </tr>  </table> <p>If <code>factorize</code> is called on a Hermitian positive-definite matrix, for instance, then <code>factorize</code> will return a Cholesky factorization.</p> <p>Example:</p> <pre data-language="julia">A = diagm(rand(5)) + diagm(rand(4),1); #A is really bidiagonal
factorize(A) #factorize will check to see that A is already factorized
</pre> <p>This returns a <code>5×5 Bidiagonal{Float64}</code>, which can now be passed to other linear algebra functions (e.g. eigensolvers) which will use specialized methods for <code>Bidiagonal</code> types.</p> </dd>
</dl> <dl class="function"> <dt id="Base.full">
<code>full(F)</code> </dt> <dd>
<p>Reconstruct the matrix <code>A</code> from the factorization <code>F=factorize(A)</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Diagonal">
<code>Diagonal(A::AbstractMatrix)</code> </dt> <dd>
<p>Constructs a matrix from the diagonal of <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>Diagonal(V::AbstractVector)</code> </dt> <dd>
<p>Constructs a matrix with <code>V</code> as its diagonal.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Bidiagonal">
<code>Bidiagonal(dv, ev, isupper::Bool)</code> </dt> <dd>
<p>Constructs an upper (<code>isupper=true</code>) or lower (<code>isupper=false</code>) bidiagonal matrix using the given diagonal (<code>dv</code>) and off-diagonal (<code>ev</code>) vectors. The result is of type <code>Bidiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>. <code>ev</code>‘s length must be one less than the length of <code>dv</code>.</p> <p><strong>Example</strong></p> <pre data-language="julia">dv = rand(5)
ev = rand(4)
Bu = Bidiagonal(dv, ev, true) #e is on the first superdiagonal
Bl = Bidiagonal(dv, ev, false) #e is on the first subdiagonal
</pre> </dd>
</dl> <dl class="function"> <dt>
<code>Bidiagonal(dv, ev, uplo::Char)</code> </dt> <dd>
<p>Constructs an upper (<code>uplo='U'</code>) or lower (<code>uplo='L'</code>) bidiagonal matrix using the given diagonal (<code>dv</code>) and off-diagonal (<code>ev</code>) vectors. The result is of type <code>Bidiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>. <code>ev</code>‘s length must be one less than the length of <code>dv</code>.</p> <p><strong>Example</strong></p> <pre data-language="julia">dv = rand(5)
ev = rand(4)
Bu = Bidiagonal(dv, ev, 'U') #e is on the first superdiagonal
Bl = Bidiagonal(dv, ev, 'L') #e is on the first subdiagonal
</pre> </dd>
</dl> <dl class="function"> <dt>
<code>Bidiagonal(A, isupper::Bool)</code> </dt> <dd>
<p>Construct a <code>Bidiagonal</code> matrix from the main diagonal of <code>A</code> and its first super- (if <code>isupper=true</code>) or sub-diagonal (if <code>isupper=false</code>).</p> <p><strong>Example</strong></p> <pre data-language="julia">A = rand(5,5)
Bu = Bidiagonal(A, true) #contains the main diagonal and first superdiagonal of A
Bl = Bidiagonal(A, false) #contains the main diagonal and first subdiagonal of A
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.SymTridiagonal">
<code>SymTridiagonal(dv, ev)</code> </dt> <dd>
<p>Construct a symmetric tridiagonal matrix from the diagonal and first sub/super-diagonal, respectively. The result is of type <code>SymTridiagonal</code> and provides efficient specialized eigensolvers, but may be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Tridiagonal">
<code>Tridiagonal(dl, d, du)</code> </dt> <dd>
<p>Construct a tridiagonal matrix from the first subdiagonal, diagonal, and first superdiagonal, respectively. The result is of type <code>Tridiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>. The lengths of <code>dl</code> and <code>du</code> must be one less than the length of <code>d</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Symmetric">
<code>Symmetric(A, uplo=:U)</code> </dt> <dd>
<p>Construct a <code>Symmetric</code> matrix from the upper (if <code>uplo = :U</code>) or lower (if <code>uplo = :L</code>) triangle of <code>A</code>.</p> <p><strong>Example</strong></p> <pre data-language="julia">A = randn(10,10)
Supper = Symmetric(A)
Slower = Symmetric(A,:L)
eigfact(Supper)
</pre> <p><code>eigfact</code> will use a method specialized for matrices known to be symmetric. Note that <code>Supper</code> will not be equal to <code>Slower</code> unless <code>A</code> is itself symmetric (e.g. if <code>A == A.'</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.Hermitian">
<code>Hermitian(A, uplo=:U)</code> </dt> <dd>
<p>Construct a <code>Hermitian</code> matrix from the upper (if <code>uplo = :U</code>) or lower (if <code>uplo = :L</code>) triangle of <code>A</code>.</p> <p><strong>Example</strong></p> <pre data-language="julia">A = randn(10,10)
Hupper = Hermitian(A)
Hlower = Hermitian(A,:L)
eigfact(Hupper)
</pre> <p><code>eigfact</code> will use a method specialized for matrices known to be Hermitian. Note that <code>Hupper</code> will not be equal to <code>Hlower</code> unless <code>A</code> is itself Hermitian (e.g. if <code>A == A'</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.lu">
<code>lu(A) → L, U, p</code> </dt> <dd>
<p>Compute the LU factorization of <code>A</code>, such that <code>A[p,:] = L*U</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.lufact">
<code>lufact(A[, pivot=Val{true}]) → F::LU</code> </dt> <dd>
<p>Compute the LU factorization of <code>A</code>.</p> <p>In most cases, if <code>A</code> is a subtype <code>S</code> of <code>AbstractMatrix{T}</code> with an element type <code>T</code> supporting <code>+</code>, <code>-</code>, <code>*</code> and <code>/</code>, the return type is <code>LU{T,S{T}}</code>. If pivoting is chosen (default) the element type should also support <code>abs</code> and <code>&lt;</code>.</p> <p>The individual components of the factorization <code>F</code> can be accessed by indexing:</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Component</th> <th class="head">Description</th> </tr> </thead>  <tr class="row-even">
<td><code>F[:L]</code></td> <td>
<code>L</code> (lower triangular) part of <code>LU</code>
</td> </tr> <tr class="row-odd">
<td><code>F[:U]</code></td> <td>
<code>U</code> (upper triangular) part of <code>LU</code>
</td> </tr> <tr class="row-even">
<td><code>F[:p]</code></td> <td>(right) permutation <code>Vector</code>
</td> </tr> <tr class="row-odd">
<td><code>F[:P]</code></td> <td>(right) permutation <code>Matrix</code>
</td> </tr>  </table> <p>The relationship between <code>F</code> and <code>A</code> is</p> <p><code>F[:L]*F[:U] == A[F[:p], :]</code></p> <p><code>F</code> further supports the following functions:</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Supported function</th> <th class="head"><code>LU</code></th> <th class="head"><code>LU{T,Tridiagonal{T}}</code></th> </tr> </thead>  <tr class="row-even">
<td><a class="reference internal" href="../math/#Base./" title="Base./"><code>/()</code></a></td> <td>✓</td> <td> </td> </tr> <tr class="row-odd">
<td><a class="reference internal" href="#" title="Base.\"><code>\()</code></a></td> <td>✓</td> <td>✓</td> </tr> <tr class="row-even">
<td><a class="reference internal" href="#Base.cond" title="Base.cond"><code>cond()</code></a></td> <td>✓</td> <td> </td> </tr> <tr class="row-odd">
<td><a class="reference internal" href="#Base.det" title="Base.det"><code>det()</code></a></td> <td>✓</td> <td>✓</td> </tr> <tr class="row-even">
<td><a class="reference internal" href="#Base.logdet" title="Base.logdet"><code>logdet()</code></a></td> <td>✓</td> <td>✓</td> </tr> <tr class="row-odd">
<td><a class="reference internal" href="#Base.logabsdet" title="Base.logabsdet"><code>logabsdet()</code></a></td> <td>✓</td> <td>✓</td> </tr> <tr class="row-even">
<td><a class="reference internal" href="../arrays/#Base.size" title="Base.size"><code>size()</code></a></td> <td>✓</td> <td>✓</td> </tr>  </table> </dd>
</dl> <dl class="function"> <dt>
<code>lufact(A::SparseMatrixCSC) → F::UmfpackLU</code> </dt> <dd>
<p>Compute the LU factorization of a sparse matrix <code>A</code>.</p> <p>For sparse <code>A</code> with real or complex element type, the return type of <code>F</code> is <code>UmfpackLU{Tv, Ti}</code>, with <code>Tv</code> = <code>Float64</code> or <code>Complex128</code> respectively and <code>Ti</code> is an integer type (<code>Int32</code> or <code>Int64</code>).</p> <p>The individual components of the factorization <code>F</code> can be accessed by indexing:</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Component</th> <th class="head">Description</th> </tr> </thead>  <tr class="row-even">
<td><code>F[:L]</code></td> <td>
<code>L</code> (lower triangular) part of <code>LU</code>
</td> </tr> <tr class="row-odd">
<td><code>F[:U]</code></td> <td>
<code>U</code> (upper triangular) part of <code>LU</code>
</td> </tr> <tr class="row-even">
<td><code>F[:p]</code></td> <td>right permutation <code>Vector</code>
</td> </tr> <tr class="row-odd">
<td><code>F[:q]</code></td> <td>left permutation <code>Vector</code>
</td> </tr> <tr class="row-even">
<td><code>F[:Rs]</code></td> <td>
<code>Vector</code> of scaling factors</td> </tr> <tr class="row-odd">
<td><code>F[:(:)]</code></td> <td>
<code>(L,U,p,q,Rs)</code> components</td> </tr>  </table> <p>The relation between <code>F</code> and <code>A</code> is</p> <p><code>F[:L]*F[:U] == (F[:Rs] .* A)[F[:p], F[:q]]</code></p> <p><code>F</code> further supports the following functions:</p> <ul class="simple"> <li><a class="reference internal" href="#" title="Base.\"><code>\()</code></a></li> <li><a class="reference internal" href="#Base.cond" title="Base.cond"><code>cond()</code></a></li> <li><a class="reference internal" href="#Base.det" title="Base.det"><code>det()</code></a></li> </ul> <p>** Implementation note **</p> <p><code>lufact(A::SparseMatrixCSC)</code> uses the UMFPACK library that is part of SuiteSparse. As this library only supports sparse matrices with <code>Float64</code> or <code>Complex128</code> elements, <code>lufact</code> converts <code>A</code> into a copy that is of type <code>SparseMatrixCSC{Float64}</code> or <code>SparseMatrixCSC{Complex128}</code> as appropriate.</p> </dd>
</dl> <dl class="function"> <dt id="Base.lufact!">
<code>lufact!(A) → LU</code> </dt> <dd>
<p><code>lufact!</code> is the same as <a class="reference internal" href="#Base.lufact" title="Base.lufact"><code>lufact()</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <code>InexactError</code> exception is thrown if the factorisation produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p> </dd>
</dl> <dl class="function"> <dt id="Base.chol">
<code>chol(A) → U</code> </dt> <dd>
<p>Compute the Cholesky factorization of a positive definite matrix <code>A</code> and return the UpperTriangular matrix <code>U</code> such that <code>A = U'U</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>chol(x::Number) → y</code> </dt> <dd>
<p>Compute the square root of a non-negative number <code>x</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.cholfact">
<code>cholfact(A, [uplo::Symbol, ]Val{false}) → Cholesky</code> </dt> <dd>
<p>Compute the Cholesky factorization of a dense symmetric positive definite matrix <code>A</code> and return a <code>Cholesky</code> factorization. The matrix <code>A</code> can either be a <code>Symmetric</code> or <code>Hermitian</code> <code>StridedMatrix</code> or a <em>perfectly</em> symmetric or Hermitian <code>StridedMatrix</code>. In the latter case, the optional argument <code>uplo</code> may be <code>:L</code> for using the lower part or <code>:U</code> for the upper part of <code>A</code>. The default is to use <code>:U</code>. The triangular Cholesky factor can be obtained from the factorization <code>F</code> with: <code>F[:L]</code> and <code>F[:U]</code>. The following functions are available for <code>Cholesky</code> objects: <code>size</code>, <code>\</code>, <code>inv</code>, <code>det</code>. A <code>PosDefException</code> exception is thrown in case the matrix is not positive definite.</p> </dd>
</dl> <dl class="function"> <dt>
<code>cholfact(A, [uplo::Symbol, ]Val{true}; tol = 0.0) → CholeskyPivoted</code> </dt> <dd>
<p>Compute the pivoted Cholesky factorization of a dense symmetric positive semi-definite matrix <code>A</code> and return a <code>CholeskyPivoted</code> factorization. The matrix <code>A</code> can either be a <code>Symmetric</code> or <code>Hermitian</code> <code>StridedMatrix</code> or a <em>perfectly</em> symmetric or Hermitian <code>StridedMatrix</code>. In the latter case, the optional argument <code>uplo</code> may be <code>:L</code> for using the lower part or <code>:U</code> for the upper part of <code>A</code>. The default is to use <code>:U</code>. The triangular Cholesky factor can be obtained from the factorization <code>F</code> with: <code>F[:L]</code> and <code>F[:U]</code>. The following functions are available for <code>PivotedCholesky</code> objects: <code>size</code>, <code>\</code>, <code>inv</code>, <code>det</code>, and <code>rank</code>. The argument <code>tol</code> determines the tolerance for determining the rank. For negative values, the tolerance is the machine precision.</p> </dd>
</dl> <dl class="function"> <dt>
<code>cholfact(A; shift = 0.0, perm = Int[]) → CHOLMOD.Factor</code> </dt> <dd>
<p>Compute the Cholesky factorization of a sparse positive definite matrix <code>A</code>. <code>A</code> must be a <code>SparseMatrixCSC</code>, <code>Symmetric{SparseMatrixCSC}</code>, or <code>Hermitian{SparseMatrixCSC}</code>. Note that even if <code>A</code> doesn’t have the type tag, it must still be symmetric or Hermitian. A fill-reducing permutation is used. <code>F = cholfact(A)</code> is most frequently used to solve systems of equations with <code>F\b</code>, but also the methods <code>diag</code>, <code>det</code>, <code>logdet</code> are defined for <code>F</code>. You can also extract individual factors from <code>F</code>, using <code>F[:L]</code>. However, since pivoting is on by default, the factorization is internally represented as <code>A == P'*L*L'*P</code> with a permutation matrix <code>P</code>; using just <code>L</code> without accounting for <code>P</code> will give incorrect answers. To include the effects of permutation, it’s typically preferable to extact “combined” factors like <code>PtL = F[:PtL]</code> (the equivalent of <code>P'*L</code>) and <code>LtP = F[:UP]</code> (the equivalent of <code>L'*P</code>).</p> <p>Setting optional <code>shift</code> keyword argument computes the factorization of <code>A+shift*I</code> instead of <code>A</code>. If the <code>perm</code> argument is nonempty, it should be a permutation of <code>1:size(A,1)</code> giving the ordering to use (instead of CHOLMOD’s default AMD ordering).</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>This method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to <code>SparseMatrixCSC{Float64}</code> or <code>SparseMatrixCSC{Complex128}</code> as appropriate.</p> <p class="last">Many other functions from CHOLMOD are wrapped but not exported from the <code>Base.SparseArrays.CHOLMOD</code> module.</p> </div> </dd>
</dl> <dl class="function"> <dt id="Base.cholfact!">
<code>cholfact!(F::Factor, A; shift = 0.0) → CHOLMOD.Factor</code> </dt> <dd>
<p>Compute the Cholesky (<span class="math">\(LL'\)</span>) factorization of <code>A</code>, reusing the symbolic factorization <code>F</code>. <code>A</code> must be a <code>SparseMatrixCSC</code>, <code>Symmetric{SparseMatrixCSC}</code>, or <code>Hermitian{SparseMatrixCSC}</code>. Note that even if <code>A</code> doesn’t have the type tag, it must still be symmetric or Hermitian.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">This method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to <code>SparseMatrixCSC{Float64}</code> or <code>SparseMatrixCSC{Complex128}</code> as appropriate.</p> </div> </dd>
</dl> <dl class="function"> <dt>
<code>cholfact!(A, [uplo::Symbol, ]Val{false}) → Cholesky</code> </dt> <dd>
<p>The same as <code>cholfact</code>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <code>InexactError</code> exception is thrown if the factorisation produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p> </dd>
</dl> <dl class="function"> <dt>
<code>cholfact!(A, [uplo::Symbol, ]Val{true}; tol = 0.0) → CholeskyPivoted</code> </dt> <dd>
<p>The same as <code>cholfact</code>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <code>InexactError</code> exception is thrown if the factorisation produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.lowrankupdate">
<code>lowrankupdate(C::Cholesky, v::StridedVector) → CC::Cholesky</code> </dt> <dd>
<p>Update a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C[:U]'C[:U]</code> then <code>CC = cholfact(C[:U]'C[:U] + v*v')</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.lowrankdowndate">
<code>lowrankdowndate(C::Cholesky, v::StridedVector) → CC::Cholesky</code> </dt> <dd>
<p>Downdate a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C[:U]'C[:U]</code> then <code>CC = cholfact(C[:U]'C[:U] - v*v')</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.lowrankupdate!">
<code>lowrankupdate!(C::Cholesky, v::StridedVector) → CC::Cholesky</code> </dt> <dd>
<p>Update a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C[:U]'C[:U]</code> then <code>CC = cholfact(C[:U]'C[:U] + v*v')</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations. The input factorization <code>C</code> is updated in place such that on exit <code>C == CC</code>. The vector <code>v</code> is destroyed during the computation.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.lowrankdowndate!">
<code>lowrankdowndate!(C::Cholesky, v::StridedVector) → CC::Cholesky</code> </dt> <dd>
<p>Downdate a Cholesky factorization <code>C</code> with the vector <code>v</code>. If <code>A = C[:U]'C[:U]</code> then <code>CC = cholfact(C[:U]'C[:U] - v*v')</code> but the computation of <code>CC</code> only uses <code>O(n^2)</code> operations. The input factorization <code>C</code> is updated in place such that on exit <code>C == CC</code>. The vector <code>v</code> is destroyed during the computation.</p> </dd>
</dl> <dl class="function"> <dt id="Base.ldltfact">
<code>ldltfact(::SymTridiagonal) → LDLt</code> </dt> <dd>
<p>Compute an <code>LDLt</code> factorization of a real symmetric tridiagonal matrix such that <code>A = L*Diagonal(d)*L'</code> where <code>L</code> is a unit lower triangular matrix and <code>d</code> is a vector. The main use of an <code>LDLt</code> factorization <code>F = ldltfact(A)</code> is to solve the linear system of equations <code>Ax = b</code> with <code>F\b</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ldltfact(A; shift = 0.0, perm=Int[]) → CHOLMOD.Factor</code> </dt> <dd>
<p>Compute the <span class="math">\(LDL'\)</span> factorization of a sparse matrix <code>A</code>. <code>A</code> must be a <code>SparseMatrixCSC</code>, <code>Symmetric{SparseMatrixCSC}</code>, or <code>Hermitian{SparseMatrixCSC}</code>. Note that even if <code>A</code> doesn’t have the type tag, it must still be symmetric or Hermitian. A fill-reducing permutation is used. <code>F = ldltfact(A)</code> is most frequently used to solve systems of equations <code>A*x = b</code> with <code>F\b</code>. The returned factorization object <code>F</code> also supports the methods <code>diag</code>, <code>det</code>, and <code>logdet</code>. You can extract individual factors from <code>F</code> using <code>F[:L]</code>. However, since pivoting is on by default, the factorization is internally represented as <code>A == P'*L*D*L'*P</code> with a permutation matrix <code>P</code>; using just <code>L</code> without accounting for <code>P</code> will give incorrect answers. To include the effects of permutation, it is typically preferable to extact “combined” factors like <code>PtL = F[:PtL]</code> (the equivalent of <code>P'*L</code>) and <code>LtP = F[:UP]</code> (the equivalent of <code>L'*P</code>). The complete list of supported factors is <code>:L, :PtL, :D, :UP, :U, :LD, :DU, :PtLD, :DUP</code>.</p> <p>Setting optional <code>shift</code> keyword argument computes the factorization of <code>A+shift*I</code> instead of <code>A</code>. If the <code>perm</code> argument is nonempty, it should be a permutation of <code>1:size(A,1)</code> giving the ordering to use (instead of CHOLMOD’s default AMD ordering).</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>This method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to <code>SparseMatrixCSC{Float64}</code> or <code>SparseMatrixCSC{Complex128}</code> as appropriate.</p> <p class="last">Many other functions from CHOLMOD are wrapped but not exported from the <code>Base.SparseArrays.CHOLMOD</code> module.</p> </div> </dd>
</dl> <dl class="function"> <dt id="Base.ldltfact!">
<code>ldltfact!(F::Factor, A; shift = 0.0) → CHOLMOD.Factor</code> </dt> <dd>
<p>Compute the <span class="math">\(LDL'\)</span> factorization of <code>A</code>, reusing the symbolic factorization <code>F</code>. <code>A</code> must be a <code>SparseMatrixCSC</code>, <code>Symmetric{SparseMatrixCSC}</code>, or <code>Hermitian{SparseMatrixCSC}</code>. Note that even if <code>A</code> doesn’t have the type tag, it must still be symmetric or Hermitian.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">This method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to <code>SparseMatrixCSC{Float64}</code> or <code>SparseMatrixCSC{Complex128}</code> as appropriate.</p> </div> </dd>
</dl> <dl class="function"> <dt>
<code>ldltfact!(::SymTridiagonal) → LDLt</code> </dt> <dd>
<p>Same as <code>ldltfact</code>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p> </dd>
</dl> <dl class="function"> <dt id="Base.qr">
<code>qr(v::AbstractVector)</code> </dt> <dd>
<p>Computes the polar decomposition of a vector.</p> <p>Input:</p> <ul class="simple"> <li>
<code>v::AbstractVector</code> - vector to normalize</li> </ul> <p>Outputs:</p> <ul class="simple"> <li>
<code>w</code> - A unit vector in the direction of <code>v</code>
</li> <li>
<code>r</code> - The norm of <code>v</code>
</li> </ul> <p>See also:</p> <p><code>normalize</code>, <code>normalize!</code>, <code>LinAlg.qr!</code></p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.qr!">
<code>LinAlg.qr!(v::AbstractVector)</code> </dt> <dd>
<p>Computes the polar decomposition of a vector. Instead of returning a new vector as <code>qr(v::AbstractVector)</code>, this function mutates the input vector <code>v</code> in place.</p> <p>Input:</p> <ul class="simple"> <li>
<code>v::AbstractVector</code> - vector to normalize</li> </ul> <p>Outputs:</p> <ul class="simple"> <li>
<code>w</code> - A unit vector in the direction of <code>v</code> (This is a mutation of <code>v</code>).</li> <li>
<code>r</code> - The norm of <code>v</code>
</li> </ul> <p>See also:</p> <p><code>normalize</code>, <code>normalize!</code>, <code>qr</code></p> </dd>
</dl> <dl class="function"> <dt>
<code>qr(A[, pivot=Val{false}][;thin=true]) → Q, R, [p]</code> </dt> <dd>
<p>Compute the (pivoted) QR factorization of <code>A</code> such that either <code>A = Q*R</code> or <code>A[:,p] = Q*R</code>. Also see <code>qrfact</code>. The default is to compute a thin factorization. Note that <code>R</code> is not extended with zeros when the full <code>Q</code> is requested.</p> </dd>
</dl> <dl class="function"> <dt id="Base.qrfact">
<code>qrfact(A[, pivot=Val{false}]) → F</code> </dt> <dd>
<p>Computes the QR factorization of <code>A</code>. The return type of <code>F</code> depends on the element type of <code>A</code> and whether pivoting is specified (with <code>pivot==Val{true}</code>).</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Return type</th> <th class="head"><code>eltype(A)</code></th> <th class="head"><code>pivot</code></th> <th class="head">Relationship between <code>F</code> and <code>A</code>
</th> </tr> </thead>  <tr class="row-even">
<td><code>QR</code></td> <td>not <code>BlasFloat</code>
</td> <td>either</td> <td><code>A==F[:Q]*F[:R]</code></td> </tr> <tr class="row-odd">
<td><code>QRCompactWY</code></td> <td><code>BlasFloat</code></td> <td><code>Val{false}</code></td> <td><code>A==F[:Q]*F[:R]</code></td> </tr> <tr class="row-even">
<td><code>QRPivoted</code></td> <td><code>BlasFloat</code></td> <td><code>Val{true}</code></td> <td><code>A[:,F[:p]]==F[:Q]*F[:R]</code></td> </tr>  </table> <p><code>BlasFloat</code> refers to any of: <code>Float32</code>, <code>Float64</code>, <code>Complex64</code> or <code>Complex128</code>.</p> <p>The individual components of the factorization <code>F</code> can be accessed by indexing:</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Component</th> <th class="head">Description</th> <th class="head"><code>QR</code></th> <th class="head"><code>QRCompactWY</code></th> <th class="head"><code>QRPivoted</code></th> </tr> </thead>  <tr class="row-even">
<td><code>F[:Q]</code></td> <td>
<code>Q</code> (orthogonal/unitary) part of <code>QR</code>
</td> <td>✓ (<code>QRPackedQ</code>)</td> <td>✓ (<code>QRCompactWYQ</code>)</td> <td>✓ (<code>QRPackedQ</code>)</td> </tr> <tr class="row-odd">
<td><code>F[:R]</code></td> <td>
<code>R</code> (upper right triangular) part of <code>QR</code>
</td> <td>✓</td> <td>✓</td> <td>✓</td> </tr> <tr class="row-even">
<td><code>F[:p]</code></td> <td>pivot <code>Vector</code>
</td> <td> </td> <td> </td> <td>✓</td> </tr> <tr class="row-odd">
<td><code>F[:P]</code></td> <td>(pivot) permutation <code>Matrix</code>
</td> <td> </td> <td> </td> <td>✓</td> </tr>  </table> <p>The following functions are available for the <code>QR</code> objects: <code>size</code>, <code>\</code>. When <code>A</code> is rectangular, <code>\</code> will return a least squares solution and if the solution is not unique, the one with smallest norm is returned.</p> <p>Multiplication with respect to either thin or full <code>Q</code> is allowed, i.e. both <code>F[:Q]*F[:R]</code> and <code>F[:Q]*A</code> are supported. A <code>Q</code> matrix can be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a> which has a named argument <code>thin</code>.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p><code>qrfact</code> returns multiple types because LAPACK uses several representations that minimize the memory storage requirements of products of Householder elementary reflectors, so that the <code>Q</code> and <code>R</code> matrices can be stored compactly rather as two separate dense matrices.</p> <p>The data contained in <code>QR</code> or <code>QRPivoted</code> can be used to construct the <code>QRPackedQ</code> type, which is a compact representation of the rotation matrix:</p> <div class="math"> \[Q = \prod_{i=1}^{\min(m,n)} (I - \tau_i v_i v_i^T)\]</div> <p>where <span class="math">\(\tau_i\)</span> is the scale factor and <span class="math">\(v_i\)</span> is the projection vector associated with the <span class="math">\(i^{th}\)</span> Householder elementary reflector.</p> <p>The data contained in <code>QRCompactWY</code> can be used to construct the <code>QRCompactWYQ</code> type, which is a compact representation of the rotation matrix</p> <div class="math"> \[Q = I + Y T Y^T\]</div> <p>where <code>Y</code> is <span class="math">\(m \times r\)</span> lower trapezoidal and <code>T</code> is <span class="math">\(r \times r\)</span> upper triangular. The <em>compact WY</em> representation <a class="reference internal" href="#schreiber1989" id="id1">[Schreiber1989]</a> is not to be confused with the older, <em>WY</em> representation <a class="reference internal" href="#bischof1987" id="id2">[Bischof1987]</a>. (The LAPACK documentation uses <code>V</code> in lieu of <code>Y</code>.)</p> <table class="docutils citation" frame="void" id="bischof1987" rules="none">   <tr>
<td class="label">[Bischof1987]</td>
<td>
<em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>)</em> C Bischof and C Van Loan, “The WY representation for products of Householder matrices”, SIAM J Sci Stat Comput 8 (1987), s2-s13. <a class="reference external" href="http://dx.doi.org/10.1137/0908009" target="_blank">doi:10.1137/0908009</a>
</td>
</tr>  </table> <table class="last docutils citation" frame="void" id="schreiber1989" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id1">[Schreiber1989]</a></td>
<td>R Schreiber and C Van Loan, “A storage-efficient WY representation for products of Householder transformations”, SIAM J Sci Stat Comput 10 (1989), 53-57. <a class="reference external" href="http://dx.doi.org/10.1137/0910005" target="_blank">doi:10.1137/0910005</a>
</td>
</tr>  </table> </div> </dd>
</dl> <dl class="function"> <dt>
<code>qrfact(A) → SPQR.Factorization</code> </dt> <dd>
<p>Compute the QR factorization of a sparse matrix <code>A</code>. A fill-reducing permutation is used. The main application of this type is to solve least squares problems with <code>\</code>. The function calls the C library SPQR and a few additional functions from the library are wrapped but not exported.</p> </dd>
</dl> <dl class="function"> <dt id="Base.qrfact!">
<code>qrfact!(A[, pivot=Val{false}])</code> </dt> <dd>
<p><code>qrfact!</code> is the same as <a class="reference internal" href="#Base.qrfact" title="Base.qrfact"><code>qrfact()</code></a> when <code>A</code> is a subtype of <code>StridedMatrix</code>, but saves space by overwriting the input <code>A</code>, instead of creating a copy. An <code>InexactError</code> exception is thrown if the factorisation produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p> </dd>
</dl> <dl class="function"> <dt>
<code>full(QRCompactWYQ[, thin=true]) → Matrix</code> </dt> <dd>
<p>Converts an orthogonal or unitary matrix stored as a <code>QRCompactWYQ</code> object, i.e. in the compact WY format <a class="reference internal" href="#bischof1987" id="id3">[Bischof1987]</a>, to a dense matrix.</p> <p>Optionally takes a <code>thin</code> Boolean argument, which if <code>true</code> omits the columns that span the rows of <code>R</code> in the QR factorization that are zero. The resulting matrix is the <code>Q</code> in a thin QR factorization (sometimes called the reduced QR factorization). If <code>false</code>, returns a <code>Q</code> that spans all rows of <code>R</code> in its corresponding QR factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.lqfact!">
<code>lqfact!(A) → LQ</code> </dt> <dd>
<p>Compute the LQ factorization of <code>A</code>, using the input matrix as a workspace. See also <a class="reference internal" href="#Base.lq" title="Base.lq"><code>lq()</code></a>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.lqfact">
<code>lqfact(A) → LQ</code> </dt> <dd>
<p>Compute the LQ factorization of <code>A</code>. See also <a class="reference internal" href="#Base.lq" title="Base.lq"><code>lq()</code></a>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.lq">
<code>lq(A; [thin=true]) → L, Q</code> </dt> <dd>
<p>Perform an LQ factorization of <code>A</code> such that <code>A = L*Q</code>. The default is to compute a thin factorization. The LQ factorization is the QR factorization of <code>A.'</code>. <code>L</code> is not extended with zeros if the full <code>Q</code> is requested.</p> </dd>
</dl> <dl class="function"> <dt id="Base.bkfact">
<code>bkfact(A) → BunchKaufman</code> </dt> <dd>
<p>Compute the Bunch-Kaufman <a class="reference internal" href="#bunch1977" id="id4">[Bunch1977]</a> factorization of a real symmetric or complex Hermitian matrix <code>A</code> and return a <code>BunchKaufman</code> object. The following functions are available for <code>BunchKaufman</code> objects: <code>size</code>, <code>\</code>, <code>inv</code>, <code>issymmetric</code>, <code>ishermitian</code>.</p> <table class="docutils citation" frame="void" id="bunch1977" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id4">[Bunch1977]</a></td>
<td>J R Bunch and L Kaufman, Some stable methods for calculating inertia and solving symmetric linear systems, Mathematics of Computation 31:137 (1977), 163-179. <a class="reference external" href="http://www.ams.org/journals/mcom/1977-31-137/S0025-5718-1977-0428694-0" target="_blank">url</a>.</td>
</tr>  </table> </dd>
</dl> <dl class="function"> <dt id="Base.bkfact!">
<code>bkfact!(A) → BunchKaufman</code> </dt> <dd>
<p><code>bkfact!</code> is the same as <a class="reference internal" href="#Base.bkfact" title="Base.bkfact"><code>bkfact()</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p> </dd>
</dl> <dl class="function"> <dt id="Base.eig">
<code>eig(A,[irange,][vl,][vu,][permute=true,][scale=true]) → D, V</code> </dt> <dd>
<p>Computes eigenvalues (<code>D</code>) and eigenvectors (<code>V</code>) of <code>A</code>. See <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a> for details on the <code>irange</code>, <code>vl</code>, and <code>vu</code> arguments and the <code>permute</code> and <code>scale</code> keyword arguments. The eigenvectors are returned columnwise.</p> <pre data-language="julia">julia&gt; eig([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])
([1.0,3.0,18.0],
[1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0])
</pre> <p><code>eig</code> is a wrapper around <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>, extracting all parts of the factorization to a tuple; where possible, using <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a> is recommended.</p> </dd>
</dl> <dl class="function"> <dt>
<code>eig(A, B) → D, V</code> </dt> <dd>
<p>Computes generalized eigenvalues (<code>D</code>) and vectors (<code>V</code>) of <code>A</code> with respect to <code>B</code>.</p> <p><code>eig</code> is a wrapper around <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>, extracting all parts of the factorization to a tuple; where possible, using <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a> is recommended.</p> <pre data-language="julia">julia&gt; A = [1 0; 0 -1]
2×2 Array{Int64,2}:
 1   0
 0  -1

julia&gt; B = [0 1; 1 0]
2×2 Array{Int64,2}:
 0  1
 1  0

julia&gt; eig(A, B)
(Complex{Float64}[0.0+1.0im,0.0-1.0im],
Complex{Float64}[0.0-1.0im 0.0+1.0im; -1.0-0.0im -1.0+0.0im])
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.eigvals">
<code>eigvals(A,[irange,][vl,][vu]) → values</code> </dt> <dd>
<p>Returns the eigenvalues of <code>A</code>. If <code>A</code> is <code>Symmetric</code>, <code>Hermitian</code> or <code>SymTridiagonal</code>, it is possible to calculate only a subset of the eigenvalues by specifying either a <code>UnitRange</code> <code>irange</code> covering indices of the sorted eigenvalues, or a pair <code>vl</code> and <code>vu</code> for the lower and upper boundaries of the eigenvalues.</p> <p>For general non-symmetric matrices it is possible to specify how the matrix is balanced before the eigenvector calculation. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns moreequal in norm. The default is <code>true</code> for both options.</p> </dd>
</dl> <dl class="function"> <dt id="Base.eigvals!">
<code>eigvals!(A,[irange,][vl,][vu]) → values</code> </dt> <dd>
<p>Same as <a class="reference internal" href="#Base.eigvals" title="Base.eigvals"><code>eigvals()</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p> </dd>
</dl> <dl class="function"> <dt id="Base.eigmax">
<code>eigmax(A; permute::Bool=true, scale::Bool=true)</code> </dt> <dd>
<p>Returns the largest eigenvalue of <code>A</code>. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of <code>A</code> are complex, this method will fail, since complex numbers cannot be sorted.</p> <pre data-language="julia">julia&gt; A = [0 im; -im 0]
2×2 Array{Complex{Int64},2}:
 0+0im  0+1im
 0-1im  0+0im

julia&gt; eigmax(A)
1.0

julia&gt; A = [0 im; -1 0]
2×2 Array{Complex{Int64},2}:
  0+0im  0+1im
 -1+0im  0+0im

julia&gt; eigmax(A)
ERROR: DomainError:
 in #eigmax#30(::Bool, ::Bool, ::Function, ::Array{Complex{Int64},2}) at ./linalg/eigen.jl:186
 in eigmax(::Array{Complex{Int64},2}) at ./linalg/eigen.jl:184
 ...
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.eigmin">
<code>eigmin(A; permute::Bool=true, scale::Bool=true)</code> </dt> <dd>
<p>Returns the smallest eigenvalue of <code>A</code>. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of <code>A</code> are complex, this method will fail, since complex numbers cannot be sorted.</p> <pre data-language="julia">julia&gt; A = [0 im; -im 0]
2×2 Array{Complex{Int64},2}:
 0+0im  0+1im
 0-1im  0+0im

julia&gt; eigmin(A)
-1.0

julia&gt; A = [0 im; -1 0]
2×2 Array{Complex{Int64},2}:
  0+0im  0+1im
 -1+0im  0+0im

julia&gt; eigmin(A)
ERROR: DomainError:
 in #eigmin#31(::Bool, ::Bool, ::Function, ::Array{Complex{Int64},2}) at ./linalg/eigen.jl:226
 in eigmin(::Array{Complex{Int64},2}) at ./linalg/eigen.jl:224
 ...
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.eigvecs">
<code>eigvecs(A, [eigvals,][permute=true,][scale=true]) → Matrix</code> </dt> <dd>
<p>Returns a matrix <code>M</code> whose columns are the eigenvectors of <code>A</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>M[:, k]</code>.) The <code>permute</code> and <code>scale</code> keywords are the same as for <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>.</p> <p>For <a class="reference internal" href="#Base.SymTridiagonal" title="Base.SymTridiagonal"><code>SymTridiagonal</code></a> matrices, if the optional vector of eigenvalues <code>eigvals</code> is specified, returns the specific corresponding eigenvectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.eigfact">
<code>eigfact(A,[irange,][vl,][vu,][permute=true,][scale=true]) → Eigen</code> </dt> <dd>
<p>Computes the eigenvalue decomposition of <code>A</code>, returning an <code>Eigen</code> factorization object <code>F</code> which contains the eigenvalues in <code>F[:values]</code> and the eigenvectors in the columns of the matrix <code>F[:vectors]</code>. (The <code>k</code>th eigenvector can be obtained from the slice <code>F[:vectors][:, k]</code>.)</p> <p>The following functions are available for <code>Eigen</code> objects: <a class="reference internal" href="#Base.inv" title="Base.inv"><code>inv()</code></a>, <a class="reference internal" href="#Base.det" title="Base.det"><code>det()</code></a>, and <a class="reference internal" href="#Base.isposdef" title="Base.isposdef"><code>isposdef()</code></a>.</p> <p>If <code>A</code> is <a class="reference internal" href="#Base.Symmetric" title="Base.Symmetric"><code>Symmetric</code></a>, <a class="reference internal" href="#Base.Hermitian" title="Base.Hermitian"><code>Hermitian</code></a> or <a class="reference internal" href="#Base.SymTridiagonal" title="Base.SymTridiagonal"><code>SymTridiagonal</code></a>, it is possible to calculate only a subset of the eigenvalues by specifying either a <code>UnitRange</code> <code>irange</code> covering indices of the sorted eigenvalues or a pair <code>vl</code> and <code>vu</code> for the lower and upper boundaries of the eigenvalues.</p> <p>For general nonsymmetric matrices it is possible to specify how the matrix is balanced before the eigenvector calculation. The option <code>permute=true</code> permutes the matrix to become closer to upper triangular, and <code>scale=true</code> scales the matrix by its diagonal elements to make rows and columns more equal in norm. The default is <code>true</code> for both options.</p> </dd>
</dl> <dl class="function"> <dt>
<code>eigfact(A, B) → GeneralizedEigen</code> </dt> <dd>
<p>Computes the generalized eigenvalue decomposition of <code>A</code> and <code>B</code>, returning a <code>GeneralizedEigen</code> factorization object <code>F</code> which contains the generalized eigenvalues in <code>F[:values]</code> and the generalized eigenvectors in the columns of the matrix <code>F[:vectors]</code>. (The <code>k</code>th generalized eigenvector can be obtained from the slice <code>F[:vectors][:, k]</code>.)</p> </dd>
</dl> <dl class="function"> <dt id="Base.eigfact!">
<code>eigfact!(A[, B])</code> </dt> <dd>
<p>Same as <a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>, but saves space by overwriting the input <code>A</code> (and <code>B</code>), instead of creating a copy.</p> </dd>
</dl> <dl class="function"> <dt id="Base.hessfact">
<code>hessfact(A)</code> </dt> <dd>
<p>Compute the Hessenberg decomposition of <code>A</code> and return a <code>Hessenberg</code> object. If <code>F</code> is the factorization object, the unitary matrix can be accessed with <code>F[:Q]</code> and the Hessenberg matrix with <code>F[:H]</code>. When <code>Q</code> is extracted, the resulting type is the <code>HessenbergQ</code> object, and may be converted to a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.hessfact!">
<code>hessfact!(A)</code> </dt> <dd>
<p><code>hessfact!</code> is the same as <a class="reference internal" href="#Base.hessfact" title="Base.hessfact"><code>hessfact()</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p> </dd>
</dl> <dl class="function"> <dt id="Base.schurfact">
<code>schurfact(A::StridedMatrix) → F::Schur</code> </dt> <dd>
<p>Computes the Schur factorization of the matrix <code>A</code>. The (quasi) triangular Schur factor can be obtained from the <code>Schur</code> object <code>F</code> with either <code>F[:Schur]</code> or <code>F[:T]</code> and the orthogonal/unitary Schur vectors can be obtained with <code>F[:vectors]</code> or <code>F[:Z]</code> such that <code>A = F[:vectors]*F[:Schur]*F[:vectors]'</code>. The eigenvalues of <code>A</code> can be obtained with <code>F[:values]</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.schurfact!">
<code>schurfact!(A::StridedMatrix) → F::Schur</code> </dt> <dd>
<p>Same as <code>schurfact</code> but uses the input argument as workspace.</p> </dd>
</dl> <dl class="function"> <dt id="Base.schur">
<code>schur(A::StridedMatrix) → T::Matrix, Z::Matrix, λ::Vector</code> </dt> <dd>
<p>Computes the Schur factorization of the matrix <code>A</code>. The methods return the (quasi) triangular Schur factor <code>T</code> and the orthogonal/unitary Schur vectors <code>Z</code> such that <code>A = Z*T*Z'</code>. The eigenvalues of <code>A</code> are returned in the vector <code>λ</code>.</p> <p>See <code>schurfact</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.ordschur">
<code>ordschur(F::Schur, select::Union{Vector{Bool}, BitVector}) → F::Schur</code> </dt> <dd>
<p>Reorders the Schur factorization <code>F</code> of a matrix <code>A = Z*T*Z'</code> according to the logical array <code>select</code> returning the reordered factorization <code>F</code> object. The selected eigenvalues appear in the leading diagonal of <code>F[:Schur]</code> and the corresponding leading columns of <code>F[:vectors]</code> form an orthogonal/unitary basis of the corresponding right invariant subspace. In the real case, a complex conjugate pair of eigenvalues must be either both included or both excluded via <code>select</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.ordschur!">
<code>ordschur!(F::Schur, select::Union{Vector{Bool}, BitVector}) → F::Schur</code> </dt> <dd>
<p>Same as <code>ordschur</code> but overwrites the factorization <code>F</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur(T::StridedMatrix, Z::StridedMatrix, select::Union{Vector{Bool}, BitVector}) → T::StridedMatrix, Z::StridedMatrix, λ::Vector</code> </dt> <dd>
<p>Reorders the Schur factorization of a real matrix <code>A = Z*T*Z'</code> according to the logical array <code>select</code> returning the reordered matrices <code>T</code> and <code>Z</code> as well as the vector of eigenvalues <code>λ</code>. The selected eigenvalues appear in the leading diagonal of <code>T</code> and the corresponding leading columns of <code>Z</code> form an orthogonal/unitary basis of the corresponding right invariant subspace. In the real case, a complex conjugate pair of eigenvalues must be either both included or both excluded via <code>select</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur!(T::StridedMatrix, Z::StridedMatrix, select::Union{Vector{Bool}, BitVector}) → T::StridedMatrix, Z::StridedMatrix, λ::Vector</code> </dt> <dd>
<p>Same as <code>ordschur</code> but overwrites the input arguments.</p> </dd>
</dl> <dl class="function"> <dt>
<code>schurfact(A::StridedMatrix, B::StridedMatrix) → F::GeneralizedSchur</code> </dt> <dd>
<p>Computes the Generalized Schur (or QZ) factorization of the matrices <code>A</code> and <code>B</code>. The (quasi) triangular Schur factors can be obtained from the <code>Schur</code> object <code>F</code> with <code>F[:S]</code> and <code>F[:T]</code>, the left unitary/orthogonal Schur vectors can be obtained with <code>F[:left]</code> or <code>F[:Q]</code> and the right unitary/orthogonal Schur vectors can be obtained with <code>F[:right]</code> or <code>F[:Z]</code> such that <code>A=F[:left]*F[:S]*F[:right]'</code> and <code>B=F[:left]*F[:T]*F[:right]'</code>. The generalized eigenvalues of <code>A</code> and <code>B</code> can be obtained with <code>F[:alpha]./F[:beta]</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>schurfact!(A::StridedMatrix, B::StridedMatrix) → F::GeneralizedSchur</code> </dt> <dd>
<p>Same as <code>schurfact</code> but uses the input matrices <code>A</code> and <code>B</code> as workspace.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur(F::GeneralizedSchur, select::Union{Vector{Bool}, BitVector}) → F::GeneralizedSchur</code> </dt> <dd>
<p>Reorders the Generalized Schur factorization <code>F</code> of a matrix pair <code>(A, B) = (Q*S*Z', Q*T*Z')</code> according to the logical array <code>select</code> and returns a GeneralizedSchur object <code>F</code>. The selected eigenvalues appear in the leading diagonal of both <code>F[:S]</code> and <code>F[:T]</code>, and the left and right orthogonal/unitary Schur vectors are also reordered such that <code>(A, B) = F[:Q]*(F[:S], F[:T])*F[:Z]'</code> still holds and the generalized eigenvalues of <code>A</code> and <code>B</code> can still be obtained with <code>F[:alpha]./F[:beta]</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur!(F::GeneralizedSchur, select::Union{Vector{Bool}, BitVector}) → F::GeneralizedSchur</code> </dt> <dd>
<p>Same as <code>ordschur</code> but overwrites the factorization <code>F</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur(S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, select) → S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector</code> </dt> <dd>
<p>Reorders the Generalized Schur factorization of a matrix pair <code>(A, B) = (Q*S*Z', Q*T*Z')</code> according to the logical array <code>select</code> and returns the matrices <code>S</code>, <code>T</code>, <code>Q</code>, <code>Z</code> and vectors <code>α</code> and <code>β</code>. The selected eigenvalues appear in the leading diagonal of both <code>S</code> and <code>T</code>, and the left and right unitary/orthogonal Schur vectors are also reordered such that <code>(A, B) = Q*(S, T)*Z'</code> still holds and the generalized eigenvalues of <code>A</code> and <code>B</code> can still be obtained with <code>α./β</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>ordschur!(S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, select) → S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector</code> </dt> <dd>
<p>Same as <code>ordschur</code> but overwrites the factorization the input arguments.</p> </dd>
</dl> <dl class="function"> <dt>
<code>schur(A::StridedMatrix, B::StridedMatrix) → S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector</code> </dt> <dd>
<p>See <code>schurfact</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.svdfact">
<code>svdfact(A[, thin=true]) → SVD</code> </dt> <dd>
<p>Compute the singular value decomposition (SVD) of <code>A</code> and return an <code>SVD</code> object.</p> <p><code>U</code>, <code>S</code>, <code>V</code> and <code>Vt</code> can be obtained from the factorization <code>F</code> with <code>F[:U]</code>, <code>F[:S]</code>, <code>F[:V]</code> and <code>F[:Vt]</code>, such that <code>A = U*diagm(S)*Vt</code>. The algorithm produces <code>Vt</code> and hence <code>Vt</code> is more efficient to extract than <code>V</code>.</p> <p>If <code>thin=true</code> (default), a thin SVD is returned. For a <span class="math">\(M \times N\)</span> matrix <code>A</code>, <code>U</code> is <span class="math">\(M \times M\)</span> for a full SVD (<code>thin=false</code>) and <span class="math">\(M \times \min(M, N)\)</span> for a thin SVD.</p> </dd>
</dl> <dl class="function"> <dt id="Base.svdfact!">
<code>svdfact!(A[, thin=true]) → SVD</code> </dt> <dd>
<p><code>svdfact!</code> is the same as <a class="reference internal" href="#Base.svdfact" title="Base.svdfact"><code>svdfact()</code></a>, but saves space by overwriting the input <code>A</code>, instead of creating a copy.</p> <p>If <code>thin=true</code> (default), a thin SVD is returned. For a <span class="math">\(M \times N\)</span> matrix <code>A</code>, <code>U</code> is <span class="math">\(M \times M\)</span> for a full SVD (<code>thin=false</code>) and <span class="math">\(M \times \min(M, N)\)</span> for a thin SVD.</p> </dd>
</dl> <dl class="function"> <dt id="Base.svd">
<code>svd(A[, thin=true]) → U, S, V</code> </dt> <dd>
<p>Computes the SVD of <code>A</code>, returning <code>U</code>, vector <code>S</code>, and <code>V</code> such that <code>A == U*diagm(S)*V'</code>.</p> <p>If <code>thin=true</code> (default), a thin SVD is returned. For a <span class="math">\(M \times N\)</span> matrix <code>A</code>, <code>U</code> is <span class="math">\(M \times M\)</span> for a full SVD (<code>thin=false</code>) and <span class="math">\(M \times \min(M, N)\)</span> for a thin SVD.</p> <p><code>svd</code> is a wrapper around <code>svdfact(A)()</code>, extracting all parts of the <code>SVD</code> factorization to a tuple. Direct use of <code>svdfact</code> is therefore more efficient.</p> </dd>
</dl> <dl class="function"> <dt id="Base.svdvals">
<code>svdvals(A)</code> </dt> <dd>
<p>Returns the singular values of <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.svdvals!">
<code>svdvals!(A)</code> </dt> <dd>
<p>Returns the singular values of <code>A</code>, saving space by overwriting the input.</p> </dd>
</dl> <dl class="function"> <dt>
<code>svdfact(A, B) → GeneralizedSVD</code> </dt> <dd>
<p>Compute the generalized SVD of <code>A</code> and <code>B</code>, returning a <code>GeneralizedSVD</code> factorization object <code>F</code>, such that <code>A = F[:U]*F[:D1]*F[:R0]*F[:Q]'</code> and <code>B = F[:V]*F[:D2]*F[:R0]*F[:Q]'</code>.</p> <p>For an M-by-N matrix <code>A</code> and P-by-N matrix <code>B</code>,</p> <ul class="simple"> <li>
<code>F[:U]</code> is a M-by-M orthogonal matrix,</li> <li>
<code>F[:V]</code> is a P-by-P orthogonal matrix,</li> <li>
<code>F[:Q]</code> is a N-by-N orthogonal matrix,</li> <li>
<code>F[:R0]</code> is a (K+L)-by-N matrix whose rightmost (K+L)-by-(K+L) block is nonsingular upper block triangular,</li> <li>
<code>F[:D1]</code> is a M-by-(K+L) diagonal matrix with 1s in the first K entries,</li> <li>
<code>F[:D2]</code> is a P-by-(K+L) matrix whose top right L-by-L block is diagonal,</li> </ul> <p><code>K+L</code> is the effective numerical rank of the matrix <code>[A; B]</code>.</p> <p>The entries of <code>F[:D1]</code> and <code>F[:D2]</code> are related, as explained in the LAPACK documentation for the <a class="reference external" href="http://www.netlib.org/lapack/lug/node36.html" target="_blank">generalized SVD</a> and the <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d6/db3/dggsvd3_8f.html" target="_blank">xGGSVD3</a> routine which is called underneath (in LAPACK 3.6.0 and newer).</p> </dd>
</dl> <dl class="function"> <dt>
<code>svd(A, B) → U, V, Q, D1, D2, R0</code> </dt> <dd>
<p>Wrapper around <code>svdfact(A, B)()</code> extracting all parts of the factorization to a tuple. Direct use of <code>svdfact</code> is therefore generally more efficient. The function returns the generalized SVD of <code>A</code> and <code>B</code>, returning <code>U</code>, <code>V</code>, <code>Q</code>, <code>D1</code>, <code>D2</code>, and <code>R0</code> such that <code>A = U*D1*R0*Q'</code> and <code>B = V*D2*R0*Q'</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>svdvals(A, B)</code> </dt> <dd>
<p>Return the generalized singular values from the generalized singular value decomposition of <code>A</code> and <code>B</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.Givens">
<code>LinAlg.Givens(i1, i2, c, s) → G</code> </dt> <dd>
<p>A Givens rotation linear operator. The fields <code>c</code> and <code>s</code> represent the cosine and sine of the rotation angle, respectively. The <code>Givens</code> type supports left multiplication <code>G*A</code> and conjugated transpose right multiplication <code>A*G'</code>. The type doesn’t have a <code>size</code> and can therefore be multiplied with matrices of arbitrary size as long as <code>i2&lt;=size(A,2)</code> for <code>G*A</code> or <code>i2&lt;=size(A,1)</code> for <code>A*G'</code>.</p> <p>See also: <a class="reference internal" href="#Base.givens" title="Base.givens"><code>givens()</code></a></p> </dd>
</dl> <dl class="function"> <dt id="Base.givens{T}">
<code>givens{T}(f::T, g::T, i1::Integer, i2::Integer) → (G::Givens, r::T)</code> </dt> <dd>
<p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that for any vector <code>x</code> where</p> <pre data-language="julia">x[i1] = f
x[i2] = g
</pre> <p>the result of the multiplication</p> <pre data-language="julia">y = G*x
</pre> <p>has the property that</p> <pre data-language="julia">y[i1] = r
y[i2] = 0
</pre> <p>See also: <a class="reference internal" href="#Base.LinAlg.Givens" title="Base.LinAlg.Givens"><code>LinAlg.Givens</code></a></p> </dd>
</dl> <dl class="function"> <dt id="Base.givens">
<code>givens(x::AbstractVector, i1::Integer, i2::Integer) → (G::Givens, r)</code> </dt> <dd>
<p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that the result of the multiplication</p> <pre data-language="julia">B = G*x
</pre> <p>has the property that</p> <pre data-language="julia">B[i1] = r
B[i2] = 0
</pre> <p>See also: <a class="reference internal" href="#Base.LinAlg.Givens" title="Base.LinAlg.Givens"><code>LinAlg.Givens</code></a></p> </dd>
</dl> <dl class="function"> <dt>
<code>givens(A::AbstractArray, i1::Integer, i2::Integer, j::Integer) → (G::Givens, r)</code> </dt> <dd>
<p>Computes the Givens rotation <code>G</code> and scalar <code>r</code> such that the result of the multiplication</p> <pre data-language="julia">B = G*A
</pre> <p>has the property that</p> <pre data-language="julia">B[i1,j] = r
B[i2,j] = 0
</pre> <p>See also: <a class="reference internal" href="#Base.LinAlg.Givens" title="Base.LinAlg.Givens"><code>LinAlg.Givens</code></a></p> </dd>
</dl> <dl class="function"> <dt id="Base.triu">
<code>triu(M)</code> </dt> <dd>
<p>Upper triangle of a matrix.</p> </dd>
</dl> <dl class="function"> <dt>
<code>triu(M, k)</code> </dt> <dd>
<p>Returns the upper triangle of <code>M</code> starting from the <code>k</code>th superdiagonal.</p> </dd>
</dl> <dl class="function"> <dt id="Base.triu!">
<code>triu!(M)</code> </dt> <dd>
<p>Upper triangle of a matrix, overwriting <code>M</code> in the process.</p> </dd>
</dl> <dl class="function"> <dt>
<code>triu!(M, k)</code> </dt> <dd>
<p>Returns the upper triangle of <code>M</code> starting from the <code>k</code>th superdiagonal, overwriting <code>M</code> in the process.</p> </dd>
</dl> <dl class="function"> <dt id="Base.tril">
<code>tril(M)</code> </dt> <dd>
<p>Lower triangle of a matrix.</p> </dd>
</dl> <dl class="function"> <dt>
<code>tril(M, k)</code> </dt> <dd>
<p>Returns the lower triangle of <code>M</code> starting from the <code>k</code>th superdiagonal.</p> </dd>
</dl> <dl class="function"> <dt id="Base.tril!">
<code>tril!(M)</code> </dt> <dd>
<p>Lower triangle of a matrix, overwriting <code>M</code> in the process.</p> </dd>
</dl> <dl class="function"> <dt>
<code>tril!(M, k)</code> </dt> <dd>
<p>Returns the lower triangle of <code>M</code> starting from the <code>k</code>th superdiagonal, overwriting <code>M</code> in the process.</p> </dd>
</dl> <dl class="function"> <dt id="Base.diagind">
<code>diagind(M[, k])</code> </dt> <dd>
<p>A <code>Range</code> giving the indices of the <code>k</code>th diagonal of the matrix <code>M</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.diag">
<code>diag(M[, k])</code> </dt> <dd>
<p>The <code>k</code>th diagonal of a matrix, as a vector. Use <code>diagm</code> to construct a diagonal matrix.</p> </dd>
</dl> <dl class="function"> <dt id="Base.diagm">
<code>diagm(v[, k])</code> </dt> <dd>
<p>Construct a diagonal matrix and place <code>v</code> on the <code>k</code>th diagonal.</p> </dd>
</dl> <dl class="function"> <dt id="Base.scale!">
<code>scale!(A, b)</code> </dt> <dt>
<code>scale!(b, A)</code> </dt> <dd>
<p>Scale an array <code>A</code> by a scalar <code>b</code> overwriting <code>A</code> in-place.</p> <p>If <code>A</code> is a matrix and <code>b</code> is a vector, then <code>scale!(A,b)</code> scales each column <code>i</code> of <code>A</code> by <code>b[i]</code> (similar to <code>A*Diagonal(b)</code>), while <code>scale!(b,A)</code> scales each row <code>i</code> of <code>A</code> by <code>b[i]</code> (similar to <code>Diagonal(b)*A</code>), again operating in-place on <code>A</code>. An <code>InexactError</code> exception is thrown if the scaling produces a number not representable by the element type of <code>A</code>, e.g. for integer types.</p> </dd>
</dl> <dl class="function"> <dt>
<code>Tridiagonal(dl, d, du)</code> </dt> <dd>
<p>Construct a tridiagonal matrix from the first subdiagonal, diagonal, and first superdiagonal, respectively. The result is of type <code>Tridiagonal</code> and provides efficient specialized linear solvers, but may be converted into a regular matrix with <a class="reference internal" href="#Base.full" title="Base.full"><code>full()</code></a>. The lengths of <code>dl</code> and <code>du</code> must be one less than the length of <code>d</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.rank">
<code>rank(M)</code> </dt> <dd>
<p>Compute the rank of a matrix.</p> </dd>
</dl> <dl class="function"> <dt id="Base.norm">
<code>norm(A[, p])</code> </dt> <dd>
<p>Compute the <code>p</code>-norm of a vector or the operator norm of a matrix <code>A</code>, defaulting to the <code>p=2</code>-norm.</p> <p>For vectors, <code>p</code> can assume any numeric value (even though not all values produce a mathematically valid vector norm). In particular, <code>norm(A, Inf)</code> returns the largest value in <code>abs(A)</code>, whereas <code>norm(A, -Inf)</code> returns the smallest.</p> <p>For matrices, the matrix norm induced by the vector <code>p</code>-norm is used, where valid values of <code>p</code> are <code>1</code>, <code>2</code>, or <code>Inf</code>. (Note that for sparse matrices, <code>p=2</code> is currently not implemented.) Use <a class="reference internal" href="#Base.vecnorm" title="Base.vecnorm"><code>vecnorm()</code></a> to compute the Frobenius norm.</p> </dd>
</dl> <dl class="function"> <dt id="Base.vecnorm">
<code>vecnorm(A[, p])</code> </dt> <dd>
<p>For any iterable container <code>A</code> (including arrays of any dimension) of numbers (or any element type for which <code>norm</code> is defined), compute the <code>p</code>-norm (defaulting to <code>p=2</code>) as if <code>A</code> were a vector of the corresponding length.</p> <p>For example, if <code>A</code> is a matrix and <code>p=2</code>, then this is equivalent to the Frobenius norm.</p> </dd>
</dl> <dl class="function"> <dt id="Base.normalize!">
<code>normalize!(v[, p=2])</code> </dt> <dd>
<p>Normalize the vector <code>v</code> in-place with respect to the <code>p</code>-norm.</p> <p>Inputs:</p> <ul class="simple"> <li>
<code>v::AbstractVector</code> - vector to be normalized</li> <li>
<code>p::Real</code> - The <code>p</code>-norm to normalize with respect to. Default: 2</li> </ul> <p>Output:</p> <ul class="simple"> <li>
<code>v</code> - A unit vector being the input vector, rescaled to have norm 1. The input vector is modified in-place.</li> </ul> <p>See also:</p> <p><code>normalize</code>, <code>qr</code></p> </dd>
</dl> <dl class="function"> <dt id="Base.normalize">
<code>normalize(v[, p=2])</code> </dt> <dd>
<p>Normalize the vector <code>v</code> with respect to the <code>p</code>-norm.</p> <p>Inputs:</p> <ul class="simple"> <li>
<code>v::AbstractVector</code> - vector to be normalized</li> <li>
<code>p::Real</code> - The <code>p</code>-norm to normalize with respect to. Default: 2</li> </ul> <p>Output:</p> <ul class="simple"> <li>
<code>v</code> - A unit vector being a copy of the input vector, scaled to have norm 1</li> </ul> <p>See also:</p> <p><code>normalize!</code>, <code>qr</code></p> </dd>
</dl> <dl class="function"> <dt id="Base.cond">
<code>cond(M[, p])</code> </dt> <dd>
<p>Condition number of the matrix <code>M</code>, computed using the operator <code>p</code>-norm. Valid values for <code>p</code> are <code>1</code>, <code>2</code> (default), or <code>Inf</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.condskeel">
<code>condskeel(M[, x, p])</code> </dt> <dd>
<div class="math"> \[\begin{split}\kappa_S(M, p) &amp; = \left\Vert \left\vert M \right\vert \left\vert M^{-1} \right\vert \right\Vert_p \\ \kappa_S(M, x, p) &amp; = \left\Vert \left\vert M \right\vert \left\vert M^{-1} \right\vert \left\vert x \right\vert \right\Vert_p\end{split}\]</div> <p>Skeel condition number <span class="math">\(\kappa_S\)</span> of the matrix <code>M</code>, optionally with respect to the vector <code>x</code>, as computed using the operator <code>p</code>-norm. <code>p</code> is <code>Inf</code> by default, if not provided. Valid values for <code>p</code> are <code>1</code>, <code>2</code>, or <code>Inf</code>.</p> <p>This quantity is also known in the literature as the Bauer condition number, relative condition number, or componentwise relative condition number.</p> </dd>
</dl> <dl class="function"> <dt id="Base.trace">
<code>trace(M)</code> </dt> <dd>
<p>Matrix trace.</p> </dd>
</dl> <dl class="function"> <dt id="Base.det">
<code>det(M)</code> </dt> <dd>
<p>Matrix determinant.</p> </dd>
</dl> <dl class="function"> <dt id="Base.logdet">
<code>logdet(M)</code> </dt> <dd>
<p>Log of matrix determinant. Equivalent to <code>log(det(M))</code>, but may provide increased accuracy and/or speed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.logabsdet">
<code>logabsdet(M)</code> </dt> <dd>
<p>Log of absolute value of determinant of real matrix. Equivalent to <code>(log(abs(det(M))), sign(det(M)))</code>, but may provide increased accuracy and/or speed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.inv">
<code>inv(M)</code> </dt> <dd>
<p>Matrix inverse.</p> </dd>
</dl> <dl class="function"> <dt id="Base.pinv">
<code>pinv(M[, tol])</code> </dt> <dd>
<p>Computes the Moore-Penrose pseudoinverse.</p> <p>For matrices <code>M</code> with floating point elements, it is convenient to compute the pseudoinverse by inverting only singular values above a given threshold, <code>tol</code>.</p> <p>The optimal choice of <code>tol</code> varies both with the value of <code>M</code> and the intended application of the pseudoinverse. The default value of <code>tol</code> is <code>eps(real(float(one(eltype(M)))))*maximum(size(A))</code>, which is essentially machine epsilon for the real part of a matrix element multiplied by the larger matrix dimension. For inverting dense ill-conditioned matrices in a least-squares sense, <code>tol = sqrt(eps(real(float(one(eltype(M))))))</code> is recommended.</p> <p>For more information, see <a class="reference internal" href="#issue8859" id="id5">[issue8859]</a>, <a class="reference internal" href="#b96" id="id6">[B96]</a>, <a class="reference internal" href="#s84" id="id7">[S84]</a>, <a class="reference internal" href="#ky88" id="id8">[KY88]</a>.</p> <table class="docutils citation" frame="void" id="issue8859" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id5">[issue8859]</a></td>
<td>Issue 8859, “Fix least squares”, <a class="reference external" href="https://github.com/JuliaLang/julia/pull/8859" target="_blank">https://github.com/JuliaLang/julia/pull/8859</a>
</td>
</tr>  </table> <table class="docutils citation" frame="void" id="b96" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id6">[B96]</a></td>
<td>Åke Björck, “Numerical Methods for Least Squares Problems”, SIAM Press, Philadelphia, 1996, “Other Titles in Applied Mathematics”, Vol. 51. <a class="reference external" href="http://epubs.siam.org/doi/book/10.1137/1.9781611971484" target="_blank">doi:10.1137/1.9781611971484</a>
</td>
</tr>  </table> <table class="docutils citation" frame="void" id="s84" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id7">[S84]</a></td>
<td>
<ol class="first last upperalpha simple" start="7"> <li>
<ol class="first upperalpha" start="23"> <li>Stewart, “Rank Degeneracy”, SIAM Journal on Scientific and Statistical Computing, 5(2), 1984, 403-413. <a class="reference external" href="http://epubs.siam.org/doi/abs/10.1137/0905030" target="_blank">doi:10.1137/0905030</a>
</li> </ol> </li> </ol> </td>
</tr>  </table> <table class="docutils citation" frame="void" id="ky88" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id8">[KY88]</a></td>
<td>Konstantinos Konstantinides and Kung Yao, “Statistical analysis of effective singular values in matrix rank determination”, IEEE Transactions on Acoustics, Speech and Signal Processing, 36(5), 1988, 757-763. <a class="reference external" href="http://dx.doi.org/10.1109/29.1585" target="_blank">doi:10.1109/29.1585</a>
</td>
</tr>  </table> </dd>
</dl> <dl class="function"> <dt id="Base.nullspace">
<code>nullspace(M)</code> </dt> <dd>
<p>Basis for nullspace of <code>M</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.repmat">
<code>repmat(A, n, m)</code> </dt> <dd>
<p>Construct a matrix by repeating the given matrix <code>n</code> times in dimension 1 and <code>m</code> times in dimension 2.</p> </dd>
</dl> <dl class="function"> <dt id="Base.repeat">
<code>repeat(A::AbstractArray; inner=ntuple(x-&gt;1, ndims(A)), outer=ntuple(x-&gt;1, ndims(A)))</code> </dt> <dd>
<p>Construct an array by repeating the entries of <code>A</code>. The i-th element of <code>inner</code> specifies the number of times that the individual entries of the i-th dimension of <code>A</code> should be repeated. The i-th element of <code>outer</code> specifies the number of times that a slice along the i-th dimension of <code>A</code> should be repeated. If <code>inner</code> or <code>outer</code> are omitted, no repetition is performed.</p> <pre data-language="julia">julia&gt; repeat(1:2, inner=2)
4-element Array{Int64,1}:
 1
 1
 2
 2

julia&gt; repeat(1:2, outer=2)
4-element Array{Int64,1}:
 1
 2
 1
 2

julia&gt; repeat([1 2; 3 4], inner=(2, 1), outer=(1, 3))
4×6 Array{Int64,2}:
 1  2  1  2  1  2
 1  2  1  2  1  2
 3  4  3  4  3  4
 3  4  3  4  3  4
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.kron">
<code>kron(A, B)</code> </dt> <dd>
<p>Kronecker tensor product of two vectors or two matrices.</p> </dd>
</dl> <dl class="function"> <dt id="Base.blkdiag">
<code>blkdiag(A...)</code> </dt> <dd>
<p>Concatenate matrices block-diagonally. Currently only implemented for sparse matrices.</p> </dd>
</dl> <dl class="function"> <dt id="Base.linreg">
<code>linreg(x, y)</code> </dt> <dd>
<p>Perform simple linear regression using Ordinary Least Squares. Returns <code>a</code> and <code>b</code> such that <code>a + b*x</code> is the closest straight line to the given points <code>(x, y)</code>, i.e., such that the squared error between <code>y</code> and <code>a + b*x</code> is minimized.</p> <p>Examples:</p> <pre data-language="julia">using PyPlot
x = 1.0:12.0
y = [5.5, 6.3, 7.6, 8.8, 10.9, 11.79, 13.48, 15.02, 17.77, 20.81, 22.0, 22.99]
a, b = linreg(x, y)          # Linear regression
plot(x, y, "o")              # Plot (x, y) points
plot(x, a + b*x)             # Plot line determined by linear regression
</pre> <p>See also:</p> <p><code>\</code>, <code>cov</code>, <code>std</code>, <code>mean</code></p> </dd>
</dl> <dl class="function"> <dt id="Base.expm">
<code>expm(A)</code> </dt> <dd>
<p>Compute the matrix exponential of <code>A</code>, defined by</p> <div class="math"> \[e^A = \sum_{n=0}^{\infty} \frac{A^n}{n!}.\]</div> <p>For symmetric or Hermitian <code>A</code>, an eigendecomposition (<a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>) is used, otherwise the scaling and squaring algorithm (see <a class="reference internal" href="#h05" id="id9">[H05]</a>) is chosen.</p> <table class="docutils citation" frame="void" id="h05" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id9">[H05]</a></td>
<td>Nicholas J. Higham, “The squaring and scaling method for the matrix exponential revisited”, SIAM Journal on Matrix Analysis and Applications, 26(4), 2005, 1179-1193. <a class="reference external" href="http://dx.doi.org/10.1137/090768539" target="_blank">doi:10.1137/090768539</a>
</td>
</tr>  </table> </dd>
</dl> <dl class="function"> <dt id="Base.logm">
<code>logm(A::StridedMatrix)</code> </dt> <dd>
<p>If <code>A</code> has no negative real eigenvalue, compute the principal matrix logarithm of <code>A</code>, i.e. the unique matrix <span class="math">\(X\)</span> such that <span class="math">\(e^X = A\)</span> and <span class="math">\(-\pi &lt; Im(\lambda) &lt; \pi\)</span> for all the eigenvalues <span class="math">\(\lambda\)</span> of <span class="math">\(X\)</span>. If <code>A</code> has nonpositive eigenvalues, a nonprincipal matrix function is returned whenever possible.</p> <p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>) is used, if <code>A</code> is triangular an improved version of the inverse scaling and squaring method is employed (see <a class="reference internal" href="#ah12" id="id10">[AH12]</a> and <a class="reference internal" href="#ahr13" id="id11">[AHR13]</a>). For general matrices, the complex Schur form (<a class="reference internal" href="#Base.schur" title="Base.schur"><code>schur()</code></a>) is computed and the triangular algorithm is used on the triangular factor.</p> <table class="docutils citation" frame="void" id="ah12" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id10">[AH12]</a></td>
<td>Awad H. Al-Mohy and Nicholas J. Higham, “Improved inverse scaling and squaring algorithms for the matrix logarithm”, SIAM Journal on Scientific Computing, 34(4), 2012, C153-C169. <a class="reference external" href="http://dx.doi.org/10.1137/110852553" target="_blank">doi:10.1137/110852553</a>
</td>
</tr>  </table> <table class="docutils citation" frame="void" id="ahr13" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id11">[AHR13]</a></td>
<td>Awad H. Al-Mohy, Nicholas J. Higham and Samuel D. Relton, “Computing the Fréchet derivative of the matrix logarithm and estimating the condition number”, SIAM Journal on Scientific Computing, 35(4), 2013, C394-C410. <a class="reference external" href="http://dx.doi.org/10.1137/120885991" target="_blank">doi:10.1137/120885991</a>
</td>
</tr>  </table> </dd>
</dl> <dl class="function"> <dt id="Base.sqrtm">
<code>sqrtm(A)</code> </dt> <dd>
<p>If <code>A</code> has no negative real eigenvalues, compute the principal matrix square root of <code>A</code>, that is the unique matrix <span class="math">\(X\)</span> with eigenvalues having positive real part such that <span class="math">\(X^2 = A\)</span>. Otherwise, a nonprincipal square root is returned.</p> <p>If <code>A</code> is symmetric or Hermitian, its eigendecomposition (<a class="reference internal" href="#Base.eigfact" title="Base.eigfact"><code>eigfact()</code></a>) is used to compute the square root. Otherwise, the square root is determined by means of the Björck-Hammarling method, which computes the complex Schur form (<a class="reference internal" href="#Base.schur" title="Base.schur"><code>schur()</code></a>) and then the complex square root of the triangular factor.</p> <table class="docutils citation" frame="void" id="bh83" rules="none">   <tr>
<td class="label">[BH83]</td>
<td>Åke Björck and Sven Hammarling, “A Schur method for the square root of a matrix”, Linear Algebra and its Applications, 52-53, 1983, 127-140. <a class="reference external" href="http://dx.doi.org/10.1016/0024-3795(83)80010-X" target="_blank">doi:10.1016/0024-3795(83)80010-X</a>
</td>
</tr>  </table> </dd>
</dl> <dl class="function"> <dt id="Base.lyap">
<code>lyap(A, C)</code> </dt> <dd>
<p>Computes the solution <code>X</code> to the continuous Lyapunov equation <code>AX + XA' + C = 0</code>, where no eigenvalue of <code>A</code> has a zero real part and no two eigenvalues are negative complex conjugates of each other.</p> </dd>
</dl> <dl class="function"> <dt id="Base.sylvester">
<code>sylvester(A, B, C)</code> </dt> <dd>
<p>Computes the solution <code>X</code> to the Sylvester equation <code>AX + XB + C = 0</code>, where <code>A</code>, <code>B</code> and <code>C</code> have compatible dimensions and <code>A</code> and <code>-B</code> have no eigenvalues with equal real part.</p> </dd>
</dl> <dl class="function"> <dt id="Base.issymmetric">
<code>issymmetric(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is symmetric.</p> </dd>
</dl> <dl class="function"> <dt id="Base.isposdef">
<code>isposdef(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is positive definite.</p> </dd>
</dl> <dl class="function"> <dt id="Base.isposdef!">
<code>isposdef!(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is positive definite, overwriting <code>A</code> in the processes.</p> </dd>
</dl> <dl class="function"> <dt id="Base.istril">
<code>istril(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is lower triangular.</p> </dd>
</dl> <dl class="function"> <dt id="Base.istriu">
<code>istriu(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is upper triangular.</p> </dd>
</dl> <dl class="function"> <dt id="Base.isdiag">
<code>isdiag(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is diagonal.</p> </dd>
</dl> <dl class="function"> <dt id="Base.ishermitian">
<code>ishermitian(A) → Bool</code> </dt> <dd>
<p>Test whether a matrix is Hermitian.</p> </dd>
</dl> <dl class="function"> <dt id="Base.transpose">
<code>transpose(A)</code> </dt> <dd>
<p>The transposition operator (<code>.'</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.transpose!">
<code>transpose!(dest, src)</code> </dt> <dd>
<p>Transpose array <code>src</code> and store the result in the preallocated array <code>dest</code>, which should have a size corresponding to <code>(size(src,2),size(src,1))</code>. No in-place transposition is supported and unexpected results will happen if <code>src</code> and <code>dest</code> have overlapping memory regions.</p> </dd>
</dl> <dl class="function"> <dt id="Base.ctranspose">
<code>ctranspose(A)</code> </dt> <dd>
<p>The conjugate transposition operator (<code>'</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.ctranspose!">
<code>ctranspose!(dest, src)</code> </dt> <dd>
<p>Conjugate transpose array <code>src</code> and store the result in the preallocated array <code>dest</code>, which should have a size corresponding to <code>(size(src,2),size(src,1))</code>. No in-place transposition is supported and unexpected results will happen if <code>src</code> and <code>dest</code> have overlapping memory regions.</p> </dd>
</dl> <dl class="function"> <dt id="Base.eigs">
<code>eigs(A; nev=6, ncv=max(20, 2*nev+1), which="LM", tol=0.0, maxiter=300, sigma=nothing, ritzvec=true, v0=zeros((0, ))) → (d,[v,],nconv,niter,nmult,resid)</code> </dt> <dd>
<p>Computes eigenvalues <code>d</code> of <code>A</code> using implicitly restarted Lanczos or Arnoldi iterations for real symmetric or general nonsymmetric matrices respectively.</p> <p>The following keyword arguments are supported:</p> <ul class="simple"> <li>
<code>nev</code>: Number of eigenvalues</li> <li>
<code>ncv</code>: Number of Krylov vectors used in the computation; should satisfy <code>nev+1 &lt;= ncv &lt;= n</code> for real symmetric problems and <code>nev+2 &lt;= ncv &lt;= n</code> for other problems, where <code>n</code> is the size of the input matrix <code>A</code>. The default is <code>ncv = max(20,2*nev+1)</code>. Note that these restrictions limit the input matrix <code>A</code> to be of dimension at least 2.</li> <li>
<code>which</code>: type of eigenvalues to compute. See the note below.</li> </ul> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head"><code>which</code></th> <th class="head">type of eigenvalues</th> </tr> </thead>  <tr class="row-even">
<td><code>:LM</code></td> <td>eigenvalues of largest magnitude (default)</td> </tr> <tr class="row-odd">
<td><code>:SM</code></td> <td>eigenvalues of smallest magnitude</td> </tr> <tr class="row-even">
<td><code>:LR</code></td> <td>eigenvalues of largest real part</td> </tr> <tr class="row-odd">
<td><code>:SR</code></td> <td>eigenvalues of smallest real part</td> </tr> <tr class="row-even">
<td><code>:LI</code></td> <td>eigenvalues of largest imaginary part (nonsymmetric or complex <code>A</code> only)</td> </tr> <tr class="row-odd">
<td><code>:SI</code></td> <td>eigenvalues of smallest imaginary part (nonsymmetric or complex <code>A</code> only)</td> </tr> <tr class="row-even">
<td><code>:BE</code></td> <td>compute half of the eigenvalues from each end of the spectrum, biased in favor of the high end. (real symmetric <code>A</code> only)</td> </tr>  </table> <ul class="simple"> <li>
<code>tol</code>: parameter defining the relative tolerance for convergence of Ritz values (eigenvalue estimates). A Ritz value <span class="math">\(θ\)</span> is considered converged when its associated residual is less than or equal to the product of <code>tol</code> and <span class="math">\(max(ɛ^{2/3}, |θ|)\)</span>, where <code>ɛ = eps(real(eltype(A)))/2</code> is LAPACK’s machine epsilon. The residual associated with <span class="math">\(θ\)</span> and its corresponding Ritz vector <span class="math">\(v\)</span> is defined as the norm <span class="math">\(||Av - vθ||\)</span>. The specified value of <code>tol</code> should be positive; otherwise, it is ignored and <span class="math">\(ɛ\)</span> is used instead. Default: <span class="math">\(ɛ\)</span>.</li> <li>
<code>maxiter</code>: Maximum number of iterations (default = 300)</li> <li>
<code>sigma</code>: Specifies the level shift used in inverse iteration. If <code>nothing</code> (default), defaults to ordinary (forward) iterations. Otherwise, find eigenvalues close to <code>sigma</code> using shift and invert iterations.</li> <li>
<code>ritzvec</code>: Returns the Ritz vectors <code>v</code> (eigenvectors) if <code>true</code>
</li> <li>
<code>v0</code>: starting vector from which to start the iterations</li> </ul> <p><code>eigs</code> returns the <code>nev</code> requested eigenvalues in <code>d</code>, the corresponding Ritz vectors <code>v</code> (only if <code>ritzvec=true</code>), the number of converged eigenvalues <code>nconv</code>, the number of iterations <code>niter</code> and the number of matrix vector multiplications <code>nmult</code>, as well as the final residual vector <code>resid</code>.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>The <code>sigma</code> and <code>which</code> keywords interact: the description of eigenvalues searched for by <code>which</code> do <em>not</em> necessarily refer to the eigenvalues of <code>A</code>, but rather the linear operator constructed by the specification of the iteration mode implied by <code>sigma</code>.</p> <table class="last docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head"><code>sigma</code></th> <th class="head">iteration mode</th> <th class="head">
<code>which</code> refers to eigenvalues of</th> </tr> </thead>  <tr class="row-even">
<td><code>nothing</code></td> <td>ordinary (forward)</td> <td><span class="math">\(A\)</span></td> </tr> <tr class="row-odd">
<td>real or complex</td> <td>inverse with level shift <code>sigma</code>
</td> <td><span class="math">\((A - \sigma I )^{-1}\)</span></td> </tr>  </table> </div> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>Although <code>tol</code> has a default value, the best choice depends strongly on the matrix <code>A</code>. We recommend that users _always_ specify a value for <code>tol</code> which suits their specific needs.</p> <p>For details of how the errors in the computed eigenvalues are estimated, see:</p> <ul class="last simple"> <li>
<ol class="first upperalpha" start="2"> <li>
<ol class="first upperalpha" start="14"> <li>Parlett, “The Symmetric Eigenvalue Problem”, SIAM: Philadelphia, 2/e (1998), Ch. 13.2, “Accessing Accuracy in Lanczos Problems”, pp. 290-292 ff.</li> </ol> </li> </ol> </li> <li>
<ol class="first upperalpha" start="18"> <li>
<ol class="first upperalpha" start="2"> <li>Lehoucq and D. C. Sorensen, “Deflation Techniques for an Implicitly Restarted Arnoldi Iteration”, SIAM Journal on Matrix Analysis and Applications (1996), 17(4), 789–821. doi:10.1137/S0895479895281484</li> </ol> </li> </ol> </li> </ul> </div> </dd>
</dl> <dl class="function"> <dt>
<code>eigs(A, B; nev=6, ncv=max(20, 2*nev+1), which="LM", tol=0.0, maxiter=300, sigma=nothing, ritzvec=true, v0=zeros((0, ))) → (d,[v,],nconv,niter,nmult,resid)</code> </dt> <dd>
<p>Computes generalized eigenvalues <code>d</code> of <code>A</code> and <code>B</code> using implicitly restarted Lanczos or Arnoldi iterations for real symmetric or general nonsymmetric matrices respectively.</p> <p>The following keyword arguments are supported:</p> <ul class="simple"> <li>
<code>nev</code>: Number of eigenvalues</li> <li>
<code>ncv</code>: Number of Krylov vectors used in the computation; should satisfy <code>nev+1 &lt;= ncv &lt;= n</code> for real symmetric problems and <code>nev+2 &lt;= ncv &lt;= n</code> for other problems, where <code>n</code> is the size of the input matrices <code>A</code> and <code>B</code>. The default is <code>ncv = max(20,2*nev+1)</code>. Note that these restrictions limit the input matrix <code>A</code> to be of dimension at least 2.</li> <li>
<code>which</code>: type of eigenvalues to compute. See the note below.</li> </ul> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head"><code>which</code></th> <th class="head">type of eigenvalues</th> </tr> </thead>  <tr class="row-even">
<td><code>:LM</code></td> <td>eigenvalues of largest magnitude (default)</td> </tr> <tr class="row-odd">
<td><code>:SM</code></td> <td>eigenvalues of smallest magnitude</td> </tr> <tr class="row-even">
<td><code>:LR</code></td> <td>eigenvalues of largest real part</td> </tr> <tr class="row-odd">
<td><code>:SR</code></td> <td>eigenvalues of smallest real part</td> </tr> <tr class="row-even">
<td><code>:LI</code></td> <td>eigenvalues of largest imaginary part (nonsymmetric or complex <code>A</code> only)</td> </tr> <tr class="row-odd">
<td><code>:SI</code></td> <td>eigenvalues of smallest imaginary part (nonsymmetric or complex <code>A</code> only)</td> </tr> <tr class="row-even">
<td><code>:BE</code></td> <td>compute half of the eigenvalues from each end of the spectrum, biased in favor of the high end. (real symmetric <code>A</code> only)</td> </tr>  </table> <ul class="simple"> <li>
<code>tol</code>: relative tolerance used in the convergence criterion for eigenvalues, similar to <code>tol</code> in the <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a> method for the ordinary eigenvalue problem, but effectively for the eigenvalues of <span class="math">\(B^{-1} A\)</span> instead of <span class="math">\(A\)</span>. See the documentation for the ordinary eigenvalue problem in <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a> and the accompanying note about <code>tol</code>.</li> <li>
<code>maxiter</code>: Maximum number of iterations (default = 300)</li> <li>
<code>sigma</code>: Specifies the level shift used in inverse iteration. If <code>nothing</code> (default), defaults to ordinary (forward) iterations. Otherwise, find eigenvalues close to <code>sigma</code> using shift and invert iterations.</li> <li>
<code>ritzvec</code>: Returns the Ritz vectors <code>v</code> (eigenvectors) if <code>true</code>
</li> <li>
<code>v0</code>: starting vector from which to start the iterations</li> </ul> <p><code>eigs</code> returns the <code>nev</code> requested eigenvalues in <code>d</code>, the corresponding Ritz vectors <code>v</code> (only if <code>ritzvec=true</code>), the number of converged eigenvalues <code>nconv</code>, the number of iterations <code>niter</code> and the number of matrix vector multiplications <code>nmult</code>, as well as the final residual vector <code>resid</code>.</p> <p><strong>Example</strong></p> <pre data-language="julia">X = sprand(10, 5, 0.2)
eigs(X, nsv = 2, tol = 1e-3)
</pre> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>The <code>sigma</code> and <code>which</code> keywords interact: the description of eigenvalues searched for by <code>which</code> do <em>not</em> necessarily refer to the eigenvalue problem <span class="math">\(Av = Bv\lambda\)</span>, but rather the linear operator constructed by the specification of the iteration mode implied by <code>sigma</code>.</p> <table class="last docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head"><code>sigma</code></th> <th class="head">iteration mode</th> <th class="head">
<code>which</code> refers to the problem</th> </tr> </thead>  <tr class="row-even">
<td><code>nothing</code></td> <td>ordinary (forward)</td> <td><span class="math">\(Av = Bv\lambda\)</span></td> </tr> <tr class="row-odd">
<td>real or complex</td> <td>inverse with level shift <code>sigma</code>
</td> <td><span class="math">\((A - \sigma B )^{-1}B = v\nu\)</span></td> </tr>  </table> </div> </dd>
</dl> <dl class="function"> <dt id="Base.svds">
<code>svds(A; nsv=6, ritzvec=true, tol=0.0, maxiter=1000, ncv=2*nsv, u0=zeros((0, )), v0=zeros((0, ))) → (SVD([left_sv,] s, [right_sv,]), nconv, niter, nmult, resid)</code> </dt> <dd>
<p>Computes the largest singular values <code>s</code> of <code>A</code> using implicitly restarted Lanczos iterations derived from <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a>.</p> <p><strong>Inputs</strong></p> <ul class="simple"> <li>
<code>A</code>: Linear operator whose singular values are desired. <code>A</code> may be represented as a subtype of <code>AbstractArray</code>, e.g., a sparse matrix, or any other type supporting the four methods <code>size(A)</code>, <code>eltype(A)</code>, <code>A * vector</code>, and <code>A' * vector</code>.</li> <li>
<code>nsv</code>: Number of singular values. Default: 6.</li> <li>
<code>ritzvec</code>: If <code>true</code>, return the left and right singular vectors <code>left_sv</code> and <code>right_sv</code>. If <code>false</code>, omit the singular vectors. Default: <code>true</code>.</li> <li>
<code>tol</code>: tolerance, see <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a>.</li> <li>
<code>maxiter</code>: Maximum number of iterations, see <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a>. Default: 1000.</li> <li>
<code>ncv</code>: Maximum size of the Krylov subspace, see <a class="reference internal" href="#Base.eigs" title="Base.eigs"><code>eigs()</code></a> (there called <code>nev</code>). Default: <code>2*nsv</code>.</li> <li>
<code>u0</code>: Initial guess for the first left Krylov vector. It may have length <code>m</code> (the first dimension of <code>A</code>), or 0.</li> <li>
<code>v0</code>: Initial guess for the first right Krylov vector. It may have length <code>n</code> (the second dimension of <code>A</code>), or 0.</li> </ul> <p><strong>Outputs</strong></p> <ul class="simple"> <li>
<code>svd</code>: An <code>SVD</code> object containing the left singular vectors, the requested values, and the right singular vectors. If <code>ritzvec = false</code>, the left and right singular vectors will be empty.</li> <li>
<code>nconv</code>: Number of converged singular values.</li> <li>
<code>niter</code>: Number of iterations.</li> <li>
<code>nmult</code>: Number of matrix–vector products used.</li> <li>
<code>resid</code>: Final residual vector.</li> </ul> <p><strong>Example</strong></p> <pre data-language="julia">X = sprand(10, 5, 0.2)
svds(X, nsv = 2)
</pre> <p><strong>Implementation note</strong></p> <p><code>svds(A)</code> is formally equivalent to calling <code>eigs</code> to perform implicitly restarted Lanczos tridiagonalization on the Hermitian matrix <span class="math">\(\begin{pmatrix} 0 &amp; A^\prime \\ A &amp; 0 \end{pmatrix}\)</span>, whose eigenvalues are plus and minus the singular values of <span class="math">\(A\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.peakflops">
<code>peakflops(n; parallel=false)</code> </dt> <dd>
<p><code>peakflops</code> computes the peak flop rate of the computer by using double precision <a class="reference internal" href="#Base.LinAlg.BLAS.gemm!" title="Base.LinAlg.BLAS.gemm!"><code>Base.LinAlg.BLAS.gemm!()</code></a>. By default, if no arguments are specified, it multiplies a matrix of size <code>n x n</code>, where <code>n = 2000</code>. If the underlying BLAS is using multiple threads, higher flop rates are realized. The number of BLAS threads can be set with <code>BLAS.set_num_threads(n)</code>.</p> <p>If the keyword argument <code>parallel</code> is set to <code>true</code>, <code>peakflops</code> is run in parallel on all the worker processors. The flop rate of the entire parallel computer is returned. When running in parallel, only 1 BLAS thread is used. The argument <code>n</code> still refers to the size of the problem that is solved on each processor.</p> </dd>
</dl>   <h2 id="low-level-matrix-operations">Low-level matrix operations</h2> <p>Matrix operations involving transpositions operations like <code>A' \ B</code> are converted by the Julia parser into calls to specially named functions like <code>Ac_ldiv_B</code>. If you want to overload these operations for your own types, then it is useful to know the names of these functions.</p> <p>Also, in many cases there are in-place versions of matrix operations that allow you to supply a pre-allocated output vector or matrix. This is useful when optimizing critical code in order to avoid the overhead of repeated allocations. These in-place operations are suffixed with <code>!</code> below (e.g. <code>A_mul_B!</code>) according to the usual Julia convention.</p> <dl class="function"> <dt id="Base.A_ldiv_B!">
<code>A_ldiv_B!([Y, ]A, B) → Y</code> </dt> <dd>
<p>Compute <code>A \ B</code> in-place and store the result in <code>Y</code>, returning the result. If only two arguments are passed, then <code>A_ldiv_B!(A, B)</code> overwrites <code>B</code> with the result.</p> <p>The argument <code>A</code> should <em>not</em> be a matrix. Rather, instead of matrices it should be a factorization object (e.g. produced by <a class="reference internal" href="#Base.factorize" title="Base.factorize"><code>factorize()</code></a> or <a class="reference internal" href="#Base.cholfact" title="Base.cholfact"><code>cholfact()</code></a>). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., <a class="reference internal" href="#Base.lufact!" title="Base.lufact!"><code>lufact!()</code></a>), and performance-critical situations requiring <code>A_ldiv_B!</code> usually also require fine-grained control over the factorization of <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_ldiv_Bc">
<code>A_ldiv_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A\)</span> \ <span class="math">\(Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_ldiv_Bt">
<code>A_ldiv_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A\)</span> \ <span class="math">\(Bᵀ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_mul_B!">
<code>A_mul_B!(Y, A, B) → Y</code> </dt> <dd>
<p>Calculates the matrix-matrix or matrix-vector product <span class="math">\(A⋅B\)</span> and stores the result in <code>Y</code>, overwriting the existing value of <code>Y</code>. Note that <code>Y</code> must not be aliased with either <code>A</code> or <code>B</code>.</p> <pre data-language="julia">julia&gt; A=[1.0 2.0; 3.0 4.0]; B=[1.0 1.0; 1.0 1.0]; Y = similar(B); A_mul_B!(Y, A, B);

julia&gt; Y
2×2 Array{Float64,2}:
 3.0  3.0
 7.0  7.0
</pre> </dd>
</dl> <dl class="function"> <dt id="Base.A_mul_Bc">
<code>A_mul_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A⋅Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_mul_Bt">
<code>A_mul_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A⋅Bᵀ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_rdiv_Bc">
<code>A_rdiv_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A / Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.A_rdiv_Bt">
<code>A_rdiv_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(A / Bᵀ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_ldiv_B">
<code>Ac_ldiv_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ\)</span> \ <span class="math">\(B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_ldiv_B!">
<code>Ac_ldiv_B!([Y, ]A, B) → Y</code> </dt> <dd>
<p>Similar to <a class="reference internal" href="#Base.A_ldiv_B!" title="Base.A_ldiv_B!"><code>A_ldiv_B!()</code></a>, but return <span class="math">\(Aᴴ\)</span> \ <span class="math">\(B\)</span>, computing the result in-place in <code>Y</code> (or overwriting <code>B</code> if <code>Y</code> is not supplied).</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_ldiv_Bc">
<code>Ac_ldiv_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ\)</span> \ <span class="math">\(Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_mul_B">
<code>Ac_mul_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ⋅B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_mul_Bc">
<code>Ac_mul_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_rdiv_B">
<code>Ac_rdiv_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ / B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.Ac_rdiv_Bc">
<code>Ac_rdiv_Bc(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᴴ / Bᴴ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_ldiv_B">
<code>At_ldiv_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ\)</span> \ <span class="math">\(B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_ldiv_B!">
<code>At_ldiv_B!([Y, ]A, B) → Y</code> </dt> <dd>
<p>Similar to <a class="reference internal" href="#Base.A_ldiv_B!" title="Base.A_ldiv_B!"><code>A_ldiv_B!()</code></a>, but return <span class="math">\(Aᵀ\)</span> \ <span class="math">\(B\)</span>, computing the result in-place in <code>Y</code> (or overwriting <code>B</code> if <code>Y</code> is not supplied).</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_ldiv_Bt">
<code>At_ldiv_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ\)</span> \ <span class="math">\(Bᵀ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_mul_B">
<code>At_mul_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ⋅B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_mul_Bt">
<code>At_mul_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ⋅Bᵀ\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_rdiv_B">
<code>At_rdiv_B(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ / B\)</span>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.At_rdiv_Bt">
<code>At_rdiv_Bt(A, B)</code> </dt> <dd>
<p>For matrices or vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, calculates <span class="math">\(Aᵀ / Bᵀ\)</span>.</p> </dd>
</dl>   <h2 id="blas-functions">BLAS Functions</h2> <p id="module-Base.LinAlg.BLAS">In Julia (as in much of scientific computation), dense linear-algebra operations are based on the <a class="reference external" href="http://www.netlib.org/lapack/" target="_blank">LAPACK library</a>, which in turn is built on top of basic linear-algebra building-blocks known as the <a class="reference external" href="http://www.netlib.org/blas/" target="_blank">BLAS</a>. There are highly optimized implementations of BLAS available for every computer architecture, and sometimes in high-performance linear algebra routines it is useful to call the BLAS functions directly.</p> <p><a class="reference internal" href="#module-Base.LinAlg.BLAS" title="Base.LinAlg.BLAS"><code>Base.LinAlg.BLAS</code></a> provides wrappers for some of the BLAS functions. Those BLAS functions that overwrite one of the input arrays have names ending in <code>'!'</code>. Usually, a BLAS function has four methods defined, for <code>Float64</code>, <code>Float32</code>, <code>Complex128</code>, and <code>Complex64</code> arrays.</p> <dl class="function"> <dt id="Base.LinAlg.BLAS.dot">
<code>dot(n, X, incx, Y, incy)</code> </dt> <dd>
<p>Dot product of two vectors consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code> and <code>n</code> elements of array <code>Y</code> with stride <code>incy</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.dotu">
<code>dotu(n, X, incx, Y, incy)</code> </dt> <dd>
<p>Dot function for two complex vectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.dotc">
<code>dotc(n, X, incx, U, incy)</code> </dt> <dd>
<p>Dot function for two complex vectors conjugating the first vector.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.blascopy!">
<code>blascopy!(n, X, incx, Y, incy)</code> </dt> <dd>
<p>Copy <code>n</code> elements of array <code>X</code> with stride <code>incx</code> to array <code>Y</code> with stride <code>incy</code>. Returns <code>Y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.nrm2">
<code>nrm2(n, X, incx)</code> </dt> <dd>
<p>2-norm of a vector consisting of <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.asum">
<code>asum(n, X, incx)</code> </dt> <dd>
<p>Sum of the absolute values of the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.axpy!">
<code>axpy!(a, X, Y)</code> </dt> <dd>
<p>Overwrite <code>Y</code> with <code>a*X + Y</code>. Returns <code>Y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.scal!">
<code>scal!(n, a, X, incx)</code> </dt> <dd>
<p>Overwrite <code>X</code> with <code>a*X</code> for the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>. Returns <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.scal">
<code>scal(n, a, X, incx)</code> </dt> <dd>
<p>Returns <code>X</code> scaled by <code>a</code> for the first <code>n</code> elements of array <code>X</code> with stride <code>incx</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.ger!">
<code>ger!(alpha, x, y, A)</code> </dt> <dd>
<p>Rank-1 update of the matrix <code>A</code> with vectors <code>x</code> and <code>y</code> as <code>alpha*x*y' + A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.syr!">
<code>syr!(uplo, alpha, x, A)</code> </dt> <dd>
<p>Rank-1 update of the symmetric matrix <code>A</code> with vector <code>x</code> as <code>alpha*x*x.' + A</code>. When <code>uplo</code> is ‘U’ the upper triangle of <code>A</code> is updated (‘L’ for lower triangle). Returns <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.syrk!">
<code>syrk!(uplo, trans, alpha, A, beta, C)</code> </dt> <dd>
<p>Rank-k update of the symmetric matrix <code>C</code> as <code>alpha*A*A.' + beta*C</code> or <code>alpha*A.'*A + beta*C</code> according to whether <code>trans</code> is ‘N’ or ‘T’. When <code>uplo</code> is ‘U’ the upper triangle of <code>C</code> is updated (‘L’ for lower triangle). Returns <code>C</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.syrk">
<code>syrk(uplo, trans, alpha, A)</code> </dt> <dd>
<p>Returns either the upper triangle or the lower triangle, according to <code>uplo</code> (‘U’ or ‘L’), of <code>alpha*A*A.'</code> or <code>alpha*A.'*A</code>, according to <code>trans</code> (‘N’ or ‘T’).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.her!">
<code>her!(uplo, alpha, x, A)</code> </dt> <dd>
<p>Methods for complex arrays only. Rank-1 update of the Hermitian matrix <code>A</code> with vector <code>x</code> as <code>alpha*x*x' + A</code>. When <code>uplo</code> is ‘U’ the upper triangle of <code>A</code> is updated (‘L’ for lower triangle). Returns <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.herk!">
<code>herk!(uplo, trans, alpha, A, beta, C)</code> </dt> <dd>
<p>Methods for complex arrays only. Rank-k update of the Hermitian matrix <code>C</code> as <code>alpha*A*A' + beta*C</code> or <code>alpha*A'*A + beta*C</code> according to whether <code>trans</code> is ‘N’ or ‘T’. When <code>uplo</code> is ‘U’ the upper triangle of <code>C</code> is updated (‘L’ for lower triangle). Returns <code>C</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.herk">
<code>herk(uplo, trans, alpha, A)</code> </dt> <dd>
<p>Methods for complex arrays only. Returns either the upper triangle or the lower triangle, according to <code>uplo</code> (‘U’ or ‘L’), of <code>alpha*A*A'</code> or <code>alpha*A'*A</code>, according to <code>trans</code> (‘N’ or ‘T’).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gbmv!">
<code>gbmv!(trans, m, kl, ku, alpha, A, x, beta, y)</code> </dt> <dd>
<p>Update vector <code>y</code> as <code>alpha*A*x + beta*y</code> or <code>alpha*A'*x + beta*y</code> according to <code>trans</code> (‘N’ or ‘T’). The matrix <code>A</code> is a general band matrix of dimension <code>m</code> by <code>size(A,2)</code> with <code>kl</code> sub-diagonals and <code>ku</code> super-diagonals. Returns the updated <code>y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gbmv">
<code>gbmv(trans, m, kl, ku, alpha, A, x, beta, y)</code> </dt> <dd>
<p>Returns <code>alpha*A*x</code> or <code>alpha*A'*x</code> according to <code>trans</code> (‘N’ or ‘T’). The matrix <code>A</code> is a general band matrix of dimension <code>m</code> by <code>size(A,2)</code> with <code>kl</code> sub-diagonals and <code>ku</code> super-diagonals.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.sbmv!">
<code>sbmv!(uplo, k, alpha, A, x, beta, y)</code> </dt> <dd>
<p>Update vector <code>y</code> as <code>alpha*A*x + beta*y</code> where <code>A</code> is a a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>. The storage layout for <code>A</code> is described the reference BLAS module, level-2 BLAS at &lt;<a class="reference external" href="http://www.netlib.org/lapack/explore-html/" target="_blank">http://www.netlib.org/lapack/explore-html/</a>&gt;.</p> <p>Returns the updated <code>y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.sbmv">
<code>sbmv(uplo, k, alpha, A, x)</code> </dt> <dd>
<p>Returns <code>alpha*A*x</code> where <code>A</code> is a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>sbmv(uplo, k, A, x)</code> </dt> <dd>
<p>Returns <code>A*x</code> where <code>A</code> is a symmetric band matrix of order <code>size(A,2)</code> with <code>k</code> super-diagonals stored in the argument <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gemm!">
<code>gemm!(tA, tB, alpha, A, B, beta, C)</code> </dt> <dd>
<p>Update <code>C</code> as <code>alpha*A*B + beta*C</code> or the other three variants according to <code>tA</code> (transpose <code>A</code>) and <code>tB</code>. Returns the updated <code>C</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gemm">
<code>gemm(tA, tB, alpha, A, B)</code> </dt> <dd>
<p>Returns <code>alpha*A*B</code> or the other three variants according to <code>tA</code> (transpose <code>A</code>) and <code>tB</code>.</p> </dd>
</dl> <dl class="function"> <dt>
<code>gemm(tA, tB, A, B)</code> </dt> <dd>
<p>Returns <code>A*B</code> or the other three variants according to <code>tA</code> (transpose <code>A</code>) and <code>tB</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gemv!">
<code>gemv!(tA, alpha, A, x, beta, y)</code> </dt> <dd>
<p>Update the vector <code>y</code> as <code>alpha*A*x + beta*y</code> or <code>alpha*A'x + beta*y</code> according to <code>tA</code> (transpose <code>A</code>). Returns the updated <code>y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.gemv">
<code>gemv(tA, alpha, A, x)</code> </dt> <dd>
<p>Returns <code>alpha*A*x</code> or <code>alpha*A'x</code> according to <code>tA</code> (transpose <code>A</code>).</p> </dd>
</dl> <dl class="function"> <dt>
<code>gemv(tA, A, x)</code> </dt> <dd>
<p>Returns <code>A*x</code> or <code>A'x</code> according to <code>tA</code> (transpose <code>A</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.symm!">
<code>symm!(side, ul, alpha, A, B, beta, C)</code> </dt> <dd>
<p>Update <code>C</code> as <code>alpha*A*B + beta*C</code> or <code>alpha*B*A + beta*C</code> according to <code>side</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used. Returns the updated <code>C</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.symm">
<code>symm(side, ul, alpha, A, B)</code> </dt> <dd>
<p>Returns <code>alpha*A*B</code> or <code>alpha*B*A</code> according to <code>side</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used.</p> </dd>
</dl> <dl class="function"> <dt>
<code>symm(side, ul, A, B)</code> </dt> <dd>
<p>Returns <code>A*B</code> or <code>B*A</code> according to <code>side</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used.</p> </dd>
</dl> <dl class="function"> <dt>
<code>symm(tA, tB, alpha, A, B)</code> </dt> <dd>
<p>Returns <code>alpha*A*B</code> or the other three variants according to <code>tA</code> (transpose <code>A</code>) and <code>tB</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.symv!">
<code>symv!(ul, alpha, A, x, beta, y)</code> </dt> <dd>
<p>Update the vector <code>y</code> as <code>alpha*A*x + beta*y</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used. Returns the updated <code>y</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.symv">
<code>symv(ul, alpha, A, x)</code> </dt> <dd>
<p>Returns <code>alpha*A*x</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used.</p> </dd>
</dl> <dl class="function"> <dt>
<code>symv(ul, A, x)</code> </dt> <dd>
<p>Returns <code>A*x</code>. <code>A</code> is assumed to be symmetric. Only the <code>ul</code> triangle of <code>A</code> is used.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trmm!">
<code>trmm!(side, ul, tA, dA, alpha, A, B)</code> </dt> <dd>
<p>Update <code>B</code> as <code>alpha*A*B</code> or one of the other three variants determined by <code>side</code> (<code>A</code> on left or right) and <code>tA</code> (transpose <code>A</code>). Only the <code>ul</code> triangle of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones). Returns the updated <code>B</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trmm">
<code>trmm(side, ul, tA, dA, alpha, A, B)</code> </dt> <dd>
<p>Returns <code>alpha*A*B</code> or one of the other three variants determined by <code>side</code> (<code>A</code> on left or right) and <code>tA</code> (transpose <code>A</code>). Only the <code>ul</code> triangle of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trsm!">
<code>trsm!(side, ul, tA, dA, alpha, A, B)</code> </dt> <dd>
<p>Overwrite <code>B</code> with the solution to <code>A*X = alpha*B</code> or one of the other three variants determined by <code>side</code> (<code>A</code> on left or right of <code>X</code>) and <code>tA</code> (transpose <code>A</code>). Only the <code>ul</code> triangle of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones). Returns the updated <code>B</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trsm">
<code>trsm(side, ul, tA, dA, alpha, A, B)</code> </dt> <dd>
<p>Returns the solution to <code>A*X = alpha*B</code> or one of the other three variants determined by <code>side</code> (<code>A</code> on left or right of <code>X</code>) and <code>tA</code> (transpose <code>A</code>). Only the <code>ul</code> triangle of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trmv!">
<code>trmv!(ul, tA, dA, A, b)</code> </dt> <dd>
<p>Returns <code>op(A)*b</code>, where <code>op</code> is determined by <code>tA</code> (<code>N</code> for identity, <code>T</code> for transpose <code>A</code>, and <code>C</code> for conjugate transpose <code>A</code>). Only the <code>ul</code> triangle (<code>U</code> for upper, <code>L</code> for lower) of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones if <code>U</code>, or non-unit if <code>N</code>). The multiplication occurs in-place on <code>b</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trmv">
<code>trmv(ul, tA, dA, A, b)</code> </dt> <dd>
<p>Returns <code>op(A)*b</code>, where <code>op</code> is determined by <code>tA</code> (<code>N</code> for identity, <code>T</code> for transpose <code>A</code>, and <code>C</code> for conjugate transpose <code>A</code>). Only the <code>ul</code> triangle (<code>U</code> for upper, <code>L</code> for lower) of <code>A</code> is used. <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones if <code>U</code>, or non-unit if <code>N</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trsv!">
<code>trsv!(ul, tA, dA, A, b)</code> </dt> <dd>
<p>Overwrite <code>b</code> with the solution to <code>A*x = b</code> or one of the other two variants determined by <code>tA</code> (transpose <code>A</code>) and <code>ul</code> (triangle of <code>A</code> used). <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones). Returns the updated <code>b</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.trsv">
<code>trsv(ul, tA, dA, A, b)</code> </dt> <dd>
<p>Returns the solution to <code>A*x = b</code> or one of the other two variants determined by <code>tA</code> (transpose <code>A</code>) and <code>ul</code> (triangle of <code>A</code> is used.) <code>dA</code> indicates if <code>A</code> is unit-triangular (the diagonal is assumed to be all ones).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.BLAS.set_num_threads">
<code>set_num_threads(n)</code> </dt> <dd>
<p>Set the number of threads the BLAS library should use.</p> </dd>
</dl> <dl class="data"> <dt id="Base.LinAlg.BLAS.I">
<code>I</code> </dt> <dd>
<p>An object of type <code>UniformScaling</code>, representing an identity matrix of any size.</p> </dd>
</dl>   <h2 id="lapack-functions">LAPACK Functions</h2> <p id="module-Base.LinAlg.LAPACK"><a class="reference internal" href="#module-Base.LinAlg.LAPACK" title="Base.LinAlg.LAPACK"><code>Base.LinAlg.LAPACK</code></a> provides wrappers for some of the LAPACK functions for linear algebra. Those functions that overwrite one of the input arrays have names ending in <code>'!'</code>.</p> <p>Usually a function has 4 methods defined, one each for <code>Float64</code>, <code>Float32</code>, <code>Complex128</code> and <code>Complex64</code> arrays.</p> <p>Note that the LAPACK API provided by Julia can and will change in the future. Since this API is not user-facing, there is no commitment to support/deprecate this specific set of functions in future releases.</p> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gbtrf!">
<code>gbtrf!(kl, ku, m, AB) → (AB, ipiv)</code> </dt> <dd>
<p>Compute the LU factorization of a banded matrix <code>AB</code>. <code>kl</code> is the first subdiagonal containing a nonzero band, <code>ku</code> is the last superdiagonal containing one, and <code>m</code> is the first dimension of the matrix <code>AB</code>. Returns the LU factorization in-place and <code>ipiv</code>, the vector of pivots used.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gbtrs!">
<code>gbtrs!(trans, kl, ku, m, AB, ipiv, B)</code> </dt> <dd>
<p>Solve the equation <code>AB * X = B</code>. <code>trans</code> determines the orientation of <code>AB</code>. It may be <code>N</code> (no transpose), <code>T</code> (transpose), or <code>C</code> (conjugate transpose). <code>kl</code> is the first subdiagonal containing a nonzero band, <code>ku</code> is the last superdiagonal containing one, and <code>m</code> is the first dimension of the matrix <code>AB</code>. <code>ipiv</code> is the vector of pivots returned from <code>gbtrf!</code>. Returns the vector or matrix <code>X</code>, overwriting <code>B</code> in-place.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gebal!">
<code>gebal!(job, A) → (ilo, ihi, scale)</code> </dt> <dd>
<p>Balance the matrix <code>A</code> before computing its eigensystem or Schur factorization. <code>job</code> can be one of <code>N</code> (<code>A</code> will not be permuted or scaled), <code>P</code> (<code>A</code> will only be permuted), <code>S</code> (<code>A</code> will only be scaled), or <code>B</code> (<code>A</code> will be both permuted and scaled). Modifies <code>A</code> in-place and returns <code>ilo</code>, <code>ihi</code>, and <code>scale</code>. If permuting was turned on, <code>A[i,j] = 0</code> if <code>j &gt; i</code> and <code>1 &lt; j &lt; ilo</code> or <code>j &gt; ihi</code>. <code>scale</code> contains information about the scaling/permutations performed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gebak!">
<code>gebak!(job, side, ilo, ihi, scale, V)</code> </dt> <dd>
<p>Transform the eigenvectors <code>V</code> of a matrix balanced using <code>gebal!</code> to the unscaled/unpermuted eigenvectors of the original matrix. Modifies <code>V</code> in-place. <code>side</code> can be <code>L</code> (left eigenvectors are transformed) or <code>R</code> (right eigenvectors are transformed).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gebrd!">
<code>gebrd!(A) → (A, d, e, tauq, taup)</code> </dt> <dd>
<p>Reduce <code>A</code> in-place to bidiagonal form <code>A = QBP'</code>. Returns <code>A</code>, containing the bidiagonal matrix <code>B</code>; <code>d</code>, containing the diagonal elements of <code>B</code>; <code>e</code>, containing the off-diagonal elements of <code>B</code>; <code>tauq</code>, containing the elementary reflectors representing <code>Q</code>; and <code>taup</code>, containing the elementary reflectors representing <code>P</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gelqf!">
<code>gelqf!(A, tau)</code> </dt> <dd>
<p>Compute the <code>LQ</code> factorization of <code>A</code>, <code>A = LQ</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>tau</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>gelqf!(A) → (A, tau)</code> </dt> <dd>
<p>Compute the <code>LQ</code> factorization of <code>A</code>, <code>A = LQ</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geqlf!">
<code>geqlf!(A, tau)</code> </dt> <dd>
<p>Compute the <code>QL</code> factorization of <code>A</code>, <code>A = QL</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>tau</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqlf!(A) → (A, tau)</code> </dt> <dd>
<p>Compute the <code>QL</code> factorization of <code>A</code>, <code>A = QL</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geqrf!">
<code>geqrf!(A, tau)</code> </dt> <dd>
<p>Compute the <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>tau</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqrf!(A) → (A, tau)</code> </dt> <dd>
<p>Compute the <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geqp3!">
<code>geqp3!(A, jpvt, tau)</code> </dt> <dd>
<p>Compute the pivoted <code>QR</code> factorization of <code>A</code>, <code>AP = QR</code> using BLAS level 3. <code>P</code> is a pivoting matrix, represented by <code>jpvt</code>. <code>tau</code> stores the elementary reflectors. <code>jpvt</code> must have length length greater than or equal to <code>n</code> if <code>A</code> is an <code>(m x n)</code> matrix. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p> <p><code>A</code>, <code>jpvt</code>, and <code>tau</code> are modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqp3!(A, jpvt) → (A, jpvt, tau)</code> </dt> <dd>
<p>Compute the pivoted <code>QR</code> factorization of <code>A</code>, <code>AP = QR</code> using BLAS level 3. <code>P</code> is a pivoting matrix, represented by <code>jpvt</code>. <code>jpvt</code> must have length greater than or equal to <code>n</code> if <code>A</code> is an <code>(m x n)</code> matrix.</p> <p>Returns <code>A</code> and <code>jpvt</code>, modified in-place, and <code>tau</code>, which stores the elementary reflectors.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqp3!(A) → (A, jpvt, tau)</code> </dt> <dd>
<p>Compute the pivoted <code>QR</code> factorization of <code>A</code>, <code>AP = QR</code> using BLAS level 3.</p> <p>Returns <code>A</code>, modified in-place, <code>jpvt</code>, which represents the pivoting matrix <code>P</code>, and <code>tau</code>, which stores the elementary reflectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gerqf!">
<code>gerqf!(A, tau)</code> </dt> <dd>
<p>Compute the <code>RQ</code> factorization of <code>A</code>, <code>A = RQ</code>. <code>tau</code> contains scalars which parameterize the elementary reflectors of the factorization. <code>tau</code> must have length greater than or equal to the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>tau</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>gerqf!(A) → (A, tau)</code> </dt> <dd>
<p>Compute the <code>RQ</code> factorization of <code>A</code>, <code>A = RQ</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>tau</code>, which contains scalars which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geqrt!">
<code>geqrt!(A, T)</code> </dt> <dd>
<p>Compute the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>T</code> contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization. The first dimension of <code>T</code> sets the block size and it must be between 1 and <code>n</code>. The second dimension of <code>T</code> must equal the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>T</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqrt!(A, nb) → (A, T)</code> </dt> <dd>
<p>Compute the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>nb</code> sets the block size and it must be between 1 and <code>n</code>, the second dimension of <code>A</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>T</code>, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geqrt3!">
<code>geqrt3!(A, T)</code> </dt> <dd>
<p>Recursively computes the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>. <code>T</code> contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization. The first dimension of <code>T</code> sets the block size and it must be between 1 and <code>n</code>. The second dimension of <code>T</code> must equal the smallest dimension of <code>A</code>.</p> <p>Returns <code>A</code> and <code>T</code> modified in-place.</p> </dd>
</dl> <dl class="function"> <dt>
<code>geqrt3!(A) → (A, T)</code> </dt> <dd>
<p>Recursively computes the blocked <code>QR</code> factorization of <code>A</code>, <code>A = QR</code>.</p> <p>Returns <code>A</code>, modified in-place, and <code>T</code>, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.getrf!">
<code>getrf!(A) → (A, ipiv, info)</code> </dt> <dd>
<p>Compute the pivoted <code>LU</code> factorization of <code>A</code>, <code>A = LU</code>.</p> <p>Returns <code>A</code>, modified in-place, <code>ipiv</code>, the pivoting information, and an <code>info</code> code which indicates success (<code>info = 0</code>), a singular value in <code>U</code> (<code>info = i</code>, in which case <code>U[i,i]</code> is singular), or an error code (<code>info &lt; 0</code>).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.tzrzf!">
<code>tzrzf!(A) → (A, tau)</code> </dt> <dd>
<p>Transforms the upper trapezoidal matrix <code>A</code> to upper triangular form in-place. Returns <code>A</code> and <code>tau</code>, the scalar parameters for the elementary reflectors of the transformation.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ormrz!">
<code>ormrz!(side, trans, A, tau, C)</code> </dt> <dd>
<p>Multiplies the matrix <code>C</code> by <code>Q</code> from the transformation supplied by <code>tzrzf!</code>. Depending on <code>side</code> or <code>trans</code> the multiplication can be left-sided (<code>side = L, Q*C</code>) or right-sided (<code>side = R, C*Q</code>) and <code>Q</code> can be unmodified (<code>trans = N</code>), transposed (<code>trans = T</code>), or conjugate transposed (<code>trans = C</code>). Returns matrix <code>C</code> which is modified in-place with the result of the multiplication.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gels!">
<code>gels!(trans, A, B) → (F, B, ssr)</code> </dt> <dd>
<p>Solves the linear equation <code>A * X = B</code>, <code>A.' * X =B</code>, or <code>A' * X = B</code> using a QR or LQ factorization. Modifies the matrix/vector <code>B</code> in place with the solution. <code>A</code> is overwritten with its <code>QR</code> or <code>LQ</code> factorization. <code>trans</code> may be one of <code>N</code> (no modification), <code>T</code> (transpose), or <code>C</code> (conjugate transpose). <code>gels!</code> searches for the minimum norm/least squares solution. <code>A</code> may be under or over determined. The solution is returned in <code>B</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gesv!">
<code>gesv!(A, B) → (B, A, ipiv)</code> </dt> <dd>
<p>Solves the linear equation <code>A * X = B</code> where <code>A</code> is a square matrix using the <code>LU</code> factorization of <code>A</code>. <code>A</code> is overwritten with its <code>LU</code> factorization and <code>B</code> is overwritten with the solution <code>X</code>. <code>ipiv</code> contains the pivoting information for the <code>LU</code> factorization of <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.getrs!">
<code>getrs!(trans, A, ipiv, B)</code> </dt> <dd>
<p>Solves the linear equation <code>A * X = B</code>, <code>A.' * X =B</code>, or <code>A' * X = B</code> for square <code>A</code>. Modifies the matrix/vector <code>B</code> in place with the solution. <code>A</code> is the <code>LU</code> factorization from <code>getrf!</code>, with <code>ipiv</code> the pivoting information. <code>trans</code> may be one of <code>N</code> (no modification), <code>T</code> (transpose), or <code>C</code> (conjugate transpose).</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.getri!">
<code>getri!(A, ipiv)</code> </dt> <dd>
<p>Computes the inverse of <code>A</code>, using its <code>LU</code> factorization found by <code>getrf!</code>. <code>ipiv</code> is the pivot information output and <code>A</code> contains the <code>LU</code> factorization of <code>getrf!</code>. <code>A</code> is overwritten with its inverse.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gesvx!">
<code>gesvx!(fact, trans, A, AF, ipiv, equed, R, C, B) → (X, equed, R, C, B, rcond, ferr, berr, work)</code> </dt> <dd>
<p>Solves the linear equation <code>A * X = B</code> (<code>trans = N</code>), <code>A.' * X =B</code> (<code>trans = T</code>), or <code>A' * X = B</code> (<code>trans = C</code>) using the <code>LU</code> factorization of <code>A</code>. <code>fact</code> may be <code>E</code>, in which case <code>A</code> will be equilibrated and copied to <code>AF</code>; <code>F</code>, in which case <code>AF</code> and <code>ipiv</code> from a previous <code>LU</code> factorization are inputs; or <code>N</code>, in which case <code>A</code> will be copied to <code>AF</code> and then factored. If <code>fact = F</code>, <code>equed</code> may be <code>N</code>, meaning <code>A</code> has not been equilibrated; <code>R</code>, meaning <code>A</code> was multiplied by <code>diagm(R)</code> from the left; <code>C</code>, meaning <code>A</code> was multiplied by <code>diagm(C)</code> from the right; or <code>B</code>, meaning <code>A</code> was multiplied by <code>diagm(R)</code> from the left and <code>diagm(C)</code> from the right. If <code>fact = F</code> and <code>equed = R</code> or <code>B</code> the elements of <code>R</code> must all be positive. If <code>fact = F</code> and <code>equed = C</code> or <code>B</code> the elements of <code>C</code> must all be positive.</p> <p>Returns the solution <code>X</code>; <code>equed</code>, which is an output if <code>fact</code> is not <code>N</code>, and describes the equilibration that was performed; <code>R</code>, the row equilibration diagonal; <code>C</code>, the column equilibration diagonal; <code>B</code>, which may be overwritten with its equilibrated form <code>diagm(R)*B</code> (if <code>trans = N</code> and <code>equed = R,B</code>) or <code>diagm(C)*B</code> (if <code>trans = T,C</code> and <code>equed = C,B</code>); <code>rcond</code>, the reciprocal condition number of <code>A</code> after equilbrating; <code>ferr</code>, the forward error bound for each solution vector in <code>X</code>; <code>berr</code>, the forward error bound for each solution vector in <code>X</code>; and <code>work</code>, the reciprocal pivot growth factor.</p> </dd>
</dl> <dl class="function"> <dt>
<code>gesvx!(A, B)</code> </dt> <dd>
<p>The no-equilibration, no-transpose simplification of <code>gesvx!</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gelsd!">
<code>gelsd!(A, B, rcond) → (B, rnk)</code> </dt> <dd>
<p>Computes the least norm solution of <code>A * X = B</code> by finding the <code>SVD</code> factorization of <code>A</code>, then dividing-and-conquering the problem. <code>B</code> is overwritten with the solution <code>X</code>. Singular values below <code>rcond</code> will be treated as zero. Returns the solution in <code>B</code> and the effective rank of <code>A</code> in <code>rnk</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gelsy!">
<code>gelsy!(A, B, rcond) → (B, rnk)</code> </dt> <dd>
<p>Computes the least norm solution of <code>A * X = B</code> by finding the full <code>QR</code> factorization of <code>A</code>, then dividing-and-conquering the problem. <code>B</code> is overwritten with the solution <code>X</code>. Singular values below <code>rcond</code> will be treated as zero. Returns the solution in <code>B</code> and the effective rank of <code>A</code> in <code>rnk</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gglse!">
<code>gglse!(A, c, B, d) → (X,res)</code> </dt> <dd>
<p>Solves the equation <code>A * x = c</code> where <code>x</code> is subject to the equality constraint <code>B * x = d</code>. Uses the formula <code>||c - A*x||^2 = 0</code> to solve. Returns <code>X</code> and the residual sum-of-squares.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geev!">
<code>geev!(jobvl, jobvr, A) → (W, VL, VR)</code> </dt> <dd>
<p>Finds the eigensystem of <code>A</code>. If <code>jobvl = N</code>, the left eigenvectors of <code>A</code> aren’t computed. If <code>jobvr = N</code>, the right eigenvectors of <code>A</code> aren’t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed. Returns the eigenvalues in <code>W</code>, the right eigenvectors in <code>VR</code>, and the left eigenvectors in <code>VL</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gesdd!">
<code>gesdd!(job, A) → (U, S, VT)</code> </dt> <dd>
<p>Finds the singular value decomposition of <code>A</code>, <code>A = U * S * V'</code>, using a divide and conquer approach. If <code>job = A</code>, all the columns of <code>U</code> and the rows of <code>V'</code> are computed. If <code>job = N</code>, no columns of <code>U</code> or rows of <code>V'</code> are computed. If <code>job = O</code>, <code>A</code> is overwritten with the columns of (thin) <code>U</code> and the rows of (thin) <code>V'</code>. If <code>job = S</code>, the columns of (thin) <code>U</code> and the rows of (thin) <code>V'</code> are computed and returned separately.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gesvd!">
<code>gesvd!(jobu, jobvt, A) → (U, S, VT)</code> </dt> <dd>
<p>Finds the singular value decomposition of <code>A</code>, <code>A = U * S * V'</code>. If <code>jobu = A</code>, all the columns of <code>U</code> are computed. If <code>jobvt = A</code> all the rows of <code>V'</code> are computed. If <code>jobu = N</code>, no columns of <code>U</code> are computed. If <code>jobvt = N</code> no rows of <code>V'</code> are computed. If <code>jobu = O</code>, <code>A</code> is overwritten with the columns of (thin) <code>U</code>. If <code>jobvt = O</code>, <code>A</code> is overwritten with the rows of (thin) <code>V'</code>. If <code>jobu = S</code>, the columns of (thin) <code>U</code> are computed and returned separately. If <code>jobvt = S</code> the rows of (thin) <code>V'</code> are computed and returned separately. <code>jobu</code> and <code>jobvt</code> can’t both be <code>O</code>.</p> <p>Returns <code>U</code>, <code>S</code>, and <code>Vt</code>, where <code>S</code> are the singular values of <code>A</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ggsvd!">
<code>ggsvd!(jobu, jobv, jobq, A, B) → (U, V, Q, alpha, beta, k, l, R)</code> </dt> <dd>
<p>Finds the generalized singular value decomposition of <code>A</code> and <code>B</code>, <code>U'*A*Q = D1*R</code> and <code>V'*B*Q = D2*R</code>. <code>D1</code> has <code>alpha</code> on its diagonal and <code>D2</code> has <code>beta</code> on its diagonal. If <code>jobu = U</code>, the orthogonal/unitary matrix <code>U</code> is computed. If <code>jobv = V</code> the orthogonal/unitary matrix <code>V</code> is computed. If <code>jobq = Q</code>, the orthogonal/unitary matrix <code>Q</code> is computed. If <code>jobu</code>, <code>jobv</code> or <code>jobq</code> is <code>N</code>, that matrix is not computed. This function is only available in LAPACK versions prior to 3.6.0.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ggsvd3!">
<code>ggsvd3!(jobu, jobv, jobq, A, B) → (U, V, Q, alpha, beta, k, l, R)</code> </dt> <dd>
<p>Finds the generalized singular value decomposition of <code>A</code> and <code>B</code>, <code>U'*A*Q = D1*R</code> and <code>V'*B*Q = D2*R</code>. <code>D1</code> has <code>alpha</code> on its diagonal and <code>D2</code> has <code>beta</code> on its diagonal. If <code>jobu = U</code>, the orthogonal/unitary matrix <code>U</code> is computed. If <code>jobv = V</code> the orthogonal/unitary matrix <code>V</code> is computed. If <code>jobq = Q</code>, the orthogonal/unitary matrix <code>Q</code> is computed. If <code>jobu</code>, <code>jobv</code>, or <code>jobq</code> is <code>N</code>, that matrix is not computed. This function requires LAPACK 3.6.0.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.geevx!">
<code>geevx!(balanc, jobvl, jobvr, sense, A) → (A, w, VL, VR, ilo, ihi, scale, abnrm, rconde, rcondv)</code> </dt> <dd>
<p>Finds the eigensystem of <code>A</code> with matrix balancing. If <code>jobvl = N</code>, the left eigenvectors of <code>A</code> aren’t computed. If <code>jobvr = N</code>, the right eigenvectors of <code>A</code> aren’t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed. If <code>balanc = N</code>, no balancing is performed. If <code>balanc = P</code>, <code>A</code> is permuted but not scaled. If <code>balanc = S</code>, <code>A</code> is scaled but not permuted. If <code>balanc = B</code>, <code>A</code> is permuted and scaled. If <code>sense = N</code>, no reciprocal condition numbers are computed. If <code>sense = E</code>, reciprocal condition numbers are computed for the eigenvalues only. If <code>sense = V</code>, reciprocal condition numbers are computed for the right eigenvectors only. If <code>sense = B</code>, reciprocal condition numbers are computed for the right eigenvectors and the eigenvectors. If <code>sense = E,B</code>, the right and left eigenvectors must be computed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ggev!">
<code>ggev!(jobvl, jobvr, A, B) → (alpha, beta, vl, vr)</code> </dt> <dd>
<p>Finds the generalized eigendecomposition of <code>A</code> and <code>B</code>. If <code>jobvl = N</code>, the left eigenvectors aren’t computed. If <code>jobvr = N</code>, the right eigenvectors aren’t computed. If <code>jobvl = V</code> or <code>jobvr = V</code>, the corresponding eigenvectors are computed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gtsv!">
<code>gtsv!(dl, d, du, B)</code> </dt> <dd>
<p>Solves the equation <code>A * X = B</code> where <code>A</code> is a tridiagonal matrix with <code>dl</code> on the subdiagonal, <code>d</code> on the diagonal, and <code>du</code> on the superdiagonal.</p> <p>Overwrites <code>B</code> with the solution <code>X</code> and returns it.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gttrf!">
<code>gttrf!(dl, d, du) → (dl, d, du, du2, ipiv)</code> </dt> <dd>
<p>Finds the <code>LU</code> factorization of a tridiagonal matrix with <code>dl</code> on the subdiagonal, <code>d</code> on the diagonal, and <code>du</code> on the superdiagonal.</p> <p>Modifies <code>dl</code>, <code>d</code>, and <code>du</code> in-place and returns them and the second superdiagonal <code>du2</code> and the pivoting vector <code>ipiv</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gttrs!">
<code>gttrs!(trans, dl, d, du, du2, ipiv, B)</code> </dt> <dd>
<p>Solves the equation <code>A * X = B</code> (<code>trans = N</code>), <code>A.' * X = B</code> (<code>trans = T</code>), or <code>A' * X = B</code> (<code>trans = C</code>) using the <code>LU</code> factorization computed by <code>gttrf!</code>. <code>B</code> is overwritten with the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.orglq!">
<code>orglq!(A, tau, k = length(tau))</code> </dt> <dd>
<p>Explicitly finds the matrix <code>Q</code> of a <code>LQ</code> factorization after calling <code>gelqf!</code> on <code>A</code>. Uses the output of <code>gelqf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.orgqr!">
<code>orgqr!(A, tau, k = length(tau))</code> </dt> <dd>
<p>Explicitly finds the matrix <code>Q</code> of a <code>QR</code> factorization after calling <code>geqrf!</code> on <code>A</code>. Uses the output of <code>geqrf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.orgql!">
<code>orgql!(A, tau, k = length(tau))</code> </dt> <dd>
<p>Explicitly finds the matrix <code>Q</code> of a <code>QL</code> factorization after calling <code>geqlf!</code> on <code>A</code>. Uses the output of <code>geqlf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.orgrq!">
<code>orgrq!(A, tau, k = length(tau))</code> </dt> <dd>
<p>Explicitly finds the matrix <code>Q</code> of a <code>RQ</code> factorization after calling <code>gerqf!</code> on <code>A</code>. Uses the output of <code>gerqf!</code>. <code>A</code> is overwritten by <code>Q</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ormlq!">
<code>ormlq!(side, trans, A, tau, C)</code> </dt> <dd>
<p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>Q.' * C</code> (<code>trans = T</code>), <code>Q' * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>LQ</code> factorization of <code>A</code> computed using <code>gelqf!</code>. <code>C</code> is overwritten.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ormqr!">
<code>ormqr!(side, trans, A, tau, C)</code> </dt> <dd>
<p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>Q.' * C</code> (<code>trans = T</code>), <code>Q' * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QR</code> factorization of <code>A</code> computed using <code>geqrf!</code>. <code>C</code> is overwritten.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ormql!">
<code>ormql!(side, trans, A, tau, C)</code> </dt> <dd>
<p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>Q.' * C</code> (<code>trans = T</code>), <code>Q' * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QL</code> factorization of <code>A</code> computed using <code>geqlf!</code>. <code>C</code> is overwritten.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ormrq!">
<code>ormrq!(side, trans, A, tau, C)</code> </dt> <dd>
<p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>Q.' * C</code> (<code>trans = T</code>), <code>Q' * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>RQ</code> factorization of <code>A</code> computed using <code>gerqf!</code>. <code>C</code> is overwritten.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gemqrt!">
<code>gemqrt!(side, trans, V, T, C)</code> </dt> <dd>
<p>Computes <code>Q * C</code> (<code>trans = N</code>), <code>Q.' * C</code> (<code>trans = T</code>), <code>Q' * C</code> (<code>trans = C</code>) for <code>side = L</code> or the equivalent right-sided multiplication for <code>side = R</code> using <code>Q</code> from a <code>QR</code> factorization of <code>A</code> computed using <code>geqrt!</code>. <code>C</code> is overwritten.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.posv!">
<code>posv!(uplo, A, B) → (A, B)</code> </dt> <dd>
<p>Finds the solution to <code>A * X = B</code> where <code>A</code> is a symmetric or Hermitian positive definite matrix. If <code>uplo = U</code> the upper Cholesky decomposition of <code>A</code> is computed. If <code>uplo = L</code> the lower Cholesky decomposition of <code>A</code> is computed. <code>A</code> is overwritten by its Cholesky decomposition. <code>B</code> is overwritten with the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.potrf!">
<code>potrf!(uplo, A)</code> </dt> <dd>
<p>Computes the Cholesky (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) decomposition of positive-definite matrix <code>A</code>. <code>A</code> is overwritten and returned with an info code.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.potri!">
<code>potri!(uplo, A)</code> </dt> <dd>
<p>Computes the inverse of positive-definite matrix <code>A</code> after calling <code>potrf!</code> to find its (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) Cholesky decomposition.</p> <p><code>A</code> is overwritten by its inverse and returned.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.potrs!">
<code>potrs!(uplo, A, B)</code> </dt> <dd>
<p>Finds the solution to <code>A * X = B</code> where <code>A</code> is a symmetric or Hermitian positive definite matrix whose Cholesky decomposition was computed by <code>potrf!</code>. If <code>uplo = U</code> the upper Cholesky decomposition of <code>A</code> was computed. If <code>uplo = L</code> the lower Cholesky decomposition of <code>A</code> was computed. <code>B</code> is overwritten with the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.pstrf!">
<code>pstrf!(uplo, A, tol) → (A, piv, rank, info)</code> </dt> <dd>
<p>Computes the (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) pivoted Cholesky decomposition of positive-definite matrix <code>A</code> with a user-set tolerance <code>tol</code>. <code>A</code> is overwritten by its Cholesky decomposition.</p> <p>Returns <code>A</code>, the pivots <code>piv</code>, the rank of <code>A</code>, and an <code>info</code> code. If <code>info = 0</code>, the factorization succeeded. If <code>info = i &gt; 0</code>, then <code>A</code> is indefinite or rank-deficient.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.ptsv!">
<code>ptsv!(D, E, B)</code> </dt> <dd>
<p>Solves <code>A * X = B</code> for positive-definite tridiagonal <code>A</code>. <code>D</code> is the diagonal of <code>A</code> and <code>E</code> is the off-diagonal. <code>B</code> is overwritten with the solution <code>X</code> and returned.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.pttrf!">
<code>pttrf!(D, E)</code> </dt> <dd>
<p>Computes the LDLt factorization of a positive-definite tridiagonal matrix with <code>D</code> as diagonal and <code>E</code> as off-diagonal. <code>D</code> and <code>E</code> are overwritten and returned.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.pttrs!">
<code>pttrs!(D, E, B)</code> </dt> <dd>
<p>Solves <code>A * X = B</code> for positive-definite tridiagonal <code>A</code> with diagonal <code>D</code> and off-diagonal <code>E</code> after computing <code>A</code>‘s LDLt factorization using <code>pttrf!</code>. <code>B</code> is overwritten with the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trtri!">
<code>trtri!(uplo, diag, A)</code> </dt> <dd>
<p>Finds the inverse of (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>A</code> is overwritten with its inverse.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trtrs!">
<code>trtrs!(uplo, trans, diag, A, B)</code> </dt> <dd>
<p>Solves <code>A * X = B</code> (<code>trans = N</code>), <code>A.' * X = B</code> (<code>trans = T</code>), or <code>A' * X = B</code> (<code>trans = C</code>) for (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>B</code> is overwritten with the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trcon!">
<code>trcon!(norm, uplo, diag, A)</code> </dt> <dd>
<p>Finds the reciprocal condition number of (upper if <code>uplo = U</code>, lower if <code>uplo = L</code>) triangular matrix <code>A</code>. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. If <code>norm = I</code>, the condition number is found in the infinity norm. If <code>norm = O</code> or <code>1</code>, the condition number is found in the one norm.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trevc!">
<code>trevc!(side, howmny, select, T, VL = similar(T), VR = similar(T))</code> </dt> <dd>
<p>Finds the eigensystem of an upper triangular matrix <code>T</code>. If <code>side = R</code>, the right eigenvectors are computed. If <code>side = L</code>, the left eigenvectors are computed. If <code>side = B</code>, both sets are computed. If <code>howmny = A</code>, all eigenvectors are found. If <code>howmny = B</code>, all eigenvectors are found and backtransformed using <code>VL</code> and <code>VR</code>. If <code>howmny = S</code>, only the eigenvectors corresponding to the values in <code>select</code> are computed.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trrfs!">
<code>trrfs!(uplo, trans, diag, A, B, X, Ferr, Berr) → (Ferr, Berr)</code> </dt> <dd>
<p>Estimates the error in the solution to <code>A * X = B</code> (<code>trans = N</code>), <code>A.' * X = B</code> (<code>trans = T</code>), <code>A' * X = B</code> (<code>trans = C</code>) for <code>side = L</code>, or the equivalent equations a right-handed <code>side = R</code> <code>X * A</code> after computing <code>X</code> using <code>trtrs!</code>. If <code>uplo = U</code>, <code>A</code> is upper triangular. If <code>uplo = L</code>, <code>A</code> is lower triangular. If <code>diag = N</code>, <code>A</code> has non-unit diagonal elements. If <code>diag = U</code>, all diagonal elements of <code>A</code> are one. <code>Ferr</code> and <code>Berr</code> are optional inputs. <code>Ferr</code> is the forward error and <code>Berr</code> is the backward error, each component-wise.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.stev!">
<code>stev!(job, dv, ev) → (dv, Zmat)</code> </dt> <dd>
<p>Computes the eigensystem for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>job = N</code> only the eigenvalues are found and returned in <code>dv</code>. If <code>job = V</code> then the eigenvectors are also found and returned in <code>Zmat</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.stebz!">
<code>stebz!(range, order, vl, vu, il, iu, abstol, dv, ev) → (dv, iblock, isplit)</code> </dt> <dd>
<p>Computes the eigenvalues for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. If <code>order = B</code>, eigvalues are ordered within a block. If <code>order = E</code>, they are ordered across all the blocks. <code>abstol</code> can be set as a tolerance for convergence.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.stegr!">
<code>stegr!(jobz, range, dv, ev, vl, vu, il, iu) → (w, Z)</code> </dt> <dd>
<p>Computes the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev</code> as off-diagonal. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. The eigenvalues are returned in <code>w</code> and the eigenvectors in <code>Z</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.stein!">
<code>stein!(dv, ev_in, w_in, iblock_in, isplit_in)</code> </dt> <dd>
<p>Computes the eigenvectors for a symmetric tridiagonal matrix with <code>dv</code> as diagonal and <code>ev_in</code> as off-diagonal. <code>w_in</code> specifies the input eigenvalues for which to find corresponding eigenvectors. <code>iblock_in</code> specifies the submatrices corresponding to the eigenvalues in <code>w_in</code>. <code>isplit_in</code> specifies the splitting points between the submatrix blocks.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.syconv!">
<code>syconv!(uplo, A, ipiv) → (A, work)</code> </dt> <dd>
<p>Converts a symmetric matrix <code>A</code> (which has been factorized into a triangular matrix) into two matrices <code>L</code> and <code>D</code>. If <code>uplo = U</code>, <code>A</code> is upper triangular. If <code>uplo = L</code>, it is lower triangular. <code>ipiv</code> is the pivot vector from the triangular factorization. <code>A</code> is overwritten by <code>L</code> and <code>D</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.sysv!">
<code>sysv!(uplo, A, B) → (B, A, ipiv)</code> </dt> <dd>
<p>Finds the solution to <code>A * X = B</code> for symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>. <code>A</code> is overwritten by its Bunch-Kaufman factorization. <code>ipiv</code> contains pivoting information about the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.sytrf!">
<code>sytrf!(uplo, A) → (A, ipiv, info)</code> </dt> <dd>
<p>Computes the Bunch-Kaufman factorization of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored.</p> <p>Returns <code>A</code>, overwritten by the factorization, a pivot vector <code>ipiv</code>, and the error code <code>info</code> which is a non-negative integer. If <code>info</code> is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position <code>info</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.sytri!">
<code>sytri!(uplo, A, ipiv)</code> </dt> <dd>
<p>Computes the inverse of a symmetric matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>A</code> is overwritten by its inverse.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.sytrs!">
<code>sytrs!(uplo, A, ipiv, B)</code> </dt> <dd>
<p>Solves the equation <code>A * X = B</code> for a symmetric matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.hesv!">
<code>hesv!(uplo, A, B) → (B, A, ipiv)</code> </dt> <dd>
<p>Finds the solution to <code>A * X = B</code> for Hermitian matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>. <code>A</code> is overwritten by its Bunch-Kaufman factorization. <code>ipiv</code> contains pivoting information about the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.hetrf!">
<code>hetrf!(uplo, A) → (A, ipiv, info)</code> </dt> <dd>
<p>Computes the Bunch-Kaufman factorization of a Hermitian matrix <code>A</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored.</p> <p>Returns <code>A</code>, overwritten by the factorization, a pivot vector <code>ipiv</code>, and the error code <code>info</code> which is a non-negative integer. If <code>info</code> is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position <code>info</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.hetri!">
<code>hetri!(uplo, A, ipiv)</code> </dt> <dd>
<p>Computes the inverse of a Hermitian matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>A</code> is overwritten by its inverse.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.hetrs!">
<code>hetrs!(uplo, A, ipiv, B)</code> </dt> <dd>
<p>Solves the equation <code>A * X = B</code> for a Hermitian matrix <code>A</code> using the results of <code>sytrf!</code>. If <code>uplo = U</code>, the upper half of <code>A</code> is stored. If <code>uplo = L</code>, the lower half is stored. <code>B</code> is overwritten by the solution <code>X</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.syev!">
<code>syev!(jobz, uplo, A)</code> </dt> <dd>
<p>Finds the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper triangle of <code>A</code> is used. If <code>uplo = L</code>, the lower triangle of <code>A</code> is used.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.syevr!">
<code>syevr!(jobz, range, uplo, A, vl, vu, il, iu, abstol) → (W, Z)</code> </dt> <dd>
<p>Finds the eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code>. If <code>uplo = U</code>, the upper triangle of <code>A</code> is used. If <code>uplo = L</code>, the lower triangle of <code>A</code> is used. If <code>range = A</code>, all the eigenvalues are found. If <code>range = V</code>, the eigenvalues in the half-open interval <code>(vl, vu]</code> are found. If <code>range = I</code>, the eigenvalues with indices between <code>il</code> and <code>iu</code> are found. <code>abstol</code> can be set as a tolerance for convergence.</p> <p>The eigenvalues are returned in <code>W</code> and the eigenvectors in <code>Z</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.sygvd!">
<code>sygvd!(jobz, range, uplo, A, vl, vu, il, iu, abstol) → (w, A, B)</code> </dt> <dd>
<p>Finds the generalized eigenvalues (<code>jobz = N</code>) or eigenvalues and eigenvectors (<code>jobz = V</code>) of a symmetric matrix <code>A</code> and symmetric positive-definite matrix <code>B</code>. If <code>uplo = U</code>, the upper triangles of <code>A</code> and <code>B</code> are used. If <code>uplo = L</code>, the lower triangles of <code>A</code> and <code>B</code> are used. If <code>itype = 1</code>, the problem to solve is <code>A * x = lambda * B * x</code>. If <code>itype = 2</code>, the problem to solve is <code>A * B * x = lambda * x</code>. If <code>itype = 3</code>, the problem to solve is <code>B * A * x = lambda * x</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.bdsqr!">
<code>bdsqr!(uplo, d, e_, Vt, U, C) → (d, Vt, U, C)</code> </dt> <dd>
<p>Computes the singular value decomposition of a bidiagonal matrix with <code>d</code> on the diagonal and <code>e_</code> on the off-diagonal. If <code>uplo = U</code>, <code>e_</code> is the superdiagonal. If <code>uplo = L</code>, <code>e_</code> is the subdiagonal. Can optionally also compute the product <code>Q' * C</code>.</p> <p>Returns the singular values in <code>d</code>, and the matrix <code>C</code> overwritten with <code>Q' * C</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.bdsdc!">
<code>bdsdc!(uplo, compq, d, e_) → (d, e, u, vt, q, iq)</code> </dt> <dd>
<p>Computes the singular value decomposition of a bidiagonal matrix with <code>d</code> on the diagonal and <code>e_</code> on the off-diagonal using a divide and conqueq method. If <code>uplo = U</code>, <code>e_</code> is the superdiagonal. If <code>uplo = L</code>, <code>e_</code> is the subdiagonal. If <code>compq = N</code>, only the singular values are found. If <code>compq = I</code>, the singular values and vectors are found. If <code>compq = P</code>, the singular values and vectors are found in compact form. Only works for real types.</p> <p>Returns the singular values in <code>d</code>, and if <code>compq = P</code>, the compact singular vectors in <code>iq</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gecon!">
<code>gecon!(normtype, A, anorm)</code> </dt> <dd>
<p>Finds the reciprocal condition number of matrix <code>A</code>. If <code>normtype = I</code>, the condition number is found in the infinity norm. If <code>normtype = O</code> or <code>1</code>, the condition number is found in the one norm. <code>A</code> must be the result of <code>getrf!</code> and <code>anorm</code> is the norm of <code>A</code> in the relevant norm.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gehrd!">
<code>gehrd!(ilo, ihi, A) → (A, tau)</code> </dt> <dd>
<p>Converts a matrix <code>A</code> to Hessenberg form. If <code>A</code> is balanced with <code>gebal!</code> then <code>ilo</code> and <code>ihi</code> are the outputs of <code>gebal!</code>. Otherwise they should be <code>ilo = 1</code> and <code>ihi = size(A,2)</code>. <code>tau</code> contains the elementary reflectors of the factorization.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.orghr!">
<code>orghr!(ilo, ihi, A, tau)</code> </dt> <dd>
<p>Explicitly finds <code>Q</code>, the orthogonal/unitary matrix from <code>gehrd!</code>. <code>ilo</code>, <code>ihi</code>, <code>A</code>, and <code>tau</code> must correspond to the input/output to <code>gehrd!</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gees!">
<code>gees!(jobvs, A) → (A, vs, w)</code> </dt> <dd>
<p>Computes the eigenvalues (<code>jobvs = N</code>) or the eigenvalues and Schur vectors (<code>jobvs = V</code>) of matrix <code>A</code>. <code>A</code> is overwritten by its Schur form.</p> <p>Returns <code>A</code>, <code>vs</code> containing the Schur vectors, and <code>w</code>, containing the eigenvalues.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.gges!">
<code>gges!(jobvsl, jobvsr, A, B) → (A, B, alpha, beta, vsl, vsr)</code> </dt> <dd>
<p>Computes the generalized eigenvalues, generalized Schur form, left Schur vectors (<code>jobsvl = V</code>), or right Schur vectors (<code>jobvsr = V</code>) of <code>A</code> and <code>B</code>.</p> <p>The generalized eigenvalues are returned in <code>alpha</code> and <code>beta</code>. The left Schur vectors are returned in <code>vsl</code> and the right Schur vectors are returned in <code>vsr</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trexc!">
<code>trexc!(compq, ifst, ilst, T, Q) → (T, Q)</code> </dt> <dd>
<p>Reorder the Schur factorization of a matrix. If <code>compq = V</code>, the Schur vectors <code>Q</code> are reordered. If <code>compq = N</code> they are not modified. <code>ifst</code> and <code>ilst</code> specify the reordering of the vectors.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trsen!">
<code>trsen!(compq, job, select, T, Q) → (T, Q, w)</code> </dt> <dd>
<p>Reorder the Schur factorization of a matrix and optionally finds reciprocal condition numbers. If <code>job = N</code>, no condition numbers are found. If <code>job = E</code>, only the condition number for this cluster of eigenvalues is found. If <code>job = V</code>, only the condition number for the invariant subspace is found. If <code>job = B</code> then the condition numbers for the cluster and subspace are found. If <code>compq = V</code> the Schur vectors <code>Q</code> are updated. If <code>compq = N</code> the Schur vectors are not modified. <code>select</code> determines which eigenvalues are in the cluster.</p> <p>Returns <code>T</code>, <code>Q</code>, and reordered eigenvalues in <code>w</code>.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.tgsen!">
<code>tgsen!(select, S, T, Q, Z) → (S, T, alpha, beta, Q, Z)</code> </dt> <dd>
<p>Reorders the vectors of a generalized Schur decomposition. <code>select</code> specifices the eigenvalues in each cluster.</p> </dd>
</dl> <dl class="function"> <dt id="Base.LinAlg.LAPACK.trsyl!">
<code>trsyl!(transa, transb, A, B, C, isgn=1) → (C, scale)</code> </dt> <dd>
<p>Solves the Sylvester matrix equation <code>A * X +/- X * B = scale*C</code> where <code>A</code> and <code>B</code> are both quasi-upper triangular. If <code>transa = N</code>, <code>A</code> is not modified. If <code>transa = T</code>, <code>A</code> is transposed. If <code>transa = C</code>, <code>A</code> is conjugate transposed. Similarly for <code>transb</code> and <code>B</code>. If <code>isgn = 1</code>, the equation <code>A * X + X * B = scale * C</code> is solved. If <code>isgn = -1</code>, the equation <code>A * X - X * B = scale * C</code> is solved.</p> <p>Returns <code>X</code> (overwriting <code>C</code>) and <code>scale</code>.</p> </dd>
</dl>
<div class="_attribution">
  <p class="_attribution-p">
    © 2009–2016 Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and other contributors<br>Licensed under the MIT License.<br>
    <a href="http://docs.julialang.org/en/release-0.5/stdlib/linalg/" class="_attribution-link" target="_blank">http://docs.julialang.org/en/release-0.5/stdlib/linalg/</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
