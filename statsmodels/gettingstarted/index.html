
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Manual&#58; Getting Started - Statsmodels - W3cubDocs</title>
  
  <meta name="description" content="This very simple case-study is designed to get you up-and-running quickly with statsmodels. Starting from raw data, we will show the steps needed to &hellip;">
  <meta name="keywords" content="getting, started, manual, -, statsmodels">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/statsmodels/gettingstarted/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/statsmodels.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/statsmodels/" class="_nav-link" title="" style="margin-left:0;">Statsmodels</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="getting-started">Getting started</h1> <p>This very simple case-study is designed to get you up-and-running quickly with <code>statsmodels</code>. Starting from raw data, we will show the steps needed to estimate a statistical model and to draw a diagnostic plot. We will only use functions provided by <code>statsmodels</code> or its <code>pandas</code> and <code>patsy</code> dependencies.</p>  <h2 id="loading-modules-and-functions">Loading modules and functions</h2> <p>After <a class="reference external" href="../install/">installing statsmodels and its dependencies</a>, we load a few modules and functions:</p> <pre data-language="python">In [1]: import statsmodels.api as sm

In [2]: import pandas

In [3]: from patsy import dmatrices
</pre> <p><a class="reference external" href="http://pandas.pydata.org/" target="_blank">pandas</a> builds on <code>numpy</code> arrays to provide rich data structures and data analysis tools. The <code>pandas.DataFrame</code> function provides labelled arrays of (potentially heterogenous) data, similar to the <code>R</code> “data.frame”. The <code>pandas.read_csv</code> function can be used to convert a comma-separated values file to a <code>DataFrame</code> object.</p> <p><a class="reference external" href="https://github.com/pydata/patsy" target="_blank">patsy</a> is a Python library for describing statistical models and building <a class="reference external" href="http://en.wikipedia.org/wiki/Design_matrix" target="_blank">Design Matrices</a> using <code>R</code>-like formulas.</p>   <h2 id="data">Data</h2> <p>We download the <a class="reference external" href="http://vincentarelbundock.github.com/Rdatasets/doc/HistData/Guerry.html" target="_blank">Guerry dataset</a>, a collection of historical data used in support of Andre-Michel Guerry’s 1833 <em>Essay on the Moral Statistics of France</em>. The data set is hosted online in comma-separated values format (CSV) by the <a class="reference external" href="http://vincentarelbundock.github.com/Rdatasets/" target="_blank">Rdatasets</a> repository. We could download the file locally and then load it using <code>read_csv</code>, but <code>pandas</code> takes care of all of this automatically for us:</p> <pre data-language="python">In [4]: df = sm.datasets.get_rdataset("Guerry", "HistData").data
</pre> <p>The <a class="reference external" href="../iolib/">Input/Output doc page</a> shows how to import from various other formats.</p> <p>We select the variables of interest and look at the bottom 5 rows:</p> <pre data-language="python">In [5]: vars = ['Department', 'Lottery', 'Literacy', 'Wealth', 'Region']

In [6]: df = df[vars]

In [7]: df[-5:]
Out[7]: 
      Department  Lottery  Literacy  Wealth Region
81        Vienne       40        25      68      W
82  Haute-Vienne       55        13      67      C
83        Vosges       14        62      82      E
84         Yonne       51        47      30      C
85         Corse       83        49      37    NaN
</pre> <p>Notice that there is one missing observation in the <em>Region</em> column. We eliminate it using a <code>DataFrame</code> method provided by <code>pandas</code>:</p> <pre data-language="python">In [8]: df = df.dropna()

In [9]: df[-5:]
Out[9]: 
      Department  Lottery  Literacy  Wealth Region
80        Vendee       68        28      56      W
81        Vienne       40        25      68      W
82  Haute-Vienne       55        13      67      C
83        Vosges       14        62      82      E
84         Yonne       51        47      30      C
</pre>   <h2 id="substantive-motivation-and-model">Substantive motivation and model</h2> <p>We want to know whether literacy rates in the 86 French departments are associated with per capita wagers on the Royal Lottery in the 1820s. We need to control for the level of wealth in each department, and we also want to include a series of dummy variables on the right-hand side of our regression equation to control for unobserved heterogeneity due to regional effects. The model is estimated using ordinary least squares regression (OLS).</p>   <h2 id="design-matrices-endog-exog">Design matrices (<em>endog</em> &amp; <em>exog</em>)</h2> <p>To fit most of the models covered by <code>statsmodels</code>, you will need to create two design matrices. The first is a matrix of endogenous variable(s) (i.e. dependent, response, regressand, etc.). The second is a matrix of exogenous variable(s) (i.e. independent, predictor, regressor, etc.). The OLS coefficient estimates are calculated as usual:</p> <div class="math"> <p><img src="http://statsmodels.sourceforge.net/stable/_images/math/b18cc518a0d2db2eeaeefccf041a3f6bd0fe8a62.png" alt="\hat{\beta} = (X'X)^{-1} X'y"></p> </div>
<p>where <img class="math" src="http://statsmodels.sourceforge.net/stable/_images/math/95ca3c6a1fbeaaafe5800c3269c4c9c2cf2e5406.png" alt="y" style="vertical-align: -4px"> is an <img class="math" src="http://statsmodels.sourceforge.net/stable/_images/math/56e79d5c018a28f583998c049a6df956c0e5e9e0.png" alt="N \times 1" style="vertical-align: -1px"> column of data on lottery wagers per capita (<em>Lottery</em>). <img class="math" src="http://statsmodels.sourceforge.net/stable/_images/math/6b20f2302d5e3b4b32a7cd8bfb55204e21b36aed.png" alt="X" style="vertical-align: 0px"> is <img class="math" src="http://statsmodels.sourceforge.net/stable/_images/math/687363741043436fe522b01afdc011e85021f44f.png" alt="N \times 7" style="vertical-align: 0px"> with an intercept, the <em>Literacy</em> and <em>Wealth</em> variables, and 4 region binary variables.</p> <p>The <code>patsy</code> module provides a convenient function to prepare design matrices using <code>R</code>-like formulas. You can find more information here: <a class="reference external" href="http://patsy.readthedocs.org" target="_blank">http://patsy.readthedocs.org</a></p> <p>We use <code>patsy</code>‘s <code>dmatrices</code> function to create design matrices:</p> <pre data-language="python">In [10]: y, X = dmatrices('Lottery ~ Literacy + Wealth + Region', data=df, return_type='dataframe')
</pre> <p>The resulting matrices/data frames look like this:</p> <pre data-language="python">In [11]: y[:3]
Out[11]: 
   Lottery
0       41
1       38
2       66

In [12]: X[:3]
Out[12]: 
   Intercept  Region[T.E]  Region[T.N]  Region[T.S]  Region[T.W]  Literacy  \
0          1            1            0            0            0        37   
1          1            0            1            0            0        51   
2          1            0            0            0            0        13   

   Wealth  
0      73  
1      22  
2      61  
</pre> <p>Notice that <code>dmatrices</code> has</p> <ul class="simple"> <li>split the categorical <em>Region</em> variable into a set of indicator variables.</li> <li>added a constant to the exogenous regressors matrix.</li> <li>returned <code>pandas</code> DataFrames instead of simple numpy arrays. This is useful because DataFrames allow <code>statsmodels</code> to carry-over meta-data (e.g. variable names) when reporting results.</li> </ul> <p>The above behavior can of course be altered. See the <a class="reference external" href="http://patsy.readthedocs.org/" target="_blank">patsy doc pages</a>.</p>   <h2 id="model-fit-and-summary">Model fit and summary</h2> <p>Fitting a model in <code>statsmodels</code> typically involves 3 easy steps:</p> <ol class="arabic simple"> <li>Use the model class to describe the model</li> <li>Fit the model using a class method</li> <li>Inspect the results using a summary method</li> </ol> <p>For OLS, this is achieved by:</p> <pre data-language="python">In [13]: mod = sm.OLS(y, X)    # Describe model

In [14]: res = mod.fit()       # Fit model

In [15]: print res.summary()   # Summarize model
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                Lottery   R-squared:                       0.338
Model:                            OLS   Adj. R-squared:                  0.287
Method:                 Least Squares   F-statistic:                     6.636
Date:                Tue, 02 Dec 2014   Prob (F-statistic):           1.07e-05
Time:                        12:55:16   Log-Likelihood:                -375.30
No. Observations:                  85   AIC:                             764.6
Df Residuals:                      78   BIC:                             781.7
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------
Intercept      38.6517      9.456      4.087      0.000        19.826    57.478
Region[T.E]   -15.4278      9.727     -1.586      0.117       -34.793     3.938
Region[T.N]   -10.0170      9.260     -1.082      0.283       -28.453     8.419
Region[T.S]    -4.5483      7.279     -0.625      0.534       -19.039     9.943
Region[T.W]   -10.0913      7.196     -1.402      0.165       -24.418     4.235
Literacy       -0.1858      0.210     -0.886      0.378        -0.603     0.232
Wealth          0.4515      0.103      4.390      0.000         0.247     0.656
==============================================================================
Omnibus:                        3.049   Durbin-Watson:                   1.785
Prob(Omnibus):                  0.218   Jarque-Bera (JB):                2.694
Skew:                          -0.340   Prob(JB):                        0.260
Kurtosis:                       2.454   Cond. No.                         371.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre> <p>The <code>res</code> object has many useful attributes. For example, we can extract parameter estimates and r-squared by typing:</p> <pre data-language="python">In [16]: res.params
Out[16]: 
Intercept      38.651655
Region[T.E]   -15.427785
Region[T.N]   -10.016961
Region[T.S]    -4.548257
Region[T.W]   -10.091276
Literacy       -0.185819
Wealth          0.451475
dtype: float64

In [17]: res.rsquared
Out[17]: 0.33795086919288198
</pre> <p>Type <code>dir(res)</code> for a full list of attributes.</p> <p>For more information and examples, see the <a class="reference external" href="../regression/">Regression doc page</a></p>   <h2 id="diagnostics-and-specification-tests">Diagnostics and specification tests</h2> <p><code>statsmodels</code> allows you to conduct a range of useful <a class="reference external" href="../stats/#residual-diagnostics-and-specification-tests">regression diagnostics and specification tests</a>. For instance, apply the Rainbow test for linearity (the null hypothesis is that the relationship is properly modelled as linear):</p> <pre data-language="python">In [18]: sm.stats.linear_rainbow(res)
Out[18]: (0.84723399761569096, 0.69979655436216437)
</pre> <p>Admittedly, the output produced above is not very verbose, but we know from reading the <a class="reference external" href="../generated/statsmodels.stats.diagnostic.linear_rainbow/">docstring</a> (also, <code>print sm.stats.linear_rainbow.__doc__</code>) that the first number is an F-statistic and that the second is the p-value.</p> <p><code>statsmodels</code> also provides graphics functions. For example, we can draw a plot of partial regression for a set of regressors by:</p> <pre data-language="python">In [19]: sm.graphics.plot_partregress('Lottery', 'Wealth', ['Region', 'Literacy'],
   ....:                              data=df, obs_labels=False)
   ....: 
Out[19]: &lt;matplotlib.figure.Figure at 0x2ac6615f1bd0&gt;
</pre> <img alt="_images/gettingstarted_0.png" src="http://statsmodels.sourceforge.net/stable/_images/gettingstarted_0.png">   <h2 id="more">More</h2> <p>Congratulations! You’re ready to move on to other topics in the <a class="reference external" href="../#table-of-contents">Table of Contents</a></p>
<div class="_attribution">
  <p class="_attribution-p">
    © 2009–2012 Statsmodels Developers<br>© 2006–2008 Scipy Developers<br>© 2006 Jonathan E. Taylor<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://statsmodels.sourceforge.net/stable/gettingstarted.html" class="_attribution-link" target="_blank">http://statsmodels.sourceforge.net/stable/gettingstarted.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
