
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Example&#58; Generalized Least Squares - Statsmodels - W3cubDocs</title>
  
  <meta name="description" content=" Link to Notebook GitHub ">
  <meta name="keywords" content="generalized, least, squares, example, -, statsmodels">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/statsmodels/examples/notebooks/generated/gls/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/statsmodels.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/statsmodels/" class="_nav-link" title="" style="margin-left:0;">Statsmodels</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="generalized-least-squares">Generalized Least Squares</h1> <p id="gls-notebook"><a class="reference external" href="https://github.com/statsmodels/statsmodels/blob/master/examples/notebooks/gls.ipynb" target="_blank">Link to Notebook GitHub</a></p> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [1]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">statsmodels.iolib.table</span> <span class="kn">import</span> <span class="p">(</span><span class="n">SimpleTable</span><span class="p">,</span> <span class="n">default_txt_fmt</span><span class="p">)</span>
</pre> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>The Longley dataset is a time series dataset: </p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [2]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">data</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">longley</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">exog</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre> </div> </div> </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">
 <div class="output_subarea output_stream output_stdout output_text"> <pre>
[[      1.       83.   234289.     2356.     1590.   107608.     1947. ]
 [      1.       88.5  259426.     2325.     1456.   108632.     1948. ]
 [      1.       88.2  258054.     3682.     1616.   109773.     1949. ]
 [      1.       89.5  284599.     3351.     1650.   110929.     1950. ]
 [      1.       96.2  328975.     2099.     3099.   112075.     1951. ]]

</pre> </div> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p> Let's assume that the data is heteroskedastic and that we know the nature of the heteroskedasticity. We can then define <code>sigma</code> and use it to give us a GLS model</p> <p> First we will obtain the residuals from an OLS fit</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [3]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">ols_resid</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">resid</span>
</pre> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>Assume that the error terms follow an AR(1) process with a trend:</p> <p>$\epsilon_i = \beta_0 + \rho\epsilon_{i-1} + \eta_i$</p> <p>where $\eta \sim N(0,\Sigma^2)$</p> <p>and that $\rho$ is simply the correlation of the residual a consistent estimator for rho is to regress the residuals on the lagged residuals</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [4]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">resid_fit</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">ols_resid</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">ols_resid</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">resid_fit</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">resid_fit</span><span class="o">.</span><span class="n">pvalues</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre> </div> </div> </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">
 <div class="output_subarea output_stream output_stdout output_text"> <pre>
-1.43902298399
0.173784447884

</pre> </div> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p> While we don't have strong evidence that the errors follow an AR(1) process we continue</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [5]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">rho</span> <span class="o">=</span> <span class="n">resid_fit</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>As we know, an AR(1) process means that near-neighbors have a stronger relation so we can give this structure by using a toeplitz matrix</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [6]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">toeplitz</span>

<span class="n">toeplitz</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre> </div> </div> </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">
<div class="prompt output_prompt"> Out[6]:</div> <div class="output_text output_subarea output_pyout"> <pre>
array([[0, 1, 2, 3, 4],
       [1, 0, 1, 2, 3],
       [2, 1, 0, 1, 2],
       [3, 2, 1, 0, 1],
       [4, 3, 2, 1, 0]])
</pre> </div> </div> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [7]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">order</span> <span class="o">=</span> <span class="n">toeplitz</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ols_resid</span><span class="p">)))</span>
</pre> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>so that our error covariance structure is actually rho**order which defines an autocorrelation structure</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [8]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">sigma</span> <span class="o">=</span> <span class="n">rho</span><span class="o">**</span><span class="n">order</span>
<span class="n">gls_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLS</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="n">gls_results</span> <span class="o">=</span> <span class="n">gls_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>Of course, the exact rho in this instance is not known so it it might make more sense to use feasible gls, which currently only has experimental support. </p> <p>We can use the GLSAR model with one lag, to get to a similar result:</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [9]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="n">glsar_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLSAR</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">glsar_results</span> <span class="o">=</span> <span class="n">glsar_model</span><span class="o">.</span><span class="n">iterative_fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">glsar_results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre> </div> </div> </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">
 <div class="output_subarea output_stream output_stdout output_text"> <pre>
                           GLSAR Regression Results
==============================================================================
Dep. Variable:                      y   R-squared:                       0.996
Model:                          GLSAR   Adj. R-squared:                  0.992
Method:                 Least Squares   F-statistic:                     295.2
Date:                Tue, 02 Dec 2014   Prob (F-statistic):           6.09e-09
Time:                        12:53:58   Log-Likelihood:                -102.04
No. Observations:                  15   AIC:                             218.1
Df Residuals:                       8   BIC:                             223.0
Df Model:                           6
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const      -3.468e+06   8.72e+05     -3.979      0.004     -5.48e+06 -1.46e+06
x1            34.5568     84.734      0.408      0.694      -160.840   229.953
x2            -0.0343      0.033     -1.047      0.326        -0.110     0.041
x3            -1.9621      0.481     -4.083      0.004        -3.070    -0.854
x4            -1.0020      0.211     -4.740      0.001        -1.489    -0.515
x5            -0.0978      0.225     -0.435      0.675        -0.616     0.421
x6          1823.1829    445.829      4.089      0.003       795.100  2851.266
==============================================================================
Omnibus:                        1.960   Durbin-Watson:                   2.554
Prob(Omnibus):                  0.375   Jarque-Bera (JB):                1.423
Skew:                           0.713   Prob(JB):                        0.491
Kurtosis:                       2.508   Cond. No.                     4.80e+09
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.8e+09. This might indicate that there are
strong multicollinearity or other numerical problems.

</pre> </div> </div> <div class="output_area">
 <div class="output_subarea output_stream output_stderr output_text"> <pre>
/home/skipper/.virtualenvs/statsmodels/local/lib/python2.7/site-packages/scipy/stats/stats.py:1205: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=15
  int(n))

</pre> </div> </div> </div> </div> </div> <div class="cell border-box-sizing text_cell rendered">  <div class="inner_cell"> <div class="text_cell_render border-box-sizing rendered_html"> <p>Comparing gls and glsar results, we see that there are some small differences in the parameter estimates and the resulting standard errors of the parameter estimate. This might be do to the numerical differences in the algorithm, e.g. the treatment of initial conditions, because of the small number of observations in the longley dataset.</p> </div> </div> </div> <div class="cell border-box-sizing code_cell rendered"> <div class="input"> <div class="prompt input_prompt"> In [10]: </div> <div class="inner_cell"> <div class="input_area"> <pre data-language="python"><span class="k">print</span><span class="p">(</span><span class="n">gls_results</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">glsar_results</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gls_results</span><span class="o">.</span><span class="n">bse</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">glsar_results</span><span class="o">.</span><span class="n">bse</span><span class="p">)</span>
</pre> </div> </div> </div> <div class="output_wrapper"> <div class="output"> <div class="output_area">
 <div class="output_subarea output_stream output_stdout output_text"> <pre>
[-3797854.9015      -12.7656       -0.038        -2.1869       -1.1518
       -0.0681     1993.9529]
[-3467960.6325       34.5568       -0.0343       -1.9621       -1.002
       -0.0978     1823.1829]
[ 670688.6993      69.4308       0.0262       0.3824       0.1653
       0.1764     342.6346]
[ 871584.0517      84.7337       0.0328       0.4805       0.2114
       0.2248     445.8287]

</pre> </div> </div> </div> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2009–2012 Statsmodels Developers<br>© 2006–2008 Scipy Developers<br>© 2006 Jonathan E. Taylor<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://statsmodels.sourceforge.net/stable/examples/notebooks/generated/gls.html" class="_attribution-link" target="_blank">http://statsmodels.sourceforge.net/stable/examples/notebooks/generated/gls.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
