
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>8. Essential Basic Functionality - Pandas 0.18 - W3cubDocs</title>
  
  <meta name="description" content="Here we discuss a lot of the essential functionality common to the pandas data structures. Here’s how to create some of the objects used in the &hellip;">
  <meta name="keywords" content="essential, basic, functionality, -, pandas, pandas~0.18">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/pandas~0.18/basics/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/pandas~0.18.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/pandas~0.18/" class="_nav-link" title="" style="margin-left:0;">pandas 0.18</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="basics">Essential Basic Functionality</h1> <p id="essential-basic-functionality">Here we discuss a lot of the essential functionality common to the pandas data structures. Here’s how to create some of the objects used in the examples from the previous section:</p> <pre data-language="python">In [1]: index = pd.date_range('1/1/2000', periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index,
   ...:                   columns=['A', 'B', 'C'])
   ...: 

In [4]: wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
   ...:               major_axis=pd.date_range('1/1/2000', periods=5),
   ...:               minor_axis=['A', 'B', 'C', 'D'])
   ...: 
</pre>  <h2 id="basics-head-tail">Head and Tail</h2> <p id="head-and-tail">To view a small sample of a Series or DataFrame object, use the <a class="reference internal" href="../generated/pandas.dataframe.head/#pandas.DataFrame.head" title="pandas.DataFrame.head"><code>head()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.tail/#pandas.DataFrame.tail" title="pandas.DataFrame.tail"><code>tail()</code></a> methods. The default number of elements to display is five, but you may pass a custom number.</p> <pre data-language="python">In [5]: long_series = pd.Series(np.random.randn(1000))

In [6]: long_series.head()
Out[6]: 
0   -0.305384
1   -0.479195
2    0.095031
3   -0.270099
4   -0.707140
dtype: float64

In [7]: long_series.tail(3)
Out[7]: 
997    0.588446
998    0.026465
999   -1.728222
dtype: float64
</pre>   <h2 id="basics-attrs">Attributes and the raw ndarray(s)</h2> <p id="attributes-and-the-raw-ndarray-s">pandas objects have a number of attributes enabling you to access the metadata</p>  <ul class="simple"> <li>
<strong>shape</strong>: gives the axis dimensions of the object, consistent with ndarray</li> <li>Axis labels<ul> <li>
<strong>Series</strong>: <em>index</em> (only axis)</li> <li>
<strong>DataFrame</strong>: <em>index</em> (rows) and <em>columns</em>
</li> <li>
<strong>Panel</strong>: <em>items</em>, <em>major_axis</em>, and <em>minor_axis</em>
</li> </ul> </li> </ul>  <p>Note, <strong>these attributes can be safely assigned to</strong>!</p> <pre data-language="python">In [8]: df[:2]
Out[8]: 
                   A         B         C
2000-01-01  0.187483 -1.933946  0.377312
2000-01-02  0.734122  2.141616 -0.011225

In [9]: df.columns = [x.lower() for x in df.columns]

In [10]: df
Out[10]: 
                   a         b         c
2000-01-01  0.187483 -1.933946  0.377312
2000-01-02  0.734122  2.141616 -0.011225
2000-01-03  0.048869 -1.360687 -0.479010
2000-01-04 -0.859661 -0.231595 -0.527750
2000-01-05 -1.296337  0.150680  0.123836
2000-01-06  0.571764  1.555563 -0.823761
2000-01-07  0.535420 -1.032853  1.469725
2000-01-08  1.304124  1.449735  0.203109
</pre> <p>To get the actual data inside a data structure, one need only access the <strong>values</strong> property:</p> <pre data-language="python">In [11]: s.values
Out[11]: array([ 0.1122,  0.8717, -0.8161, -0.7849,  1.0307])

In [12]: df.values
Out[12]: 
array([[ 0.1875, -1.9339,  0.3773],
       [ 0.7341,  2.1416, -0.0112],
       [ 0.0489, -1.3607, -0.479 ],
       [-0.8597, -0.2316, -0.5278],
       [-1.2963,  0.1507,  0.1238],
       [ 0.5718,  1.5556, -0.8238],
       [ 0.5354, -1.0329,  1.4697],
       [ 1.3041,  1.4497,  0.2031]])

In [13]: wp.values
Out[13]: 
array([[[-1.032 ,  0.9698, -0.9627,  1.3821],
        [-0.9388,  0.6691, -0.4336, -0.2736],
        [ 0.6804, -0.3084, -0.2761, -1.8212],
        [-1.9936, -1.9274, -2.0279,  1.625 ],
        [ 0.5511,  3.0593,  0.4553, -0.0307]],

       [[ 0.9357,  1.0612, -2.1079,  0.1999],
        [ 0.3236, -0.6416, -0.5875,  0.0539],
        [ 0.1949, -0.382 ,  0.3186,  2.0891],
        [-0.7283, -0.0903, -0.7482,  1.3189],
        [-2.0298,  0.7927,  0.461 , -0.5427]]])
</pre> <p>If a DataFrame or Panel contains homogeneously-typed data, the ndarray can actually be modified in-place, and the changes will be reflected in the data structure. For heterogeneous data (e.g. some of the DataFrame’s columns are not all the same dtype), this will not be the case. The values attribute itself, unlike the axis labels, cannot be assigned to.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">When working with heterogeneous data, the dtype of the resulting ndarray will be chosen to accommodate all of the data involved. For example, if strings are involved, the result will be of object dtype. If there are only floats and integers, the resulting array will be of float dtype.</p> </div>   <h2 id="basics-accelerate">Accelerated operations</h2> <p id="accelerated-operations">pandas has support for accelerating certain types of binary numerical and boolean operations using the <code>numexpr</code> library (starting in 0.11.0) and the <code>bottleneck</code> libraries.</p> <p>These libraries are especially useful when dealing with large data sets, and provide large speedups. <code>numexpr</code> uses smart chunking, caching, and multiple cores. <code>bottleneck</code> is a set of specialized cython routines that are especially fast when dealing with arrays that have <code>nans</code>.</p> <p>Here is a sample (using 100 column x 100,000 row <code>DataFrames</code>):</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Operation</th> <th class="head">0.11.0 (ms)</th> <th class="head">Prior Version (ms)</th> <th class="head">Ratio to Prior</th> </tr> </thead>  <tr class="row-even">
<td><code>df1 &gt; df2</code></td> <td>13.32</td> <td>125.35</td> <td>0.1063</td> </tr> <tr class="row-odd">
<td><code>df1 * df2</code></td> <td>21.71</td> <td>36.63</td> <td>0.5928</td> </tr> <tr class="row-even">
<td><code>df1 + df2</code></td> <td>22.04</td> <td>36.50</td> <td>0.6039</td> </tr>  </table> <p>You are highly encouraged to install both libraries. See the section <a class="reference internal" href="../install/#install-recommended-dependencies">Recommended Dependencies</a> for more installation info.</p>   <h2 id="basics-binop">Flexible binary operations</h2> <p id="flexible-binary-operations">With binary operations between pandas data structures, there are two key points of interest:</p>  <ul class="simple"> <li>Broadcasting behavior between higher- (e.g. DataFrame) and lower-dimensional (e.g. Series) objects.</li> <li>Missing data in computations</li> </ul>  <p>We will demonstrate how to manage these issues independently, though they can be handled simultaneously.</p>  <h3 id="matching-broadcasting-behavior">Matching / broadcasting behavior</h3> <p>DataFrame has the methods <a class="reference internal" href="../generated/pandas.dataframe.add/#pandas.DataFrame.add" title="pandas.DataFrame.add"><code>add()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.sub/#pandas.DataFrame.sub" title="pandas.DataFrame.sub"><code>sub()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.mul/#pandas.DataFrame.mul" title="pandas.DataFrame.mul"><code>mul()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.div/#pandas.DataFrame.div" title="pandas.DataFrame.div"><code>div()</code></a> and related functions <a class="reference internal" href="../generated/pandas.dataframe.radd/#pandas.DataFrame.radd" title="pandas.DataFrame.radd"><code>radd()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.rsub/#pandas.DataFrame.rsub" title="pandas.DataFrame.rsub"><code>rsub()</code></a>, ... for carrying out binary operations. For broadcasting behavior, Series input is of primary interest. Using these functions, you can use to either match on the <em>index</em> or <em>columns</em> via the <strong>axis</strong> keyword:</p> <pre data-language="python">In [14]: df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),
   ....:                    'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),
   ....:                    'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})
   ....: 

In [15]: df
Out[15]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [16]: row = df.ix[1]

In [17]: column = df['two']

In [18]: df.sub(row, axis='columns')
Out[18]: 
        one     three       two
a -0.487650       NaN -1.487837
b  0.000000  0.000000  0.000000
c  0.150512  0.639504 -1.585038
d       NaN  1.301762 -2.237808

In [19]: df.sub(row, axis=1)
Out[19]: 
        one     three       two
a -0.487650       NaN -1.487837
b  0.000000  0.000000  0.000000
c  0.150512  0.639504 -1.585038
d       NaN  1.301762 -2.237808

In [20]: df.sub(column, axis='index')
Out[20]: 
        one     three  two
a -0.274957       NaN  0.0
b -1.275144 -1.313539  0.0
c  0.460406  0.911003  0.0
d       NaN  2.226031  0.0

In [21]: df.sub(column, axis=0)
Out[21]: 
        one     three  two
a -0.274957       NaN  0.0
b -1.275144 -1.313539  0.0
c  0.460406  0.911003  0.0
d       NaN  2.226031  0.0
</pre> <p>Furthermore you can align a level of a multi-indexed DataFrame with a Series.</p> <pre data-language="python">In [22]: dfmi = df.copy()

In [23]: dfmi.index = pd.MultiIndex.from_tuples([(1,'a'),(1,'b'),(1,'c'),(2,'a')],
   ....:                                        names=['first','second'])
   ....: 

In [24]: dfmi.sub(column, axis=0, level='second')
Out[24]: 
                   one     three       two
first second                              
1     a      -0.274957       NaN  0.000000
      b      -1.275144 -1.313539  0.000000
      c       0.460406  0.911003  0.000000
2     a            NaN  1.476060 -0.749971
</pre> <p>With Panel, describing the matching behavior is a bit more difficult, so the arithmetic methods instead (and perhaps confusingly?) give you the option to specify the <em>broadcast axis</em>. For example, suppose we wished to demean the data over a particular axis. This can be accomplished by taking the mean over an axis and broadcasting over the same axis:</p> <pre data-language="python">In [25]: major_mean = wp.mean(axis='major')

In [26]: major_mean
Out[26]: 
      Item1     Item2
A -0.546569 -0.260774
B  0.492478  0.147993
C -0.649010 -0.532794
D  0.176307  0.623812

In [27]: wp.sub(major_mean, axis='major')
Out[27]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 2 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: Item1 to Item2
Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00
Minor_axis axis: A to D
</pre> <p>And similarly for <code>axis="items"</code> and <code>axis="minor"</code>.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">I could be convinced to make the <strong>axis</strong> argument in the DataFrame methods match the broadcasting behavior of Panel. Though it would require a transition period so users can change their code...</p> </div>   <h3 id="missing-data-operations-with-fill-values">Missing data / operations with fill values</h3> <p>In Series and DataFrame (though not yet in Panel), the arithmetic functions have the option of inputting a <em>fill_value</em>, namely a value to substitute when at most one of the values at a location are missing. For example, when adding two DataFrame objects, you may wish to treat NaN as 0 unless both DataFrames are missing that value, in which case the result will be NaN (you can later replace NaN with some other value using <code>fillna</code> if you wish).</p> <pre data-language="python">In [28]: df
Out[28]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [29]: df2
Out[29]: 
        one     three       two
a -0.626544  1.000000 -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [30]: df + df2
Out[30]: 
        one     three       two
a -1.253088       NaN -0.703174
b -0.277789 -0.354579  2.272499
c  0.023235  0.924429 -0.897577
d       NaN  2.248945 -2.203116

In [31]: df.add(df2, fill_value=0)
Out[31]: 
        one     three       two
a -1.253088  1.000000 -0.703174
b -0.277789 -0.354579  2.272499
c  0.023235  0.924429 -0.897577
d       NaN  2.248945 -2.203116
</pre>   <h3 id="basics-compare">Flexible Comparisons</h3> <p id="flexible-comparisons">Starting in v0.8, pandas introduced binary comparison methods eq, ne, lt, gt, le, and ge to Series and DataFrame whose behavior is analogous to the binary arithmetic operations described above:</p> <pre data-language="python">In [32]: df.gt(df2)
Out[32]: 
     one  three    two
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [33]: df2.ne(df)
Out[33]: 
     one  three    two
a  False   True  False
b  False  False  False
c  False  False  False
d   True  False  False
</pre> <p>These operations produce a pandas object the same type as the left-hand-side input that if of dtype <code>bool</code>. These <code>boolean</code> objects can be used in indexing operations, see <a class="reference internal" href="../indexing/#indexing-boolean">here</a></p>   <h3 id="basics-reductions">Boolean Reductions</h3> <p id="boolean-reductions">You can apply the reductions: <a class="reference internal" href="../generated/pandas.dataframe.empty/#pandas.DataFrame.empty" title="pandas.DataFrame.empty"><code>empty</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.any/#pandas.DataFrame.any" title="pandas.DataFrame.any"><code>any()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.all/#pandas.DataFrame.all" title="pandas.DataFrame.all"><code>all()</code></a>, and <a class="reference internal" href="../generated/pandas.dataframe.bool/#pandas.DataFrame.bool" title="pandas.DataFrame.bool"><code>bool()</code></a> to provide a way to summarize a boolean result.</p> <pre data-language="python">In [34]: (df &gt; 0).all()
Out[34]: 
one      False
three    False
two      False
dtype: bool

In [35]: (df &gt; 0).any()
Out[35]: 
one      True
three    True
two      True
dtype: bool
</pre> <p>You can reduce to a final boolean value.</p> <pre data-language="python">In [36]: (df &gt; 0).any().any()
Out[36]: True
</pre> <p>You can test if a pandas object is empty, via the <a class="reference internal" href="../generated/pandas.dataframe.empty/#pandas.DataFrame.empty" title="pandas.DataFrame.empty"><code>empty</code></a> property.</p> <pre data-language="python">In [37]: df.empty
Out[37]: False

In [38]: pd.DataFrame(columns=list('ABC')).empty
Out[38]: True
</pre> <p>To evaluate single-element pandas objects in a boolean context, use the method <a class="reference internal" href="../generated/pandas.dataframe.bool/#pandas.DataFrame.bool" title="pandas.DataFrame.bool"><code>bool()</code></a>:</p> <pre data-language="python">In [39]: pd.Series([True]).bool()
Out[39]: True

In [40]: pd.Series([False]).bool()
Out[40]: False

In [41]: pd.DataFrame([[True]]).bool()
Out[41]: True

In [42]: pd.DataFrame([[False]]).bool()
Out[42]: False
</pre> <div class="admonition warning"> <p class="first admonition-title">Warning</p> <p>You might be tempted to do the following:</p> <pre data-language="python">&gt;&gt;&gt; if df:
     ...
</pre> <p>Or</p> <pre data-language="python">&gt;&gt;&gt; df and df2
</pre> <p>These both will raise as you are trying to compare multiple values.</p> <pre data-language="python">ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().
</pre> </div> <p>See <a class="reference internal" href="../gotchas/#gotchas-truth">gotchas</a> for a more detailed discussion.</p>   <h3 id="basics-equals">Comparing if objects are equivalent</h3> <p id="comparing-if-objects-are-equivalent">Often you may find there is more than one way to compute the same result. As a simple example, consider <code>df+df</code> and <code>df*2</code>. To test that these two computations produce the same result, given the tools shown above, you might imagine using <code>(df+df == df*2).all()</code>. But in fact, this expression is False:</p> <pre data-language="python">In [43]: df+df == df*2
Out[43]: 
     one  three   two
a   True  False  True
b   True   True  True
c   True   True  True
d  False   True  True

In [44]: (df+df == df*2).all()
Out[44]: 
one      False
three    False
two       True
dtype: bool
</pre> <p>Notice that the boolean DataFrame <code>df+df == df*2</code> contains some False values! That is because NaNs do not compare as equals:</p> <pre data-language="python">In [45]: np.nan == np.nan
Out[45]: False
</pre> <p>So, as of v0.13.1, NDFrames (such as Series, DataFrames, and Panels) have an <a class="reference internal" href="../generated/pandas.dataframe.equals/#pandas.DataFrame.equals" title="pandas.DataFrame.equals"><code>equals()</code></a> method for testing equality, with NaNs in corresponding locations treated as equal.</p> <pre data-language="python">In [46]: (df+df).equals(df*2)
Out[46]: True
</pre> <p>Note that the Series or DataFrame index needs to be in the same order for equality to be True:</p> <pre data-language="python">In [47]: df1 = pd.DataFrame({'col':['foo', 0, np.nan]})

In [48]: df2 = pd.DataFrame({'col':[np.nan, 0, 'foo']}, index=[2,1,0])

In [49]: df1.equals(df2)
Out[49]: False

In [50]: df1.equals(df2.sort_index())
Out[50]: True
</pre>   <h3 id="comparing-array-like-objects">Comparing array-like objects</h3> <p>You can conveniently do element-wise comparisons when comparing a pandas data structure with a scalar value:</p> <pre data-language="python">In [51]: pd.Series(['foo', 'bar', 'baz']) == 'foo'
Out[51]: 
0     True
1    False
2    False
dtype: bool

In [52]: pd.Index(['foo', 'bar', 'baz']) == 'foo'
Out[52]: array([ True, False, False], dtype=bool)
</pre> <p>Pandas also handles element-wise comparisons between different array-like objects of the same length:</p> <pre data-language="python">In [53]: pd.Series(['foo', 'bar', 'baz']) == pd.Index(['foo', 'bar', 'qux'])
Out[53]: 
0     True
1     True
2    False
dtype: bool

In [54]: pd.Series(['foo', 'bar', 'baz']) == np.array(['foo', 'bar', 'qux'])
Out[54]: 
0     True
1     True
2    False
dtype: bool
</pre> <p>Trying to compare <code>Index</code> or <code>Series</code> objects of different lengths will raise a ValueError:</p> <pre data-language="python">In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare
</pre> <p>Note that this is different from the numpy behavior where a comparison can be broadcast:</p> <pre data-language="python">In [55]: np.array([1, 2, 3]) == np.array([2])
Out[55]: array([False,  True, False], dtype=bool)
</pre> <p>or it can return False if broadcasting can not be done:</p> <pre data-language="python">In [56]: np.array([1, 2, 3]) == np.array([1, 2])
Out[56]: False
</pre>   <h3 id="combining-overlapping-data-sets">Combining overlapping data sets</h3> <p>A problem occasionally arising is the combination of two similar data sets where values in one are preferred over the other. An example would be two data series representing a particular economic indicator where one is considered to be of “higher quality”. However, the lower quality series might extend further back in history or have more complete data coverage. As such, we would like to combine two DataFrame objects where missing values in one DataFrame are conditionally filled with like-labeled values from the other DataFrame. The function implementing this operation is <a class="reference internal" href="../generated/pandas.dataframe.combine_first/#pandas.DataFrame.combine_first" title="pandas.DataFrame.combine_first"><code>combine_first()</code></a>, which we illustrate:</p> <pre data-language="python">In [57]: df1 = pd.DataFrame({'A' : [1., np.nan, 3., 5., np.nan],
   ....:                     'B' : [np.nan, 2., 3., np.nan, 6.]})
   ....: 

In [58]: df2 = pd.DataFrame({'A' : [5., 2., 4., np.nan, 3., 7.],
   ....:                     'B' : [np.nan, np.nan, 3., 4., 6., 8.]})
   ....: 

In [59]: df1
Out[59]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [60]: df2
Out[60]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [61]: df1.combine_first(df2)
Out[61]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
</pre>   <h3 id="general-dataframe-combine">General DataFrame Combine</h3> <p>The <a class="reference internal" href="../generated/pandas.dataframe.combine_first/#pandas.DataFrame.combine_first" title="pandas.DataFrame.combine_first"><code>combine_first()</code></a> method above calls the more general DataFrame method <a class="reference internal" href="../generated/pandas.dataframe.combine/#pandas.DataFrame.combine" title="pandas.DataFrame.combine"><code>combine()</code></a>. This method takes another DataFrame and a combiner function, aligns the input DataFrame and then passes the combiner function pairs of Series (i.e., columns whose names are the same).</p> <p>So, for instance, to reproduce <a class="reference internal" href="../generated/pandas.dataframe.combine_first/#pandas.DataFrame.combine_first" title="pandas.DataFrame.combine_first"><code>combine_first()</code></a> as above:</p> <pre data-language="python">In [62]: combiner = lambda x, y: np.where(pd.isnull(x), y, x)

In [63]: df1.combine(df2, combiner)
Out[63]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
</pre>    <h2 id="basics-stats">Descriptive statistics</h2> <p id="descriptive-statistics">A large number of methods for computing descriptive statistics and other related operations on <a class="reference internal" href="../api/#api-series-stats">Series</a>, <a class="reference internal" href="../api/#api-dataframe-stats">DataFrame</a>, and <a class="reference internal" href="../api/#api-panel-stats">Panel</a>. Most of these are aggregations (hence producing a lower-dimensional result) like <a class="reference internal" href="../generated/pandas.dataframe.sum/#pandas.DataFrame.sum" title="pandas.DataFrame.sum"><code>sum()</code></a>, <a class="reference internal" href="../generated/pandas.dataframe.mean/#pandas.DataFrame.mean" title="pandas.DataFrame.mean"><code>mean()</code></a>, and <a class="reference internal" href="../generated/pandas.dataframe.quantile/#pandas.DataFrame.quantile" title="pandas.DataFrame.quantile"><code>quantile()</code></a>, but some of them, like <a class="reference internal" href="../generated/pandas.dataframe.cumsum/#pandas.DataFrame.cumsum" title="pandas.DataFrame.cumsum"><code>cumsum()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.cumprod/#pandas.DataFrame.cumprod" title="pandas.DataFrame.cumprod"><code>cumprod()</code></a>, produce an object of the same size. Generally speaking, these methods take an <strong>axis</strong> argument, just like <em>ndarray.{sum, std, ...}</em>, but the axis can be specified by name or integer:</p>  <ul class="simple"> <li>
<strong>Series</strong>: no axis argument needed</li> <li>
<strong>DataFrame</strong>: “index” (axis=0, default), “columns” (axis=1)</li> <li>
<strong>Panel</strong>: “items” (axis=0), “major” (axis=1, default), “minor” (axis=2)</li> </ul>  <p>For example:</p> <pre data-language="python">In [64]: df
Out[64]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [65]: df.mean(0)
Out[65]: 
one     -0.251274
three    0.469799
two     -0.191421
dtype: float64

In [66]: df.mean(1)
Out[66]: 
a   -0.489066
b    0.273355
c    0.008348
d    0.011457
dtype: float64
</pre> <p>All such methods have a <code>skipna</code> option signaling whether to exclude missing data (<code>True</code> by default):</p> <pre data-language="python">In [67]: df.sum(0, skipna=False)
Out[67]: 
one           NaN
three         NaN
two     -0.765684
dtype: float64

In [68]: df.sum(axis=1, skipna=True)
Out[68]: 
a   -0.978131
b    0.820066
c    0.025044
d    0.022914
dtype: float64
</pre> <p>Combined with the broadcasting / arithmetic behavior, one can describe various statistical procedures, like standardization (rendering data zero mean and standard deviation 1), very concisely:</p> <pre data-language="python">In [69]: ts_stand = (df - df.mean()) / df.std()

In [70]: ts_stand.std()
Out[70]: 
one      1.0
three    1.0
two      1.0
dtype: float64

In [71]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [72]: xs_stand.std(1)
Out[72]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64
</pre> <p>Note that methods like <a class="reference internal" href="../generated/pandas.dataframe.cumsum/#pandas.DataFrame.cumsum" title="pandas.DataFrame.cumsum"><code>cumsum()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.cumprod/#pandas.DataFrame.cumprod" title="pandas.DataFrame.cumprod"><code>cumprod()</code></a> preserve the location of NA values:</p> <pre data-language="python">In [73]: df.cumsum()
Out[73]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.765438 -0.177289  0.784662
c -0.753821  0.284925  0.335874
d       NaN  1.409398 -0.765684
</pre> <p>Here is a quick reference summary table of common functions. Each also takes an optional <code>level</code> parameter which applies only if the object has a <a class="reference internal" href="../advanced/#advanced-hierarchical">hierarchical index</a>.</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Function</th> <th class="head">Description</th> </tr> </thead>  <tr class="row-even">
<td><code>count</code></td> <td>Number of non-null observations</td> </tr> <tr class="row-odd">
<td><code>sum</code></td> <td>Sum of values</td> </tr> <tr class="row-even">
<td><code>mean</code></td> <td>Mean of values</td> </tr> <tr class="row-odd">
<td><code>mad</code></td> <td>Mean absolute deviation</td> </tr> <tr class="row-even">
<td><code>median</code></td> <td>Arithmetic median of values</td> </tr> <tr class="row-odd">
<td><code>min</code></td> <td>Minimum</td> </tr> <tr class="row-even">
<td><code>max</code></td> <td>Maximum</td> </tr> <tr class="row-odd">
<td><code>mode</code></td> <td>Mode</td> </tr> <tr class="row-even">
<td><code>abs</code></td> <td>Absolute Value</td> </tr> <tr class="row-odd">
<td><code>prod</code></td> <td>Product of values</td> </tr> <tr class="row-even">
<td><code>std</code></td> <td>Bessel-corrected sample standard deviation</td> </tr> <tr class="row-odd">
<td><code>var</code></td> <td>Unbiased variance</td> </tr> <tr class="row-even">
<td><code>sem</code></td> <td>Standard error of the mean</td> </tr> <tr class="row-odd">
<td><code>skew</code></td> <td>Sample skewness (3rd moment)</td> </tr> <tr class="row-even">
<td><code>kurt</code></td> <td>Sample kurtosis (4th moment)</td> </tr> <tr class="row-odd">
<td><code>quantile</code></td> <td>Sample quantile (value at %)</td> </tr> <tr class="row-even">
<td><code>cumsum</code></td> <td>Cumulative sum</td> </tr> <tr class="row-odd">
<td><code>cumprod</code></td> <td>Cumulative product</td> </tr> <tr class="row-even">
<td><code>cummax</code></td> <td>Cumulative maximum</td> </tr> <tr class="row-odd">
<td><code>cummin</code></td> <td>Cumulative minimum</td> </tr>  </table> <p>Note that by chance some NumPy methods, like <code>mean</code>, <code>std</code>, and <code>sum</code>, will exclude NAs on Series input by default:</p> <pre data-language="python">In [74]: np.mean(df['one'])
Out[74]: -0.25127365175839511

In [75]: np.mean(df['one'].values)
Out[75]: nan
</pre> <p><code>Series</code> also has a method <a class="reference internal" href="../generated/pandas.series.nunique/#pandas.Series.nunique" title="pandas.Series.nunique"><code>nunique()</code></a> which will return the number of unique non-null values:</p> <pre data-language="python">In [76]: series = pd.Series(np.random.randn(500))

In [77]: series[20:500] = np.nan

In [78]: series[10:20]  = 5

In [79]: series.nunique()
Out[79]: 11
</pre>  <h3 id="basics-describe">Summarizing data: describe</h3> <p id="summarizing-data-describe">There is a convenient <a class="reference internal" href="../generated/pandas.dataframe.describe/#pandas.DataFrame.describe" title="pandas.DataFrame.describe"><code>describe()</code></a> function which computes a variety of summary statistics about a Series or the columns of a DataFrame (excluding NAs of course):</p> <pre data-language="python">In [80]: series = pd.Series(np.random.randn(1000))

In [81]: series[::2] = np.nan

In [82]: series.describe()
Out[82]: 
count    500.000000
mean      -0.039663
std        1.069371
min       -3.463789
25%             NaN
50%             NaN
75%             NaN
max        3.120271
dtype: float64

In [83]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=['a', 'b', 'c', 'd', 'e'])

In [84]: frame.ix[::2] = np.nan

In [85]: frame.describe()
Out[85]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.000954   -0.044014    0.075936   -0.003679    0.020751
std      1.005133    0.974882    0.967432    1.004732    0.963812
min     -3.010899   -2.782760   -3.401252   -2.944925   -3.794127
25%           NaN         NaN         NaN         NaN         NaN
50%           NaN         NaN         NaN         NaN         NaN
75%           NaN         NaN         NaN         NaN         NaN
max      3.007143    2.627688    2.702490    2.850852    3.072117
</pre> <p>You can select specific percentiles to include in the output:</p> <pre data-language="python">In [86]: series.describe(percentiles=[.05, .25, .75, .95])
Out[86]: 
count    500.000000
mean      -0.039663
std        1.069371
min       -3.463789
5%              NaN
25%             NaN
50%             NaN
75%             NaN
95%             NaN
max        3.120271
dtype: float64
</pre> <p>By default, the median is always included.</p> <p>For a non-numerical Series object, <a class="reference internal" href="../generated/pandas.series.describe/#pandas.Series.describe" title="pandas.Series.describe"><code>describe()</code></a> will give a simple summary of the number of unique values and most frequently occurring values:</p> <pre data-language="python">In [87]: s = pd.Series(['a', 'a', 'b', 'b', 'a', 'a', np.nan, 'c', 'd', 'a'])

In [88]: s.describe()
Out[88]: 
count     9
unique    4
top       a
freq      5
dtype: object
</pre> <p>Note that on a mixed-type DataFrame object, <a class="reference internal" href="../generated/pandas.dataframe.describe/#pandas.DataFrame.describe" title="pandas.DataFrame.describe"><code>describe()</code></a> will restrict the summary to include only numerical columns or, if none are, only categorical columns:</p> <pre data-language="python">In [89]: frame = pd.DataFrame({'a': ['Yes', 'Yes', 'No', 'No'], 'b': range(4)})

In [90]: frame.describe()
Out[90]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000
</pre> <p>This behaviour can be controlled by providing a list of types as <code>include</code>/<code>exclude</code> arguments. The special value <code>all</code> can also be used:</p> <pre data-language="python">In [91]: frame.describe(include=['object'])
Out[91]: 
         a
count    4
unique   2
top     No
freq     2

In [92]: frame.describe(include=['number'])
Out[92]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [93]: frame.describe(include='all')
Out[93]: 
          a         b
count     4  4.000000
unique    2       NaN
top      No       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000
</pre> <p>That feature relies on <a class="reference internal" href="#basics-selectdtypes">select_dtypes</a>. Refer to there for details about accepted inputs.</p>   <h3 id="basics-idxmin">Index of Min/Max Values</h3> <p id="index-of-min-max-values">The <a class="reference internal" href="../generated/pandas.dataframe.idxmin/#pandas.DataFrame.idxmin" title="pandas.DataFrame.idxmin"><code>idxmin()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.idxmax/#pandas.DataFrame.idxmax" title="pandas.DataFrame.idxmax"><code>idxmax()</code></a> functions on Series and DataFrame compute the index labels with the minimum and maximum corresponding values:</p> <pre data-language="python">In [94]: s1 = pd.Series(np.random.randn(5))

In [95]: s1
Out[95]: 
0   -0.872725
1    1.522411
2    0.080594
3   -1.676067
4    0.435804
dtype: float64

In [96]: s1.idxmin(), s1.idxmax()
Out[96]: (3, 1)

In [97]: df1 = pd.DataFrame(np.random.randn(5,3), columns=['A','B','C'])

In [98]: df1
Out[98]: 
          A         B         C
0  0.445734 -1.649461  0.169660
1  1.246181  0.131682 -2.001988
2 -1.273023  0.870502  0.214583
3  0.088452 -0.173364  1.207466
4  0.546121  0.409515 -0.310515

In [99]: df1.idxmin(axis=0)
Out[99]: 
A    2
B    0
C    1
dtype: int64

In [100]: df1.idxmax(axis=1)
Out[100]: 
0    A
1    A
2    B
3    C
4    A
dtype: object
</pre> <p>When there are multiple rows (or columns) matching the minimum or maximum value, <a class="reference internal" href="../generated/pandas.dataframe.idxmin/#pandas.DataFrame.idxmin" title="pandas.DataFrame.idxmin"><code>idxmin()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.idxmax/#pandas.DataFrame.idxmax" title="pandas.DataFrame.idxmax"><code>idxmax()</code></a> return the first matching index:</p> <pre data-language="python">In [101]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=['A'], index=list('edcba'))

In [102]: df3
Out[102]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [103]: df3['A'].idxmin()
Out[103]: 'd'
</pre> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last"><code>idxmin</code> and <code>idxmax</code> are called <code>argmin</code> and <code>argmax</code> in NumPy.</p> </div>   <h3 id="basics-discretization">Value counts (histogramming) / Mode</h3> <p id="value-counts-histogramming-mode">The <a class="reference internal" href="../generated/pandas.series.value_counts/#pandas.Series.value_counts" title="pandas.Series.value_counts"><code>value_counts()</code></a> Series method and top-level function computes a histogram of a 1D array of values. It can also be used as a function on regular arrays:</p> <pre data-language="python">In [104]: data = np.random.randint(0, 7, size=50)

In [105]: data
Out[105]: 
array([5, 3, 2, 2, 1, 4, 0, 4, 0, 2, 0, 6, 4, 1, 6, 3, 3, 0, 2, 1, 0, 5, 5,
       3, 6, 1, 5, 6, 2, 0, 0, 6, 3, 3, 5, 0, 4, 3, 3, 3, 0, 6, 1, 3, 5, 5,
       0, 4, 0, 6])

In [106]: s = pd.Series(data)

In [107]: s.value_counts()
Out[107]: 
0    11
3    10
6     7
5     7
4     5
2     5
1     5
dtype: int64

In [108]: pd.value_counts(data)
Out[108]: 
0    11
3    10
6     7
5     7
4     5
2     5
1     5
dtype: int64
</pre> <p>Similarly, you can get the most frequently occurring value(s) (the mode) of the values in a Series or DataFrame:</p> <pre data-language="python">In [109]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [110]: s5.mode()
Out[110]: 
0    3
1    7
dtype: int64

In [111]: df5 = pd.DataFrame({"A": np.random.randint(0, 7, size=50),
   .....:                     "B": np.random.randint(-10, 15, size=50)})
   .....: 

In [112]: df5.mode()
Out[112]: 
   A  B
0  1 -5
</pre>   <h3 id="discretization-and-quantiling">Discretization and quantiling</h3> <p>Continuous values can be discretized using the <a class="reference internal" href="../generated/pandas.cut/#pandas.cut" title="pandas.cut"><code>cut()</code></a> (bins based on values) and <a class="reference internal" href="../generated/pandas.qcut/#pandas.qcut" title="pandas.qcut"><code>qcut()</code></a> (bins based on sample quantiles) functions:</p> <pre data-language="python">In [113]: arr = np.random.randn(20)

In [114]: factor = pd.cut(arr, 4)

In [115]: factor
Out[115]: 
[(-0.645, 0.336], (-2.61, -1.626], (-1.626, -0.645], (-1.626, -0.645], (-1.626, -0.645], ..., (0.336, 1.316], (0.336, 1.316], (0.336, 1.316], (0.336, 1.316], (-2.61, -1.626]]
Length: 20
Categories (4, object): [(-2.61, -1.626] &lt; (-1.626, -0.645] &lt; (-0.645, 0.336] &lt; (0.336, 1.316]]

In [116]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [117]: factor
Out[117]: 
[(-1, 0], (-5, -1], (-1, 0], (-5, -1], (-1, 0], ..., (0, 1], (1, 5], (0, 1], (0, 1], (-5, -1]]
Length: 20
Categories (4, object): [(-5, -1] &lt; (-1, 0] &lt; (0, 1] &lt; (1, 5]]
</pre> <p><a class="reference internal" href="../generated/pandas.qcut/#pandas.qcut" title="pandas.qcut"><code>qcut()</code></a> computes sample quantiles. For example, we could slice up some normally distributed data into equal-size quartiles like so:</p> <pre data-language="python">In [118]: arr = np.random.randn(30)

In [119]: factor = pd.qcut(arr, [0, .25, .5, .75, 1])

In [120]: factor
Out[120]: 
[(-0.139, 1.00736], (1.00736, 1.976], (1.00736, 1.976], [-1.0705, -0.439], [-1.0705, -0.439], ..., (1.00736, 1.976], [-1.0705, -0.439], (-0.439, -0.139], (-0.439, -0.139], (-0.439, -0.139]]
Length: 30
Categories (4, object): [[-1.0705, -0.439] &lt; (-0.439, -0.139] &lt; (-0.139, 1.00736] &lt; (1.00736, 1.976]]

In [121]: pd.value_counts(factor)
Out[121]: 
(1.00736, 1.976]     8
[-1.0705, -0.439]    8
(-0.139, 1.00736]    7
(-0.439, -0.139]     7
dtype: int64
</pre> <p>We can also pass infinite values to define the bins:</p> <pre data-language="python">In [122]: arr = np.random.randn(20)

In [123]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [124]: factor
Out[124]: 
[(-inf, 0], (0, inf], (0, inf], (0, inf], (-inf, 0], ..., (-inf, 0], (0, inf], (-inf, 0], (-inf, 0], (0, inf]]
Length: 20
Categories (2, object): [(-inf, 0] &lt; (0, inf]]
</pre>    <h2 id="basics-apply">Function application</h2> <p id="function-application">To apply your own or another library’s functions to pandas objects, you should be aware of the three methods below. The appropriate method to use depends on whether your function expects to operate on an entire <code>DataFrame</code> or <code>Series</code>, row- or column-wise, or elementwise.</p> <ol class="arabic simple"> <li>
<a class="reference internal" href="#tablewise-function-application">Tablewise Function Application</a>: <a class="reference internal" href="../generated/pandas.dataframe.pipe/#pandas.DataFrame.pipe" title="pandas.DataFrame.pipe"><code>pipe()</code></a>
</li> <li>
<a class="reference internal" href="#row-or-column-wise-function-application">Row or Column-wise Function Application</a>: <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a>
</li> <li>
<a class="reference internal" href="#elementwise">Elementwise</a> function application: <a class="reference internal" href="../generated/pandas.dataframe.applymap/#pandas.DataFrame.applymap" title="pandas.DataFrame.applymap"><code>applymap()</code></a>
</li> </ol>  <h3 id="basics-pipe">Tablewise Function Application</h3> <div class="versionadded" id="tablewise-function-application"> <p><span class="versionmodified">New in version 0.16.2.</span></p> </div> <p><code>DataFrames</code> and <code>Series</code> can of course just be passed into functions. However, if the function needs to be called in a chain, consider using the <a class="reference internal" href="../generated/pandas.dataframe.pipe/#pandas.DataFrame.pipe" title="pandas.DataFrame.pipe"><code>pipe()</code></a> method. Compare the following</p> <pre data-language="python"># f, g, and h are functions taking and returning ``DataFrames``
&gt;&gt;&gt; f(g(h(df), arg1=1), arg2=2, arg3=3)
</pre> <p>with the equivalent</p> <pre data-language="python">&gt;&gt;&gt; (df.pipe(h)
       .pipe(g, arg1=1)
       .pipe(f, arg2=2, arg3=3)
    )
</pre> <p>Pandas encourages the second style, which is known as method chaining. <code>pipe</code> makes it easy to use your own or another library’s functions in method chains, alongside pandas’ methods.</p> <p>In the example above, the functions <code>f</code>, <code>g</code>, and <code>h</code> each expected the <code>DataFrame</code> as the first positional argument. What if the function you wish to apply takes its data as, say, the second argument? In this case, provide <code>pipe</code> with a tuple of <code>(callable, data_keyword)</code>. <code>.pipe</code> will route the <code>DataFrame</code> to the argument specified in the tuple.</p> <p>For example, we can fit a regression using statsmodels. Their API expects a formula first and a <code>DataFrame</code> as the second argument, <code>data</code>. We pass in the function, keyword pair <code>(sm.poisson, 'data')</code> to <code>pipe</code>:</p> <pre data-language="python">In [125]: import statsmodels.formula.api as sm

In [126]: bb = pd.read_csv('data/baseball.csv', index_col='id')

In [127]: (bb.query('h &gt; 0')
   .....:    .assign(ln_h = lambda df: np.log(df.h))
   .....:    .pipe((sm.poisson, 'data'), 'hr ~ ln_h + year + g + C(lg)')
   .....:    .fit()
   .....:    .summary()
   .....: )
   .....: 
Optimization terminated successfully.
         Current function value: 2.116284
         Iterations 24
Out[127]: 
&lt;class 'statsmodels.iolib.summary.Summary'&gt;
"""
                          Poisson Regression Results                          
==============================================================================
Dep. Variable:                     hr   No. Observations:                   68
Model:                        Poisson   Df Residuals:                       63
Method:                           MLE   Df Model:                            4
Date:                Tue, 03 May 2016   Pseudo R-squ.:                  0.6878
Time:                        09:03:28   Log-Likelihood:                -143.91
converged:                       True   LL-Null:                       -460.91
                                        LLR p-value:                6.774e-136
===============================================================================
                  coef    std err          z      P&gt;|z|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------
Intercept   -1267.3636    457.867     -2.768      0.006     -2164.767  -369.960
C(lg)[T.NL]    -0.2057      0.101     -2.044      0.041        -0.403    -0.008
ln_h            0.9280      0.191      4.866      0.000         0.554     1.302
year            0.6301      0.228      2.762      0.006         0.183     1.077
g               0.0099      0.004      2.754      0.006         0.003     0.017
===============================================================================
"""
</pre> <p>The pipe method is inspired by unix pipes and more recently <a class="reference external" href="https://github.com/hadley/dplyr" target="_blank">dplyr</a> and <a class="reference external" href="https://github.com/smbache/magrittr" target="_blank">magrittr</a>, which have introduced the popular <code>(%&gt;%)</code> (read pipe) operator for <a class="reference external" href="http://www.r-project.org" target="_blank">R</a>. The implementation of <code>pipe</code> here is quite clean and feels right at home in python. We encourage you to view the source code (<code>pd.DataFrame.pipe??</code> in IPython).</p>   <h3 id="row-or-column-wise-function-application">Row or Column-wise Function Application</h3> <p>Arbitrary functions can be applied along the axes of a DataFrame or Panel using the <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a> method, which, like the descriptive statistics methods, take an optional <code>axis</code> argument:</p> <pre data-language="python">In [128]: df.apply(np.mean)
Out[128]: 
one     -0.251274
three    0.469799
two     -0.191421
dtype: float64

In [129]: df.apply(np.mean, axis=1)
Out[129]: 
a   -0.489066
b    0.273355
c    0.008348
d    0.011457
dtype: float64

In [130]: df.apply(lambda x: x.max() - x.min())
Out[130]: 
one      0.638161
three    1.301762
two      2.237808
dtype: float64

In [131]: df.apply(np.cumsum)
Out[131]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.765438 -0.177289  0.784662
c -0.753821  0.284925  0.335874
d       NaN  1.409398 -0.765684

In [132]: df.apply(np.exp)
Out[132]: 
        one     three       two
a  0.534436       NaN  0.703570
b  0.870320  0.837537  3.115063
c  1.011685  1.587586  0.638401
d       NaN  3.078592  0.332353
</pre> <p>Depending on the return type of the function passed to <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a>, the result will either be of lower dimension or the same dimension.</p> <p><a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a> combined with some cleverness can be used to answer many questions about a data set. For example, suppose we wanted to extract the date where the maximum value for each column occurred:</p> <pre data-language="python">In [133]: tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=1000))
   .....: 

In [134]: tsdf.apply(lambda x: x.idxmax())
Out[134]: 
A   2001-04-27
B   2002-06-02
C   2000-04-02
dtype: datetime64[ns]
</pre> <p>You may also pass additional arguments and keyword arguments to the <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a> method. For instance, consider the following function you would like to apply:</p> <pre data-language="python">def subtract_and_divide(x, sub, divide=1):
    return (x - sub) / divide
</pre> <p>You may then apply this function as follows:</p> <pre data-language="python">df.apply(subtract_and_divide, args=(5,), divide=3)
</pre> <p>Another useful feature is the ability to pass Series methods to carry out some Series operation on each column or row:</p> <pre data-language="python">In [135]: tsdf
Out[135]: 
                   A         B         C
2000-01-01  1.796883 -0.930690  3.542846
2000-01-02 -1.242888 -0.695279 -1.000884
2000-01-03 -0.720299  0.546303 -0.082042
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.527402  0.933507  0.129646
2000-01-09 -0.338903 -1.265452 -1.969004
2000-01-10  0.532566  0.341548  0.150493

In [136]: tsdf.apply(pd.Series.interpolate)
Out[136]: 
                   A         B         C
2000-01-01  1.796883 -0.930690  3.542846
2000-01-02 -1.242888 -0.695279 -1.000884
2000-01-03 -0.720299  0.546303 -0.082042
2000-01-04 -0.681720  0.623743 -0.039704
2000-01-05 -0.643140  0.701184  0.002633
2000-01-06 -0.604561  0.778625  0.044971
2000-01-07 -0.565982  0.856066  0.087309
2000-01-08 -0.527402  0.933507  0.129646
2000-01-09 -0.338903 -1.265452 -1.969004
2000-01-10  0.532566  0.341548  0.150493
</pre> <p>Finally, <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a> takes an argument <code>raw</code> which is False by default, which converts each row or column into a Series before applying the function. When set to True, the passed function will instead receive an ndarray object, which has positive performance implications if you do not need the indexing functionality.</p> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last">The section on <a class="reference internal" href="../groupby/#groupby">GroupBy</a> demonstrates related, flexible functionality for grouping by some criterion, applying, and combining the results into a Series, DataFrame, etc.</p> </div>   <h3 id="elementwise">Applying elementwise Python functions</h3> <p id="applying-elementwise-python-functions">Since not all functions can be vectorized (accept NumPy arrays and return another array or value), the methods <a class="reference internal" href="../generated/pandas.dataframe.applymap/#pandas.DataFrame.applymap" title="pandas.DataFrame.applymap"><code>applymap()</code></a> on DataFrame and analogously <a class="reference internal" href="../generated/pandas.series.map/#pandas.Series.map" title="pandas.Series.map"><code>map()</code></a> on Series accept any Python function taking a single value and returning a single value. For example:</p> <pre data-language="python">In [137]: df4
Out[137]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [138]: f = lambda x: len(str(x))

In [139]: df4['one'].map(f)
Out[139]: 
a    14
b    15
c    15
d     3
Name: one, dtype: int64

In [140]: df4.applymap(f)
Out[140]: 
   one  three  two
a   14      3   15
b   15     15   11
c   15     14   15
d    3     13   14
</pre> <p><a class="reference internal" href="../generated/pandas.series.map/#pandas.Series.map" title="pandas.Series.map"><code>Series.map()</code></a> has an additional feature which is that it can be used to easily “link” or “map” values defined by a secondary series. This is closely related to <a class="reference internal" href="../merging/#merging">merging/joining functionality</a>:</p> <pre data-language="python">In [141]: s = pd.Series(['six', 'seven', 'six', 'seven', 'six'],
   .....:               index=['a', 'b', 'c', 'd', 'e'])
   .....: 

In [142]: t = pd.Series({'six' : 6., 'seven' : 7.})

In [143]: s
Out[143]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [144]: s.map(t)
Out[144]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64
</pre>   <h3 id="basics-apply-panel">Applying with a Panel</h3> <p id="applying-with-a-panel">Applying with a <code>Panel</code> will pass a <code>Series</code> to the applied function. If the applied function returns a <code>Series</code>, the result of the application will be a <code>Panel</code>. If the applied function reduces to a scalar, the result of the application will be a <code>DataFrame</code>.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">Prior to 0.13.1 <code>apply</code> on a <code>Panel</code> would only work on <code>ufuncs</code> (e.g. <code>np.sum/np.max</code>).</p> </div> <pre data-language="python">In [145]: import pandas.util.testing as tm

In [146]: panel = tm.makePanel(5)

In [147]: panel
Out[147]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: ItemA to ItemC
Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00
Minor_axis axis: A to D

In [148]: panel['ItemA']
Out[148]: 
                   A         B         C         D
2000-01-03  0.330418  1.893177  0.801111  0.528154
2000-01-04  1.761200  0.170247  0.445614 -0.029371
2000-01-05  0.567133 -0.916844  1.453046 -0.631117
2000-01-06 -0.251020  0.835024  2.430373 -0.172441
2000-01-07  1.020099  1.259919  0.653093 -1.020485
</pre> <p>A transformational apply.</p> <pre data-language="python">In [149]: result = panel.apply(lambda x: x*2, axis='items')

In [150]: result
Out[150]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: ItemA to ItemC
Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00
Minor_axis axis: A to D

In [151]: result['ItemA']
Out[151]: 
                   A         B         C         D
2000-01-03  0.660836  3.786354  1.602222  1.056308
2000-01-04  3.522400  0.340494  0.891228 -0.058742
2000-01-05  1.134266 -1.833689  2.906092 -1.262234
2000-01-06 -0.502039  1.670047  4.860747 -0.344882
2000-01-07  2.040199  2.519838  1.306185 -2.040969
</pre> <p>A reduction operation.</p> <pre data-language="python">In [152]: panel.apply(lambda x: x.dtype, axis='items')
Out[152]: 
                  A        B        C        D
2000-01-03  float64  float64  float64  float64
2000-01-04  float64  float64  float64  float64
2000-01-05  float64  float64  float64  float64
2000-01-06  float64  float64  float64  float64
2000-01-07  float64  float64  float64  float64
</pre> <p>A similar reduction type operation</p> <pre data-language="python">In [153]: panel.apply(lambda x: x.sum(), axis='major_axis')
Out[153]: 
      ItemA     ItemB     ItemC
A  3.427831 -2.581431  0.840809
B  3.241522 -1.409935 -1.114512
C  5.783237  0.319672 -0.431906
D -1.325260 -2.914834  0.857043
</pre> <p>This last reduction is equivalent to</p> <pre data-language="python">In [154]: panel.sum('major_axis')
Out[154]: 
      ItemA     ItemB     ItemC
A  3.427831 -2.581431  0.840809
B  3.241522 -1.409935 -1.114512
C  5.783237  0.319672 -0.431906
D -1.325260 -2.914834  0.857043
</pre> <p>A transformation operation that returns a <code>Panel</code>, but is computing the z-score across the <code>major_axis</code>.</p> <pre data-language="python">In [155]: result = panel.apply(
   .....:            lambda x: (x-x.mean())/x.std(),
   .....:            axis='major_axis')
   .....: 

In [156]: result
Out[156]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 3 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: ItemA to ItemC
Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00
Minor_axis axis: A to D

In [157]: result['ItemA']
Out[157]: 
                   A         B         C         D
2000-01-03 -0.469761  1.156225 -0.441347  1.341731
2000-01-04  1.422763 -0.444015 -0.882647  0.398661
2000-01-05 -0.156654 -1.453694  0.367936 -0.619210
2000-01-06 -1.238841  0.173423  1.581149  0.156654
2000-01-07  0.442494  0.568061 -0.625091 -1.277837
</pre> <p>Apply can also accept multiple axes in the <code>axis</code> argument. This will pass a <code>DataFrame</code> of the cross-section to the applied function.</p> <pre data-language="python">In [158]: f = lambda x: ((x.T-x.mean(1))/x.std(1)).T

In [159]: result = panel.apply(f, axis = ['items','major_axis'])

In [160]: result
Out[160]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)
Items axis: A to D
Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00
Minor_axis axis: ItemA to ItemC

In [161]: result.loc[:,:,'ItemA']
Out[161]: 
                   A         B         C         D
2000-01-03  0.864236  1.132969  0.557316  0.575106
2000-01-04  0.795745  0.652527  0.534808 -0.070674
2000-01-05 -0.310864  0.558627  1.086688 -1.051477
2000-01-06 -0.001065  0.832460  0.846006  0.043602
2000-01-07  1.128946  1.152469 -0.218186 -0.891680
</pre> <p>This is equivalent to the following</p> <pre data-language="python">In [162]: result = pd.Panel(dict([ (ax, f(panel.loc[:,:,ax]))
   .....:                         for ax in panel.minor_axis ]))
   .....: 

In [163]: result
Out[163]: 
&lt;class 'pandas.core.panel.Panel'&gt;
Dimensions: 4 (items) x 5 (major_axis) x 3 (minor_axis)
Items axis: A to D
Major_axis axis: 2000-01-03 00:00:00 to 2000-01-07 00:00:00
Minor_axis axis: ItemA to ItemC

In [164]: result.loc[:,:,'ItemA']
Out[164]: 
                   A         B         C         D
2000-01-03  0.864236  1.132969  0.557316  0.575106
2000-01-04  0.795745  0.652527  0.534808 -0.070674
2000-01-05 -0.310864  0.558627  1.086688 -1.051477
2000-01-06 -0.001065  0.832460  0.846006  0.043602
2000-01-07  1.128946  1.152469 -0.218186 -0.891680
</pre>    <h2 id="basics-reindexing">Reindexing and altering labels</h2> <p id="reindexing-and-altering-labels"><a class="reference internal" href="../generated/pandas.series.reindex/#pandas.Series.reindex" title="pandas.Series.reindex"><code>reindex()</code></a> is the fundamental data alignment method in pandas. It is used to implement nearly all other features relying on label-alignment functionality. To <em>reindex</em> means to conform the data to match a given set of labels along a particular axis. This accomplishes several things:</p>  <ul class="simple"> <li>Reorders the existing data to match a new set of labels</li> <li>Inserts missing value (NA) markers in label locations where no data for that label existed</li> <li>If specified, <strong>fill</strong> data for missing labels using logic (highly relevant to working with time series data)</li> </ul>  <p>Here is a simple example:</p> <pre data-language="python">In [165]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [166]: s
Out[166]: 
a   -1.010924
b   -0.672504
c   -1.139222
d    0.354653
e    0.563622
dtype: float64

In [167]: s.reindex(['e', 'b', 'f', 'd'])
Out[167]: 
e    0.563622
b   -0.672504
f         NaN
d    0.354653
dtype: float64
</pre> <p>Here, the <code>f</code> label was not contained in the Series and hence appears as <code>NaN</code> in the result.</p> <p>With a DataFrame, you can simultaneously reindex the index and columns:</p> <pre data-language="python">In [168]: df
Out[168]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [169]: df.reindex(index=['c', 'f', 'b'], columns=['three', 'two', 'one'])
Out[169]: 
      three       two       one
c  0.462215 -0.448789  0.011617
f       NaN       NaN       NaN
b -0.177289  1.136249 -0.138894
</pre> <p>For convenience, you may utilize the <a class="reference internal" href="../generated/pandas.series.reindex_axis/#pandas.Series.reindex_axis" title="pandas.Series.reindex_axis"><code>reindex_axis()</code></a> method, which takes the labels and a keyword <code>axis</code> parameter.</p> <p>Note that the <code>Index</code> objects containing the actual axis labels can be <strong>shared</strong> between objects. So if we have a Series and a DataFrame, the following can be done:</p> <pre data-language="python">In [170]: rs = s.reindex(df.index)

In [171]: rs
Out[171]: 
a   -1.010924
b   -0.672504
c   -1.139222
d    0.354653
dtype: float64

In [172]: rs.index is df.index
Out[172]: True
</pre> <p>This means that the reindexed Series’s index is the same Python object as the DataFrame’s index.</p> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="../advanced/#advanced">MultiIndex / Advanced Indexing</a> is an even more concise way of doing reindexing.</p> </div> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">When writing performance-sensitive code, there is a good reason to spend some time becoming a reindexing ninja: <strong>many operations are faster on pre-aligned data</strong>. Adding two unaligned DataFrames internally triggers a reindexing step. For exploratory analysis you will hardly notice the difference (because <code>reindex</code> has been heavily optimized), but when CPU cycles matter sprinkling a few explicit <code>reindex</code> calls here and there can have an impact.</p> </div>  <h3 id="basics-reindex-like">Reindexing to align with another object</h3> <p id="reindexing-to-align-with-another-object">You may wish to take an object and reindex its axes to be labeled the same as another object. While the syntax for this is straightforward albeit verbose, it is a common enough operation that the <a class="reference internal" href="../generated/pandas.dataframe.reindex_like/#pandas.DataFrame.reindex_like" title="pandas.DataFrame.reindex_like"><code>reindex_like()</code></a> method is available to make this simpler:</p> <pre data-language="python">In [173]: df2
Out[173]: 
        one       two
a -0.626544 -0.351587
b -0.138894  1.136249
c  0.011617 -0.448789

In [174]: df3
Out[174]: 
        one       two
a -0.375270 -0.463545
b  0.112379  1.024292
c  0.262891 -0.560746

In [175]: df.reindex_like(df2)
Out[175]: 
        one       two
a -0.626544 -0.351587
b -0.138894  1.136249
c  0.011617 -0.448789
</pre>   <h3 id="basics-align">Aligning objects with each other with <code>align</code>
</h3> <p id="aligning-objects-with-each-other-with-align">The <a class="reference internal" href="../generated/pandas.series.align/#pandas.Series.align" title="pandas.Series.align"><code>align()</code></a> method is the fastest way to simultaneously align two objects. It supports a <code>join</code> argument (related to <a class="reference internal" href="../merging/#merging">joining and merging</a>):</p>  <ul class="simple"> <li>
<code>join='outer'</code>: take the union of the indexes (default)</li> <li>
<code>join='left'</code>: use the calling object’s index</li> <li>
<code>join='right'</code>: use the passed object’s index</li> <li>
<code>join='inner'</code>: intersect the indexes</li> </ul>  <p>It returns a tuple with both of the reindexed Series:</p> <pre data-language="python">In [176]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [177]: s1 = s[:4]

In [178]: s2 = s[1:]

In [179]: s1.align(s2)
Out[179]: 
(a   -0.365106
 b    1.092702
 c   -1.481449
 d    1.781190
 e         NaN
 dtype: float64, a         NaN
 b    1.092702
 c   -1.481449
 d    1.781190
 e   -0.031543
 dtype: float64)

In [180]: s1.align(s2, join='inner')
Out[180]: 
(b    1.092702
 c   -1.481449
 d    1.781190
 dtype: float64, b    1.092702
 c   -1.481449
 d    1.781190
 dtype: float64)

In [181]: s1.align(s2, join='left')
Out[181]: 
(a   -0.365106
 b    1.092702
 c   -1.481449
 d    1.781190
 dtype: float64, a         NaN
 b    1.092702
 c   -1.481449
 d    1.781190
 dtype: float64)
</pre> <p id="basics-df-join">For DataFrames, the join method will be applied to both the index and the columns by default:</p> <pre data-language="python">In [182]: df.align(df2, join='inner')
Out[182]: 
(        one       two
 a -0.626544 -0.351587
 b -0.138894  1.136249
 c  0.011617 -0.448789,         one       two
 a -0.626544 -0.351587
 b -0.138894  1.136249
 c  0.011617 -0.448789)
</pre> <p>You can also pass an <code>axis</code> option to only align on the specified axis:</p> <pre data-language="python">In [183]: df.align(df2, join='inner', axis=0)
Out[183]: 
(        one     three       two
 a -0.626544       NaN -0.351587
 b -0.138894 -0.177289  1.136249
 c  0.011617  0.462215 -0.448789,         one       two
 a -0.626544 -0.351587
 b -0.138894  1.136249
 c  0.011617 -0.448789)
</pre> <p id="basics-align-frame-series">If you pass a Series to <a class="reference internal" href="../generated/pandas.dataframe.align/#pandas.DataFrame.align" title="pandas.DataFrame.align"><code>DataFrame.align()</code></a>, you can choose to align both objects either on the DataFrame’s index or columns using the <code>axis</code> argument:</p> <pre data-language="python">In [184]: df.align(df2.ix[0], axis=1)
Out[184]: 
(        one     three       two
 a -0.626544       NaN -0.351587
 b -0.138894 -0.177289  1.136249
 c  0.011617  0.462215 -0.448789
 d       NaN  1.124472 -1.101558, one     -0.626544
 three         NaN
 two     -0.351587
 Name: a, dtype: float64)
</pre>   <h3 id="basics-reindex-fill">Filling while reindexing</h3> <p id="filling-while-reindexing"><a class="reference internal" href="../generated/pandas.series.reindex/#pandas.Series.reindex" title="pandas.Series.reindex"><code>reindex()</code></a> takes an optional parameter <code>method</code> which is a filling method chosen from the following table:</p> <table class="docutils">  <thead valign="bottom"> <tr class="row-odd">
<th class="head">Method</th> <th class="head">Action</th> </tr> </thead>  <tr class="row-even">
<td>pad / ffill</td> <td>Fill values forward</td> </tr> <tr class="row-odd">
<td>bfill / backfill</td> <td>Fill values backward</td> </tr> <tr class="row-even">
<td>nearest</td> <td>Fill from the nearest index value</td> </tr>  </table> <p>We illustrate these fill methods on a simple Series:</p> <pre data-language="python">In [185]: rng = pd.date_range('1/3/2000', periods=8)

In [186]: ts = pd.Series(np.random.randn(8), index=rng)

In [187]: ts2 = ts[[0, 3, 6]]

In [188]: ts
Out[188]: 
2000-01-03    0.480993
2000-01-04    0.604244
2000-01-05   -0.487265
2000-01-06    1.990533
2000-01-07    0.327007
2000-01-08    1.053639
2000-01-09   -2.927808
2000-01-10    0.082065
Freq: D, dtype: float64

In [189]: ts2
Out[189]: 
2000-01-03    0.480993
2000-01-06    1.990533
2000-01-09   -2.927808
dtype: float64

In [190]: ts2.reindex(ts.index)
Out[190]: 
2000-01-03    0.480993
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    1.990533
2000-01-07         NaN
2000-01-08         NaN
2000-01-09   -2.927808
2000-01-10         NaN
Freq: D, dtype: float64

In [191]: ts2.reindex(ts.index, method='ffill')
Out[191]: 
2000-01-03    0.480993
2000-01-04    0.480993
2000-01-05    0.480993
2000-01-06    1.990533
2000-01-07    1.990533
2000-01-08    1.990533
2000-01-09   -2.927808
2000-01-10   -2.927808
Freq: D, dtype: float64

In [192]: ts2.reindex(ts.index, method='bfill')
Out[192]: 
2000-01-03    0.480993
2000-01-04    1.990533
2000-01-05    1.990533
2000-01-06    1.990533
2000-01-07   -2.927808
2000-01-08   -2.927808
2000-01-09   -2.927808
2000-01-10         NaN
Freq: D, dtype: float64

In [193]: ts2.reindex(ts.index, method='nearest')
Out[193]: 
2000-01-03    0.480993
2000-01-04    0.480993
2000-01-05    1.990533
2000-01-06    1.990533
2000-01-07    1.990533
2000-01-08   -2.927808
2000-01-09   -2.927808
2000-01-10   -2.927808
Freq: D, dtype: float64
</pre> <p>These methods require that the indexes are <strong>ordered</strong> increasing or decreasing.</p> <p>Note that the same result could have been achieved using <a class="reference internal" href="../missing_data/#missing-data-fillna">fillna</a> (except for <code>method='nearest'</code>) or <a class="reference internal" href="../missing_data/#missing-data-interpolate">interpolate</a>:</p> <pre data-language="python">In [194]: ts2.reindex(ts.index).fillna(method='ffill')
Out[194]: 
2000-01-03    0.480993
2000-01-04    0.480993
2000-01-05    0.480993
2000-01-06    1.990533
2000-01-07    1.990533
2000-01-08    1.990533
2000-01-09   -2.927808
2000-01-10   -2.927808
Freq: D, dtype: float64
</pre> <p><a class="reference internal" href="../generated/pandas.series.reindex/#pandas.Series.reindex" title="pandas.Series.reindex"><code>reindex()</code></a> will raise a ValueError if the index is not monotonic increasing or decreasing. <a class="reference internal" href="../generated/pandas.series.fillna/#pandas.Series.fillna" title="pandas.Series.fillna"><code>fillna()</code></a> and <a class="reference internal" href="../generated/pandas.series.interpolate/#pandas.Series.interpolate" title="pandas.Series.interpolate"><code>interpolate()</code></a> will not make any checks on the order of the index.</p>   <h3 id="basics-limits-on-reindex-fill">Limits on filling while reindexing</h3> <p id="limits-on-filling-while-reindexing">The <code>limit</code> and <code>tolerance</code> arguments provide additional control over filling while reindexing. Limit specifies the maximum count of consecutive matches:</p> <pre data-language="python">In [195]: ts2.reindex(ts.index, method='ffill', limit=1)
Out[195]: 
2000-01-03    0.480993
2000-01-04    0.480993
2000-01-05         NaN
2000-01-06    1.990533
2000-01-07    1.990533
2000-01-08         NaN
2000-01-09   -2.927808
2000-01-10   -2.927808
Freq: D, dtype: float64
</pre> <p>In contrast, tolerance specifies the maximum distance between the index and indexer values:</p> <pre data-language="python">In [196]: ts2.reindex(ts.index, method='ffill', tolerance='1 day')
Out[196]: 
2000-01-03    0.480993
2000-01-04    0.480993
2000-01-05         NaN
2000-01-06    1.990533
2000-01-07    1.990533
2000-01-08         NaN
2000-01-09   -2.927808
2000-01-10   -2.927808
Freq: D, dtype: float64
</pre> <p>Notice that when used on a <code>DatetimeIndex</code>, <code>TimedeltaIndex</code> or <code>PeriodIndex</code>, <code>tolerance</code> will coerced into a <code>Timedelta</code> if possible. This allows you to specify tolerance with appropriate strings.</p>   <h3 id="basics-drop">Dropping labels from an axis</h3> <p id="dropping-labels-from-an-axis">A method closely related to <code>reindex</code> is the <a class="reference internal" href="../generated/pandas.dataframe.drop/#pandas.DataFrame.drop" title="pandas.DataFrame.drop"><code>drop()</code></a> function. It removes a set of labels from an axis:</p> <pre data-language="python">In [197]: df
Out[197]: 
        one     three       two
a -0.626544       NaN -0.351587
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
d       NaN  1.124472 -1.101558

In [198]: df.drop(['a', 'd'], axis=0)
Out[198]: 
        one     three       two
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789

In [199]: df.drop(['one'], axis=1)
Out[199]: 
      three       two
a       NaN -0.351587
b -0.177289  1.136249
c  0.462215 -0.448789
d  1.124472 -1.101558
</pre> <p>Note that the following also works, but is a bit less obvious / clean:</p> <pre data-language="python">In [200]: df.reindex(df.index.difference(['a', 'd']))
Out[200]: 
        one     three       two
b -0.138894 -0.177289  1.136249
c  0.011617  0.462215 -0.448789
</pre>   <h3 id="basics-rename">Renaming / mapping labels</h3> <p id="renaming-mapping-labels">The <a class="reference internal" href="../generated/pandas.dataframe.rename/#pandas.DataFrame.rename" title="pandas.DataFrame.rename"><code>rename()</code></a> method allows you to relabel an axis based on some mapping (a dict or Series) or an arbitrary function.</p> <pre data-language="python">In [201]: s
Out[201]: 
a   -0.365106
b    1.092702
c   -1.481449
d    1.781190
e   -0.031543
dtype: float64

In [202]: s.rename(str.upper)
Out[202]: 
A   -0.365106
B    1.092702
C   -1.481449
D    1.781190
E   -0.031543
dtype: float64
</pre> <p>If you pass a function, it must return a value when called with any of the labels (and must produce a set of unique values). But if you pass a dict or Series, it need only contain a subset of the labels as keys:</p> <pre data-language="python">In [203]: df.rename(columns={'one' : 'foo', 'two' : 'bar'},
   .....:           index={'a' : 'apple', 'b' : 'banana', 'd' : 'durian'})
   .....: 
Out[203]: 
             foo     three       bar
apple  -0.626544       NaN -0.351587
banana -0.138894 -0.177289  1.136249
c       0.011617  0.462215 -0.448789
durian       NaN  1.124472 -1.101558
</pre> <p>The <a class="reference internal" href="../generated/pandas.dataframe.rename/#pandas.DataFrame.rename" title="pandas.DataFrame.rename"><code>rename()</code></a> method also provides an <code>inplace</code> named parameter that is by default <code>False</code> and copies the underlying data. Pass <code>inplace=True</code> to rename the data in place.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.18.0.</span></p> </div> <p>Finally, <a class="reference internal" href="../generated/pandas.series.rename/#pandas.Series.rename" title="pandas.Series.rename"><code>rename()</code></a> also accepts a scalar or list-like for altering the <code>Series.name</code> attribute.</p> <pre data-language="python">In [204]: s.rename("scalar-name")
Out[204]: 
a   -0.365106
b    1.092702
c   -1.481449
d    1.781190
e   -0.031543
Name: scalar-name, dtype: float64
</pre> <p id="basics-rename-axis">The Panel class has a related <a class="reference internal" href="../generated/pandas.panel.rename_axis/#pandas.Panel.rename_axis" title="pandas.Panel.rename_axis"><code>rename_axis()</code></a> class which can rename any of its three axes.</p>    <h2 id="basics-iteration">Iteration</h2> <p id="iteration">The behavior of basic iteration over pandas objects depends on the type. When iterating over a Series, it is regarded as array-like, and basic iteration produces the values. Other data structures, like DataFrame and Panel, follow the dict-like convention of iterating over the “keys” of the objects.</p> <p>In short, basic iteration (<code>for i in object</code>) produces:</p> <ul class="simple"> <li>
<strong>Series</strong>: values</li> <li>
<strong>DataFrame</strong>: column labels</li> <li>
<strong>Panel</strong>: item labels</li> </ul> <p>Thus, for example, iterating over a DataFrame gives you the column names:</p> <pre data-language="python">In [205]: df = pd.DataFrame({'col1' : np.random.randn(3), 'col2' : np.random.randn(3)},
   .....:                   index=['a', 'b', 'c'])
   .....: 

In [206]: for col in df:
   .....:     print(col)
   .....: 
col1
col2
</pre> <p>Pandas objects also have the dict-like <a class="reference internal" href="../generated/pandas.dataframe.iteritems/#pandas.DataFrame.iteritems" title="pandas.DataFrame.iteritems"><code>iteritems()</code></a> method to iterate over the (key, value) pairs.</p> <p>To iterate over the rows of a DataFrame, you can use the following methods:</p> <ul class="simple"> <li>
<a class="reference internal" href="../generated/pandas.dataframe.iterrows/#pandas.DataFrame.iterrows" title="pandas.DataFrame.iterrows"><code>iterrows()</code></a>: Iterate over the rows of a DataFrame as (index, Series) pairs. This converts the rows to Series objects, which can change the dtypes and has some performance implications.</li> <li>
<a class="reference internal" href="../generated/pandas.dataframe.itertuples/#pandas.DataFrame.itertuples" title="pandas.DataFrame.itertuples"><code>itertuples()</code></a>: Iterate over the rows of a DataFrame as namedtuples of the values. This is a lot faster than <a class="reference internal" href="../generated/pandas.dataframe.iterrows/#pandas.DataFrame.iterrows" title="pandas.DataFrame.iterrows"><code>iterrows()</code></a>, and is in most cases preferable to use to iterate over the values of a DataFrame.</li> </ul> <div class="admonition warning"> <p class="first admonition-title">Warning</p> <p>Iterating through pandas objects is generally <strong>slow</strong>. In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches:</p> <ul class="last simple"> <li>Look for a <em>vectorized</em> solution: many operations can be performed using built-in methods or numpy functions, (boolean) indexing, ...</li> <li>When you have a function that cannot work on the full DataFrame/Series at once, it is better to use <a class="reference internal" href="../generated/pandas.dataframe.apply/#pandas.DataFrame.apply" title="pandas.DataFrame.apply"><code>apply()</code></a> instead of iterating over the values. See the docs on <a class="reference internal" href="#basics-apply">function application</a>.</li> <li>If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop using e.g. cython or numba. See the <a class="reference internal" href="../enhancingperf/#enhancingperf">enhancing performance</a> section for some examples of this approach.</li> </ul> </div> <div class="admonition warning"> <p class="first admonition-title">Warning</p> <p>You should <strong>never modify</strong> something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect!</p> <p>For example, in the following case setting the value has no effect:</p> <pre data-language="python">In [207]: df = pd.DataFrame({'a': [1, 2, 3], 'b': ['a', 'b', 'c']})

In [208]: for index, row in df.iterrows():
   .....:     row['a'] = 10
   .....: 

In [209]: df
Out[209]: 
   a  b
0  1  a
1  2  b
2  3  c
</pre> </div>  <h3 id="iteritems">iteritems</h3> <p>Consistent with the dict-like interface, <a class="reference internal" href="../generated/pandas.dataframe.iteritems/#pandas.DataFrame.iteritems" title="pandas.DataFrame.iteritems"><code>iteritems()</code></a> iterates through key-value pairs:</p> <ul class="simple"> <li>
<strong>Series</strong>: (index, scalar value) pairs</li> <li>
<strong>DataFrame</strong>: (column, Series) pairs</li> <li>
<strong>Panel</strong>: (item, DataFrame) pairs</li> </ul> <p>For example:</p> <pre data-language="python">In [210]: for item, frame in wp.iteritems():
   .....:     print(item)
   .....:     print(frame)
   .....: 
Item1
                   A         B         C         D
2000-01-01 -1.032011  0.969818 -0.962723  1.382083
2000-01-02 -0.938794  0.669142 -0.433567 -0.273610
2000-01-03  0.680433 -0.308450 -0.276099 -1.821168
2000-01-04 -1.993606 -1.927385 -2.027924  1.624972
2000-01-05  0.551135  3.059267  0.455264 -0.030740
Item2
                   A         B         C         D
2000-01-01  0.935716  1.061192 -2.107852  0.199905
2000-01-02  0.323586 -0.641630 -0.587514  0.053897
2000-01-03  0.194889 -0.381994  0.318587  2.089075
2000-01-04 -0.728293 -0.090255 -0.748199  1.318931
2000-01-05 -2.029766  0.792652  0.461007 -0.542749
</pre>   <h3 id="basics-iterrows">iterrows</h3> <p id="iterrows"><a class="reference internal" href="../generated/pandas.dataframe.iterrows/#pandas.DataFrame.iterrows" title="pandas.DataFrame.iterrows"><code>iterrows()</code></a> allows you to iterate through the rows of a DataFrame as Series objects. It returns an iterator yielding each index value along with a Series containing the data in each row:</p> <pre data-language="python">In [211]: for row_index, row in df.iterrows():
   .....:     print('%s\n%s' % (row_index, row))
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object
</pre> <div class="admonition note"> <p class="first admonition-title">Note</p> <p>Because <a class="reference internal" href="../generated/pandas.dataframe.iterrows/#pandas.DataFrame.iterrows" title="pandas.DataFrame.iterrows"><code>iterrows()</code></a> returns a Series for each row, it does <strong>not</strong> preserve dtypes across the rows (dtypes are preserved across columns for DataFrames). For example,</p> <pre data-language="python">In [212]: df_orig = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])

In [213]: df_orig.dtypes
Out[213]: 
int        int64
float    float64
dtype: object

In [214]: row = next(df_orig.iterrows())[1]

In [215]: row
Out[215]: 
int      1.0
float    1.5
Name: 0, dtype: float64
</pre> <p>All values in <code>row</code>, returned as a Series, are now upcasted to floats, also the original integer value in column <code>x</code>:</p> <pre data-language="python">In [216]: row['int'].dtype
Out[216]: dtype('float64')

In [217]: df_orig['int'].dtype
Out[217]: dtype('int64')
</pre> <p class="last">To preserve dtypes while iterating over the rows, it is better to use <a class="reference internal" href="../generated/pandas.dataframe.itertuples/#pandas.DataFrame.itertuples" title="pandas.DataFrame.itertuples"><code>itertuples()</code></a> which returns namedtuples of the values and which is generally much faster as <code>iterrows</code>.</p> </div> <p>For instance, a contrived way to transpose the DataFrame would be:</p> <pre data-language="python">In [218]: df2 = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})

In [219]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [220]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [221]: df2_t = pd.DataFrame(dict((idx,values) for idx, values in df2.iterrows()))

In [222]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6
</pre>   <h3 id="itertuples">itertuples</h3> <p>The <a class="reference internal" href="../generated/pandas.dataframe.itertuples/#pandas.DataFrame.itertuples" title="pandas.DataFrame.itertuples"><code>itertuples()</code></a> method will return an iterator yielding a namedtuple for each row in the DataFrame. The first element of the tuple will be the row’s corresponding index value, while the remaining values are the row values.</p> <p>For instance,</p> <pre data-language="python">In [223]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')
</pre> <p>This method does not convert the row to a Series object but just returns the values inside a namedtuple. Therefore, <a class="reference internal" href="../generated/pandas.dataframe.itertuples/#pandas.DataFrame.itertuples" title="pandas.DataFrame.itertuples"><code>itertuples()</code></a> preserves the data type of the values and is generally faster as <a class="reference internal" href="../generated/pandas.dataframe.iterrows/#pandas.DataFrame.iterrows" title="pandas.DataFrame.iterrows"><code>iterrows()</code></a>.</p> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (&gt;255), regular tuples are returned.</p> </div>    <h2 id="basics-dt-accessors">.dt accessor</h2> <p id="dt-accessor"><code>Series</code> has an accessor to succinctly return datetime like properties for the <em>values</em> of the Series, if it is a datetime/period like Series. This will return a Series, indexed like the existing Series.</p> <pre data-language="python"># datetime
In [224]: s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))

In [225]: s
Out[225]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [226]: s.dt.hour
Out[226]: 
0    9
1    9
2    9
3    9
dtype: int64

In [227]: s.dt.second
Out[227]: 
0    12
1    12
2    12
3    12
dtype: int64

In [228]: s.dt.day
Out[228]: 
0    1
1    2
2    3
3    4
dtype: int64
</pre> <p>This enables nice expressions like this:</p> <pre data-language="python">In [229]: s[s.dt.day==2]
Out[229]: 
1   2013-01-02 09:10:12
dtype: datetime64[ns]
</pre> <p>You can easily produces tz aware transformations:</p> <pre data-language="python">In [230]: stz = s.dt.tz_localize('US/Eastern')

In [231]: stz
Out[231]: 
0   2013-01-01 09:10:12-05:00
1   2013-01-02 09:10:12-05:00
2   2013-01-03 09:10:12-05:00
3   2013-01-04 09:10:12-05:00
dtype: datetime64[ns, US/Eastern]

In [232]: stz.dt.tz
Out[232]: &lt;DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD&gt;
</pre> <p>You can also chain these types of operations:</p> <pre data-language="python">In [233]: s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')
Out[233]: 
0   2013-01-01 04:10:12-05:00
1   2013-01-02 04:10:12-05:00
2   2013-01-03 04:10:12-05:00
3   2013-01-04 04:10:12-05:00
dtype: datetime64[ns, US/Eastern]
</pre> <p>You can also format datetime values as strings with <a class="reference internal" href="../generated/pandas.series.dt.strftime/#pandas.Series.dt.strftime" title="pandas.Series.dt.strftime"><code>Series.dt.strftime()</code></a> which supports the same format as the standard <a class="reference external" href="http://docs.python.org/3/library/datetime.html#datetime.datetime.strftime" title="(in Python v3.5)" target="_blank"><code>strftime()</code></a>.</p> <pre data-language="python"># DatetimeIndex
In [234]: s = pd.Series(pd.date_range('20130101', periods=4))

In [235]: s
Out[235]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [236]: s.dt.strftime('%Y/%m/%d')
Out[236]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
</pre> <pre data-language="python"># PeriodIndex
In [237]: s = pd.Series(pd.period_range('20130101', periods=4))

In [238]: s
Out[238]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: object

In [239]: s.dt.strftime('%Y/%m/%d')
Out[239]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
</pre> <p>The <code>.dt</code> accessor works for period and timedelta dtypes.</p> <pre data-language="python"># period
In [240]: s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))

In [241]: s
Out[241]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: object

In [242]: s.dt.year
Out[242]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [243]: s.dt.day
Out[243]: 
0    1
1    2
2    3
3    4
dtype: int64
</pre> <pre data-language="python"># timedelta
In [244]: s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))

In [245]: s
Out[245]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [246]: s.dt.days
Out[246]: 
0    1
1    1
2    1
3    1
dtype: int64

In [247]: s.dt.seconds
Out[247]: 
0    5
1    6
2    7
3    8
dtype: int64

In [248]: s.dt.components
Out[248]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0
</pre> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last"><code>Series.dt</code> will raise a <code>TypeError</code> if you access with a non-datetimelike values</p> </div>   <h2 id="vectorized-string-methods">Vectorized string methods</h2> <p>Series is equipped with a set of string processing methods that make it easy to operate on each element of the array. Perhaps most importantly, these methods exclude missing/NA values automatically. These are accessed via the Series’s <code>str</code> attribute and generally have names matching the equivalent (scalar) built-in string methods. For example:</p>  <pre data-language="python">In [249]: s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])

In [250]: s.str.lower()
Out[250]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object
</pre>  <p>Powerful pattern-matching methods are provided as well, but note that pattern-matching generally uses <a class="reference external" href="https://docs.python.org/2/library/re.html" target="_blank">regular expressions</a> by default (and in some cases always uses them).</p> <p>Please see <a class="reference internal" href="../text/#text-string-methods">Vectorized String Methods</a> for a complete description.</p>   <h2 id="basics-sorting">Sorting</h2> <div class="admonition warning" id="sorting"> <p class="first admonition-title">Warning</p> <p class="last">The sorting API is substantially changed in 0.17.0, see <a class="reference internal" href="http://pandas.pydata.org/pandas-docs/version/0.18.1/whatsnew.html#whatsnew-0170-api-breaking-sorting" target="_blank">here</a> for these changes. In particular, all sorting methods now return a new object by default, and <strong>DO NOT</strong> operate in-place (except by passing <code>inplace=True</code>).</p> </div> <p>There are two obvious kinds of sorting that you may be interested in: sorting by label and sorting by actual values.</p>  <h3 id="by-index">By Index</h3> <p>The primary method for sorting axis labels (indexes) are the <code>Series.sort_index()</code> and the <code>DataFrame.sort_index()</code> methods.</p> <pre data-language="python">In [251]: unsorted_df = df.reindex(index=['a', 'd', 'c', 'b'],
   .....:                          columns=['three', 'two', 'one'])
   .....: 

# DataFrame
In [252]: unsorted_df.sort_index()
Out[252]: 
   three  two  one
a    NaN  NaN  NaN
b    NaN  NaN  NaN
c    NaN  NaN  NaN
d    NaN  NaN  NaN

In [253]: unsorted_df.sort_index(ascending=False)
Out[253]: 
   three  two  one
d    NaN  NaN  NaN
c    NaN  NaN  NaN
b    NaN  NaN  NaN
a    NaN  NaN  NaN

In [254]: unsorted_df.sort_index(axis=1)
Out[254]: 
   one  three  two
a  NaN    NaN  NaN
d  NaN    NaN  NaN
c  NaN    NaN  NaN
b  NaN    NaN  NaN

# Series
In [255]: unsorted_df['three'].sort_index()
Out[255]: 
a   NaN
b   NaN
c   NaN
d   NaN
Name: three, dtype: float64
</pre>   <h3 id="by-values">By Values</h3> <p>The <a class="reference internal" href="../generated/pandas.series.sort_values/#pandas.Series.sort_values" title="pandas.Series.sort_values"><code>Series.sort_values()</code></a> and <a class="reference internal" href="../generated/pandas.dataframe.sort_values/#pandas.DataFrame.sort_values" title="pandas.DataFrame.sort_values"><code>DataFrame.sort_values()</code></a> are the entry points for <strong>value</strong> sorting (that is the values in a column or row). <a class="reference internal" href="../generated/pandas.dataframe.sort_values/#pandas.DataFrame.sort_values" title="pandas.DataFrame.sort_values"><code>DataFrame.sort_values()</code></a> can accept an optional <code>by</code> argument for <code>axis=0</code> which will use an arbitrary vector or a column name of the DataFrame to determine the sort order:</p> <pre data-language="python">In [256]: df1 = pd.DataFrame({'one':[2,1,1,1],'two':[1,3,2,4],'three':[5,4,3,2]})

In [257]: df1.sort_values(by='two')
Out[257]: 
   one  three  two
0    2      5    1
2    1      3    2
1    1      4    3
3    1      2    4
</pre> <p>The <code>by</code> argument can take a list of column names, e.g.:</p> <pre data-language="python">In [258]: df1[['one', 'two', 'three']].sort_values(by=['one','two'])
Out[258]: 
   one  two  three
2    1    2      3
1    1    3      4
3    1    4      2
0    2    1      5
</pre> <p>These methods have special treatment of NA values via the <code>na_position</code> argument:</p> <pre data-language="python">In [259]: s[2] = np.nan

In [260]: s.sort_values()
Out[260]: 
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
2     NaN
5     NaN
dtype: object

In [261]: s.sort_values(na_position='first')
Out[261]: 
2     NaN
5     NaN
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
dtype: object
</pre>   <h3 id="basics-searchsorted">searchsorted</h3> <p id="searchsorted">Series has the <a class="reference internal" href="../generated/pandas.series.searchsorted/#pandas.Series.searchsorted" title="pandas.Series.searchsorted"><code>searchsorted()</code></a> method, which works similar to <a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.searchsorted.html#numpy.ndarray.searchsorted" title="(in NumPy v1.10)" target="_blank"><code>numpy.ndarray.searchsorted()</code></a>.</p> <pre data-language="python">In [262]: ser = pd.Series([1, 2, 3])

In [263]: ser.searchsorted([0, 3])
Out[263]: array([0, 2])

In [264]: ser.searchsorted([0, 4])
Out[264]: array([0, 3])

In [265]: ser.searchsorted([1, 3], side='right')
Out[265]: array([1, 3])

In [266]: ser.searchsorted([1, 3], side='left')
Out[266]: array([0, 2])

In [267]: ser = pd.Series([3, 1, 2])

In [268]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[268]: array([0, 2])
</pre>   <h3 id="basics-nsorted">smallest / largest values</h3> <div class="versionadded" id="smallest-largest-values"> <p><span class="versionmodified">New in version 0.14.0.</span></p> </div> <p><code>Series</code> has the <a class="reference internal" href="../generated/pandas.series.nsmallest/#pandas.Series.nsmallest" title="pandas.Series.nsmallest"><code>nsmallest()</code></a> and <a class="reference internal" href="../generated/pandas.series.nlargest/#pandas.Series.nlargest" title="pandas.Series.nlargest"><code>nlargest()</code></a> methods which return the smallest or largest <img class="math" src="http://pandas.pydata.org/pandas-docs/version/0.18.1/_images/math/413f8a8e40062a9090d9d50b88bc7b551b314c26.png" alt="n"> values. For a large <code>Series</code> this can be much faster than sorting the entire Series and calling <code>head(n)</code> on the result.</p> <pre data-language="python">In [269]: s = pd.Series(np.random.permutation(10))

In [270]: s
Out[270]: 
0    9
1    8
2    5
3    3
4    6
5    7
6    0
7    2
8    4
9    1
dtype: int64

In [271]: s.sort_values()
Out[271]: 
6    0
9    1
7    2
3    3
8    4
2    5
4    6
5    7
1    8
0    9
dtype: int64

In [272]: s.nsmallest(3)
Out[272]: 
6    0
9    1
7    2
dtype: int64

In [273]: s.nlargest(3)
Out[273]: 
0    9
1    8
5    7
dtype: int64
</pre> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17.0.</span></p> </div> <p><code>DataFrame</code> also has the <code>nlargest</code> and <code>nsmallest</code> methods.</p> <pre data-language="python">In [274]: df = pd.DataFrame({'a': [-2, -1, 1, 10, 8, 11, -1],
   .....:                    'b': list('abdceff'),
   .....:                    'c': [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0]})
   .....: 

In [275]: df.nlargest(3, 'a')
Out[275]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [276]: df.nlargest(5, ['a', 'c'])
Out[276]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0
1  -1  b  2.0

In [277]: df.nsmallest(3, 'a')
Out[277]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [278]: df.nsmallest(5, ['a', 'c'])
Out[278]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0
2  1  d  4.0
4  8  e  NaN
</pre>   <h3 id="basics-multi-index-sorting">Sorting by a multi-index column</h3> <p id="sorting-by-a-multi-index-column">You must be explicit about sorting when the column is a multi-index, and fully specify all levels to <code>by</code>.</p> <pre data-language="python">In [279]: df1.columns = pd.MultiIndex.from_tuples([('a','one'),('a','two'),('b','three')])

In [280]: df1.sort_values(by=('a','two'))
Out[280]: 
    a         b
  one two three
3   1   2     4
2   1   3     2
1   1   4     3
0   2   5     1
</pre>    <h2 id="copying">Copying</h2> <p>The <a class="reference internal" href="../generated/pandas.dataframe.copy/#pandas.DataFrame.copy" title="pandas.DataFrame.copy"><code>copy()</code></a> method on pandas objects copies the underlying data (though not the axis indexes, since they are immutable) and returns a new object. Note that <strong>it is seldom necessary to copy objects</strong>. For example, there are only a handful of ways to alter a DataFrame <em>in-place</em>:</p>  <ul class="simple"> <li>Inserting, deleting, or modifying a column</li> <li>Assigning to the <code>index</code> or <code>columns</code> attributes</li> <li>For homogeneous data, directly modifying the values via the <code>values</code> attribute or advanced indexing</li> </ul>  <p>To be clear, no pandas methods have the side effect of modifying your data; almost all methods return new objects, leaving the original object untouched. If data is modified, it is because you did so explicitly.</p>   <h2 id="basics-dtypes">dtypes</h2> <p id="dtypes">The main types stored in pandas objects are <code>float</code>, <code>int</code>, <code>bool</code>, <code>datetime64[ns]</code> and <code>datetime64[ns, tz]</code> (in &gt;= 0.17.0), <code>timedelta[ns]</code>, <code>category</code> (in &gt;= 0.15.0), and <code>object</code>. In addition these dtypes have item sizes, e.g. <code>int64</code> and <code>int32</code>. See <a class="reference internal" href="../timeseries/#timeseries-timezone-series">Series with TZ</a> for more detail on <code>datetime64[ns, tz]</code> dtypes.</p> <p>A convenient <a class="reference internal" href="../generated/pandas.dataframe.dtypes/#pandas.DataFrame.dtypes" title="pandas.DataFrame.dtypes"><code>dtypes</code></a> attribute for DataFrames returns a Series with the data type of each column.</p> <pre data-language="python">In [281]: dft = pd.DataFrame(dict(A = np.random.rand(3),
   .....:                         B = 1,
   .....:                         C = 'foo',
   .....:                         D = pd.Timestamp('20010102'),
   .....:                         E = pd.Series([1.0]*3).astype('float32'),
   .....:                                     F = False,
   .....:                                     G = pd.Series([1]*3,dtype='int8')))
   .....: 

In [282]: dft
Out[282]: 
          A  B    C          D    E      F  G
0  0.954940  1  foo 2001-01-02  1.0  False  1
1  0.318163  1  foo 2001-01-02  1.0  False  1
2  0.985803  1  foo 2001-01-02  1.0  False  1

In [283]: dft.dtypes
Out[283]: 
A           float64
B             int64
C            object
D    datetime64[ns]
E           float32
F              bool
G              int8
dtype: object
</pre> <p>On a <code>Series</code> use the <a class="reference internal" href="../generated/pandas.series.dtype/#pandas.Series.dtype" title="pandas.Series.dtype"><code>dtype</code></a> attribute.</p> <pre data-language="python">In [284]: dft['A'].dtype
Out[284]: dtype('float64')
</pre> <p>If a pandas object contains data multiple dtypes <em>IN A SINGLE COLUMN</em>, the dtype of the column will be chosen to accommodate all of the data types (<code>object</code> is the most general).</p> <pre data-language="python"># these ints are coerced to floats
In [285]: pd.Series([1, 2, 3, 4, 5, 6.])
Out[285]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [286]: pd.Series([1, 2, 3, 6., 'foo'])
Out[286]: 
0      1
1      2
2      3
3      6
4    foo
dtype: object
</pre> <p>The method <a class="reference internal" href="../generated/pandas.dataframe.get_dtype_counts/#pandas.DataFrame.get_dtype_counts" title="pandas.DataFrame.get_dtype_counts"><code>get_dtype_counts()</code></a> will return the number of columns of each type in a <code>DataFrame</code>:</p> <pre data-language="python">In [287]: dft.get_dtype_counts()
Out[287]: 
bool              1
datetime64[ns]    1
float32           1
float64           1
int64             1
int8              1
object            1
dtype: int64
</pre> <p>Numeric dtypes will propagate and can coexist in DataFrames (starting in v0.11.0). If a dtype is passed (either directly via the <code>dtype</code> keyword, a passed <code>ndarray</code>, or a passed <code>Series</code>, then it will be preserved in DataFrame operations. Furthermore, different numeric dtypes will <strong>NOT</strong> be combined. The following example will give you a taste.</p> <pre data-language="python">In [288]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=['A'], dtype='float32')

In [289]: df1
Out[289]: 
          A
0  0.647650
1  0.822993
2  1.778703
3 -1.543048
4 -0.123256
5  2.239740
6 -0.143778
7 -2.885090

In [290]: df1.dtypes
Out[290]: 
A    float32
dtype: object

In [291]: df2 = pd.DataFrame(dict( A = pd.Series(np.random.randn(8), dtype='float16'),
   .....:                         B = pd.Series(np.random.randn(8)),
   .....:                         C = pd.Series(np.array(np.random.randn(8), dtype='uint8')) ))
   .....: 

In [292]: df2
Out[292]: 
          A         B    C
0  0.027588  0.296947    0
1 -1.150391  0.007045  255
2  0.246460  0.707877    1
3 -0.455078  0.950661    0
4 -1.507812  0.087527    0
5 -0.502441 -0.339212    0
6  0.528809 -0.278698    0
7  0.590332  1.775379    0

In [293]: df2.dtypes
Out[293]: 
A    float16
B    float64
C      uint8
dtype: object
</pre>  <h3 id="defaults">defaults</h3> <p>By default integer types are <code>int64</code> and float types are <code>float64</code>, <em>REGARDLESS</em> of platform (32-bit or 64-bit). The following will all result in <code>int64</code> dtypes.</p> <pre data-language="python">In [294]: pd.DataFrame([1, 2], columns=['a']).dtypes
Out[294]: 
a    int64
dtype: object

In [295]: pd.DataFrame({'a': [1, 2]}).dtypes
Out[295]: 
a    int64
dtype: object

In [296]: pd.DataFrame({'a': 1 }, index=list(range(2))).dtypes
Out[296]: 
a    int64
dtype: object
</pre> <p>Numpy, however will choose <em>platform-dependent</em> types when creating arrays. The following <strong>WILL</strong> result in <code>int32</code> on 32-bit platform.</p> <pre data-language="python">In [297]: frame = pd.DataFrame(np.array([1, 2]))
</pre>   <h3 id="upcasting">upcasting</h3> <p>Types can potentially be <em>upcasted</em> when combined with other types, meaning they are promoted from the current type (say <code>int</code> to <code>float</code>)</p> <pre data-language="python">In [298]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [299]: df3
Out[299]: 
          A         B      C
0  0.675238  0.296947    0.0
1 -0.327398  0.007045  255.0
2  2.025163  0.707877    1.0
3 -1.998126  0.950661    0.0
4 -1.631068  0.087527    0.0
5  1.737299 -0.339212    0.0
6  0.385030 -0.278698    0.0
7 -2.294758  1.775379    0.0

In [300]: df3.dtypes
Out[300]: 
A    float32
B    float64
C    float64
dtype: object
</pre> <p>The <code>values</code> attribute on a DataFrame return the <em>lower-common-denominator</em> of the dtypes, meaning the dtype that can accommodate <strong>ALL</strong> of the types in the resulting homogeneous dtyped numpy array. This can force some <em>upcasting</em>.</p> <pre data-language="python">In [301]: df3.values.dtype
Out[301]: dtype('float64')
</pre>   <h3 id="astype">astype</h3> <p id="basics-cast">You can use the <a class="reference internal" href="../generated/pandas.dataframe.astype/#pandas.DataFrame.astype" title="pandas.DataFrame.astype"><code>astype()</code></a> method to explicitly convert dtypes from one to another. These will by default return a copy, even if the dtype was unchanged (pass <code>copy=False</code> to change this behavior). In addition, they will raise an exception if the astype operation is invalid.</p> <p>Upcasting is always according to the <strong>numpy</strong> rules. If two different dtypes are involved in an operation, then the more <em>general</em> one will be used as the result of the operation.</p> <pre data-language="python">In [302]: df3
Out[302]: 
          A         B      C
0  0.675238  0.296947    0.0
1 -0.327398  0.007045  255.0
2  2.025163  0.707877    1.0
3 -1.998126  0.950661    0.0
4 -1.631068  0.087527    0.0
5  1.737299 -0.339212    0.0
6  0.385030 -0.278698    0.0
7 -2.294758  1.775379    0.0

In [303]: df3.dtypes
Out[303]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [304]: df3.astype('float32').dtypes
Out[304]: 
A    float32
B    float32
C    float32
dtype: object
</pre>   <h3 id="object-conversion">object conversion</h3> <p><a class="reference internal" href="../generated/pandas.dataframe.convert_objects/#pandas.DataFrame.convert_objects" title="pandas.DataFrame.convert_objects"><code>convert_objects()</code></a> is a method to try to force conversion of types from the <code>object</code> dtype to other types. To force conversion of specific types that are <em>number like</em>, e.g. could be a string that represents a number, pass <code>convert_numeric=True</code>. This will force strings and numbers alike to be numbers if possible, otherwise they will be set to <code>np.nan</code>.</p> <pre data-language="python">In [305]: df3['D'] = '1.'

In [306]: df3['E'] = '1'

In [307]: df3.convert_objects(convert_numeric=True).dtypes
Out[307]: 
A    float32
B    float64
C    float64
D    float64
E      int64
dtype: object

# same, but specific dtype conversion
In [308]: df3['D'] = df3['D'].astype('float16')

In [309]: df3['E'] = df3['E'].astype('int32')

In [310]: df3.dtypes
Out[310]: 
A    float32
B    float64
C    float64
D    float16
E      int32
dtype: object
</pre> <p>To force conversion to <code>datetime64[ns]</code>, pass <code>convert_dates='coerce'</code>. This will convert any datetime-like object to dates, forcing other values to <code>NaT</code>. This might be useful if you are reading in data which is mostly dates, but occasionally has non-dates intermixed and you want to represent as missing.</p> <pre data-language="python">In [311]: import datetime

In [312]: s = pd.Series([datetime.datetime(2001,1,1,0,0),
   .....:               'foo', 1.0, 1, pd.Timestamp('20010104'),
   .....:               '20010105'], dtype='O')
   .....: 

In [313]: s
Out[313]: 
0    2001-01-01 00:00:00
1                    foo
2                      1
3                      1
4    2001-01-04 00:00:00
5               20010105
dtype: object

In [314]: pd.to_datetime(s, errors='coerce')
Out[314]: 
0   2001-01-01
1          NaT
2          NaT
3          NaT
4   2001-01-04
5   2001-01-05
dtype: datetime64[ns]
</pre> <p>In addition, <a class="reference internal" href="../generated/pandas.dataframe.convert_objects/#pandas.DataFrame.convert_objects" title="pandas.DataFrame.convert_objects"><code>convert_objects()</code></a> will attempt the <em>soft</em> conversion of any <em>object</em> dtypes, meaning that if all the objects in a Series are of the same type, the Series will have that dtype.</p>   <h3 id="gotchas">gotchas</h3> <p>Performing selection operations on <code>integer</code> type data can easily upcast the data to <code>floating</code>. The dtype of the input data will be preserved in cases where <code>nans</code> are not introduced (starting in 0.11.0) See also <a class="reference internal" href="../gotchas/#gotchas-intna">integer na gotchas</a></p> <pre data-language="python">In [315]: dfi = df3.astype('int32')

In [316]: dfi['E'] = 1

In [317]: dfi
Out[317]: 
   A  B    C  D  E
0  0  0    0  1  1
1  0  0  255  1  1
2  2  0    1  1  1
3 -1  0    0  1  1
4 -1  0    0  1  1
5  1  0    0  1  1
6  0  0    0  1  1
7 -2  1    0  1  1

In [318]: dfi.dtypes
Out[318]: 
A    int32
B    int32
C    int32
D    int32
E    int64
dtype: object

In [319]: casted = dfi[dfi&gt;0]

In [320]: casted
Out[320]: 
     A    B      C  D  E
0  NaN  NaN    NaN  1  1
1  NaN  NaN  255.0  1  1
2  2.0  NaN    1.0  1  1
3  NaN  NaN    NaN  1  1
4  NaN  NaN    NaN  1  1
5  1.0  NaN    NaN  1  1
6  NaN  NaN    NaN  1  1
7  NaN  1.0    NaN  1  1

In [321]: casted.dtypes
Out[321]: 
A    float64
B    float64
C    float64
D      int32
E      int64
dtype: object
</pre> <p>While float dtypes are unchanged.</p> <pre data-language="python">In [322]: dfa = df3.copy()

In [323]: dfa['A'] = dfa['A'].astype('float32')

In [324]: dfa.dtypes
Out[324]: 
A    float32
B    float64
C    float64
D    float16
E      int32
dtype: object

In [325]: casted = dfa[df2&gt;0]

In [326]: casted
Out[326]: 
          A         B      C   D   E
0  0.675238  0.296947    NaN NaN NaN
1       NaN  0.007045  255.0 NaN NaN
2  2.025163  0.707877    1.0 NaN NaN
3       NaN  0.950661    NaN NaN NaN
4       NaN  0.087527    NaN NaN NaN
5       NaN       NaN    NaN NaN NaN
6  0.385030       NaN    NaN NaN NaN
7 -2.294758  1.775379    NaN NaN NaN

In [327]: casted.dtypes
Out[327]: 
A    float32
B    float64
C    float64
D    float16
E    float64
dtype: object
</pre>    <h2 id="selecting-columns-based-on-dtype">Selecting columns based on <code>dtype</code>
</h2> <div class="versionadded" id="basics-selectdtypes"> <p><span class="versionmodified">New in version 0.14.1.</span></p> </div> <p>The <a class="reference internal" href="../generated/pandas.dataframe.select_dtypes/#pandas.DataFrame.select_dtypes" title="pandas.DataFrame.select_dtypes"><code>select_dtypes()</code></a> method implements subsetting of columns based on their <code>dtype</code>.</p> <p>First, let’s create a <a class="reference internal" href="../generated/pandas.dataframe/#pandas.DataFrame" title="pandas.DataFrame"><code>DataFrame</code></a> with a slew of different dtypes:</p> <pre data-language="python">In [328]: df = pd.DataFrame({'string': list('abc'),
   .....:                    'int64': list(range(1, 4)),
   .....:                    'uint8': np.arange(3, 6).astype('u1'),
   .....:                    'float64': np.arange(4.0, 7.0),
   .....:                    'bool1': [True, False, True],
   .....:                    'bool2': [False, True, False],
   .....:                    'dates': pd.date_range('now', periods=3).values,
   .....:                    'category': pd.Series(list("ABC")).astype('category')})
   .....: 

In [329]: df['tdeltas'] = df.dates.diff()

In [330]: df['uint64'] = np.arange(3, 6).astype('u8')

In [331]: df['other_dates'] = pd.date_range('20130101', periods=3).values

In [332]: df['tz_aware_dates'] = pd.date_range('20130101', periods=3, tz='US/Eastern')

In [333]: df
Out[333]: 
   bool1  bool2 category                      dates  float64  int64 string  \
0   True  False        A 2016-05-03 09:03:31.005096      4.0      1      a   
1  False   True        B 2016-05-04 09:03:31.005096      5.0      2      b   
2   True  False        C 2016-05-05 09:03:31.005096      6.0      3      c   

   uint8  tdeltas  uint64 other_dates            tz_aware_dates  
0      3      NaT       3  2013-01-01 2013-01-01 00:00:00-05:00  
1      4   1 days       4  2013-01-02 2013-01-02 00:00:00-05:00  
2      5   1 days       5  2013-01-03 2013-01-03 00:00:00-05:00  
</pre> <p>And the dtypes</p> <pre data-language="python">In [334]: df.dtypes
Out[334]: 
bool1                                   bool
bool2                                   bool
category                            category
dates                         datetime64[ns]
float64                              float64
int64                                  int64
string                                object
uint8                                  uint8
tdeltas                      timedelta64[ns]
uint64                                uint64
other_dates                   datetime64[ns]
tz_aware_dates    datetime64[ns, US/Eastern]
dtype: object
</pre> <p><a class="reference internal" href="../generated/pandas.dataframe.select_dtypes/#pandas.DataFrame.select_dtypes" title="pandas.DataFrame.select_dtypes"><code>select_dtypes()</code></a> has two parameters <code>include</code> and <code>exclude</code> that allow you to say “give me the columns WITH these dtypes” (<code>include</code>) and/or “give the columns WITHOUT these dtypes” (<code>exclude</code>).</p> <p>For example, to select <code>bool</code> columns</p> <pre data-language="python">In [335]: df.select_dtypes(include=[bool])
Out[335]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
</pre> <p>You can also pass the name of a dtype in the <a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html" target="_blank">numpy dtype hierarchy</a>:</p> <pre data-language="python">In [336]: df.select_dtypes(include=['bool'])
Out[336]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
</pre> <p><a class="reference internal" href="../generated/pandas.dataframe.select_dtypes/#pandas.DataFrame.select_dtypes" title="pandas.DataFrame.select_dtypes"><code>select_dtypes()</code></a> also works with generic dtypes as well.</p> <p>For example, to select all numeric and boolean columns while excluding unsigned integers</p> <pre data-language="python">In [337]: df.select_dtypes(include=['number', 'bool'], exclude=['unsignedinteger'])
Out[337]: 
   bool1  bool2  float64  int64  tdeltas
0   True  False      4.0      1      NaT
1  False   True      5.0      2   1 days
2   True  False      6.0      3   1 days
</pre> <p>To select string columns you must use the <code>object</code> dtype:</p> <pre data-language="python">In [338]: df.select_dtypes(include=['object'])
Out[338]: 
  string
0      a
1      b
2      c
</pre> <p>To see all the child dtypes of a generic <code>dtype</code> like <code>numpy.number</code> you can define a function that returns a tree of child dtypes:</p> <pre data-language="python">In [339]: def subdtypes(dtype):
   .....:     subs = dtype.__subclasses__()
   .....:     if not subs:
   .....:         return dtype
   .....:     return [dtype, [subdtypes(dt) for dt in subs]]
   .....: 
</pre> <p>All numpy dtypes are subclasses of <code>numpy.generic</code>:</p> <pre data-language="python">In [340]: subdtypes(np.generic)
Out[340]: 
[numpy.generic,
 [[numpy.number,
   [[numpy.integer,
     [[numpy.signedinteger,
       [numpy.int8,
        numpy.int16,
        numpy.int32,
        numpy.int64,
        numpy.int64,
        numpy.timedelta64]],
      [numpy.unsignedinteger,
       [numpy.uint8,
        numpy.uint16,
        numpy.uint32,
        numpy.uint64,
        numpy.uint64]]]],
    [numpy.inexact,
     [[numpy.floating,
       [numpy.float16, numpy.float32, numpy.float64, numpy.float128]],
      [numpy.complexfloating,
       [numpy.complex64, numpy.complex128, numpy.complex256]]]]]],
  [numpy.flexible,
   [[numpy.character, [numpy.string_, numpy.unicode_]],
    [numpy.void, [numpy.record]]]],
  numpy.bool_,
  numpy.datetime64,
  numpy.object_]]
</pre> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">Pandas also defines the types <code>category</code>, and <code>datetime64[ns, tz]</code>, which are not integrated into the normal numpy hierarchy and wont show up with the above function.</p> </div> <div class="admonition note"> <p class="first admonition-title">Note</p> <p class="last">The <code>include</code> and <code>exclude</code> parameters must be non-string sequences.</p> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2011–2012 Lambda Foundry, Inc. and PyData Development Team<br>© 2008–2011 AQR Capital Management, LLC<br>© 2008–2014 the pandas development team<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://pandas.pydata.org/pandas-docs/version/0.18.1/basics.html" class="_attribution-link" target="_blank">http://pandas.pydata.org/pandas-docs/version/0.18.1/basics.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
