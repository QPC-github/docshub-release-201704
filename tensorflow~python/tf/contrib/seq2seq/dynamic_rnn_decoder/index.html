
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>contrib.seq2seq.dynamic_rnn_decoder() - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Dynamic RNN decoder for a sequence-to-sequence model specified by RNNCell and decoder function. ">
  <meta name="keywords" content="tf, contrib, seq, dynamic, rnn, decoder, cell, fn, inputs, none, sequence, length, parallel, iterations, swap, memory, false, time, major, scope, name, -, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/tensorflow~python/tf/contrib/seq2seq/dynamic_rnn_decoder/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _tensorflow">
				
<h1 itemprop="name" class="devsite-page-title"> tf.contrib.seq2seq.dynamic_rnn_decoder(cell, decoder_fn, inputs=None, sequence_length=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None, name=None) </h1>    <h3 id="tfcontribseq2seqdynamic_rnn_decodercell_decoder_fn_inputsnone_sequence_lengthnone_parallel_iterationsnone_swap_memoryfalse_time_majorfalse_scopenone_namenone_1"><code>tf.contrib.seq2seq.dynamic_rnn_decoder(cell, decoder_fn, inputs=None, sequence_length=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None, name=None)</code></h3> <p>Dynamic RNN decoder for a sequence-to-sequence model specified by RNNCell and decoder function.</p> <p>The <code>dynamic_rnn_decoder</code> is similar to the <code>tf.python.ops.rnn.dynamic_rnn</code> as the decoder does not make any assumptions of sequence length and batch size of the input.</p> <p>The <code>dynamic_rnn_decoder</code> has two modes: training or inference and expects the user to create seperate functions for each.</p> <p>Under both training and inference, both <code>cell</code> and <code>decoder_fn</code> are expected, where <code>cell</code> performs computation at every timestep using <code>raw_rnn</code>, and <code>decoder_fn</code> allows modeling of early stopping, output, state, and next input and context.</p> <p>When training the user is expected to supply <code>inputs</code>. At every time step a slice of the supplied input is fed to the <code>decoder_fn</code>, which modifies and returns the input for the next time step.</p> <p><code>sequence_length</code> is needed at training time, i.e., when <code>inputs</code> is not None, for dynamic unrolling. At test time, when <code>inputs</code> is None, <code>sequence_length</code> is not needed.</p> <p>Under inference <code>inputs</code> is expected to be <code>None</code> and the input is inferred solely from the <code>decoder_fn</code>.</p> <h4 id="args">Args:</h4> <ul> <li>
<b><code>cell</code></b>: An instance of RNNCell.</li> <li>
<b><code>decoder_fn</code></b>: A function that takes time, cell state, cell input, cell output and context state. It returns a early stopping vector, cell state, next input, cell output and context state. Examples of decoder_fn can be found in the decoder_fn.py folder.</li> <li> <p><b><code>inputs</code></b>: The inputs for decoding (embedded format).</p> <p>If <code>time_major == False</code> (default), this must be a <code>Tensor</code> of shape: <code>[batch_size, max_time, ...]</code>.</p> <p>If <code>time_major == True</code>, this must be a <code>Tensor</code> of shape: <code>[max_time, batch_size, ...]</code>.</p> <p>The input to <code>cell</code> at each time step will be a <code>Tensor</code> with dimensions <code>[batch_size, ...]</code>. <em> <b><code>sequence_length</code></b>: (optional) An int32/int64 vector sized <code>[batch_size]</code>. if <code>inputs</code> is not None and <code>sequence_length</code> is None it is inferred from the <code>inputs</code> as the maximal possible sequence length. </em> <b><code>parallel_iterations</code></b>: (Default: 32). The number of iterations to run in parallel. Those operations which do not have any temporal dependency and can be run in parallel, will be. This parameter trades off time for space. Values &gt;&gt; 1 use more memory but take less time, while smaller values use less memory but computations take longer. <em> <b><code>swap_memory</code></b>: Transparently swap the tensors produced in forward inference but needed for back prop from GPU to CPU. This allows training RNNs which would typically not fit on a single GPU, with very minimal (or no) performance penalty. </em> <b><code>time_major</code></b>: The shape format of the <code>inputs</code> and <code>outputs</code> Tensors. If true, these <code>Tensors</code> must be shaped <code>[max_time, batch_size, depth]</code>. If false, these <code>Tensors</code> must be shaped <code>[batch_size, max_time, depth]</code>. Using <code>time_major = True</code> is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form. <em> <b><code>scope</code></b>: VariableScope for the <code>raw_rnn</code>; defaults to None. </em> <b><code>name</code></b>: NameScope for the decoder; defaults to "dynamic_rnn_decoder"</p> </li> </ul> <h4 id="returns">Returns:</h4> <p>A tuple (outputs, final_state, final_context_state) where:</p> <pre class="prettyprint notranslate" translate="no" data-language="python">outputs: the RNN output 'Tensor'.

  If time_major == False (default), this will be a `Tensor` shaped:
    `[batch_size, max_time, cell.output_size]`.

  If time_major == True, this will be a `Tensor` shaped:
    `[max_time, batch_size, cell.output_size]`.

final_state: The final state and will be shaped
  `[batch_size, cell.state_size]`.

final_context_state: The context state returned by the final call
  to decoder_fn. This is useful if the context state maintains internal
  data which is required after the graph is run.
  For example, one way to diversify the inference output is to use
  a stochastic decoder_fn, in which case one would want to store the
  decoded outputs, not just the RNN outputs. This can be done by
  maintaining a TensorArray in context_state and storing the decoded
  output of each iteration therein.
</pre> <h4 id="raises">Raises:</h4> <ul> <li>
<b><code>ValueError</code></b>: if inputs is not None and has less than three dimensions.</li> </ul> <p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/contrib/seq2seq/python/ops/seq2seq.py" target="_blank"><code>tensorflow/contrib/seq2seq/python/ops/seq2seq.py</code></a>.</p>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2017 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder" class="_attribution-link" target="_blank">https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
