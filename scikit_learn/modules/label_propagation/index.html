
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>1.14. Semi-Supervised - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content="Semi-supervised learning is a situation in which in your training data some of the samples are not labeled. The semi-supervised estimators in &hellip;">
  <meta name="keywords" content="semi-supervised, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/label_propagation/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="id1">1.14. Semi-Supervised</h1> <p id="semi-supervised"><a class="reference external" href="https://en.wikipedia.org/wiki/Semi-supervised_learning" target="_blank">Semi-supervised learning</a> is a situation in which in your training data some of the samples are not labeled. The semi-supervised estimators in <a class="reference internal" href="../classes/#module-sklearn.semi_supervised" title="sklearn.semi_supervised"><code>sklearn.semi_supervised</code></a> are able to make use of this additional unlabeled data to better capture the shape of the underlying data distribution and generalize better to new samples. These algorithms can perform well when we have a very small amount of labeled points and a large amount of unlabeled points.</p> <div class="topic"> <p class="topic-title first">Unlabeled entries in <code>y</code></p> <p>It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the <code>fit</code> method. The identifier that this implementation uses is the integer value <img class="math" src="http://scikit-learn.org/stable/_images/math/8b058f6323328c6a0fd741e20b35726ecc4ced5f.png" alt="-1">.</p> </div>  <h2 id="id2">1.14.1. Label Propagation</h2> <p id="label-propagation">Label propagation denotes a few variations of semi-supervised graph inference algorithms.</p> <dl class="docutils"> <dt>A few features available in this model:</dt> <dd>
<ul class="first last simple"> <li>Can be used for classification and regression tasks</li> <li>Kernel methods to project data into alternate dimensional spaces</li> </ul> </dd> </dl> <p><code>scikit-learn</code> provides two label propagation models: <a class="reference internal" href="../generated/sklearn.semi_supervised.labelpropagation/#sklearn.semi_supervised.LabelPropagation" title="sklearn.semi_supervised.LabelPropagation"><code>LabelPropagation</code></a> and <a class="reference internal" href="../generated/sklearn.semi_supervised.labelspreading/#sklearn.semi_supervised.LabelSpreading" title="sklearn.semi_supervised.LabelSpreading"><code>LabelSpreading</code></a>. Both work by constructing a similarity graph over all items in the input dataset.</p> <div class="figure align-center" id="id3"> <a class="reference external image-reference" href="../../auto_examples/semi_supervised/plot_label_propagation_structure/"><img alt="../_images/sphx_glr_plot_label_propagation_structure_0011.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_label_propagation_structure_0011.png" style="width: 510.0px; height: 240.0px;"></a> <p class="caption"><span class="caption-text"><strong>An illustration of label-propagation:</strong> <em>the structure of unlabeled observations is consistent with the class structure, and thus the class label can be propagated to the unlabeled observations of the training set.</em></span></p> </div> <p><a class="reference internal" href="../generated/sklearn.semi_supervised.labelpropagation/#sklearn.semi_supervised.LabelPropagation" title="sklearn.semi_supervised.LabelPropagation"><code>LabelPropagation</code></a> and <a class="reference internal" href="../generated/sklearn.semi_supervised.labelspreading/#sklearn.semi_supervised.LabelSpreading" title="sklearn.semi_supervised.LabelSpreading"><code>LabelSpreading</code></a> differ in modifications to the similarity matrix that graph and the clamping effect on the label distributions. Clamping allows the algorithm to change the weight of the true ground labeled data to some degree. The <a class="reference internal" href="../generated/sklearn.semi_supervised.labelpropagation/#sklearn.semi_supervised.LabelPropagation" title="sklearn.semi_supervised.LabelPropagation"><code>LabelPropagation</code></a> algorithm performs hard clamping of input labels, which means <img class="math" src="http://scikit-learn.org/stable/_images/math/e65b72cca6620a19116b8ea91a6fb91d75fd9d21.png" alt="\alpha=1">. This clamping factor can be relaxed, to say <img class="math" src="http://scikit-learn.org/stable/_images/math/164858397d7bb35e578ce149e133174d998f7e56.png" alt="\alpha=0.8">, which means that we will always retain 80 percent of our original label distribution, but the algorithm gets to change its confidence of the distribution within 20 percent.</p> <p><a class="reference internal" href="../generated/sklearn.semi_supervised.labelpropagation/#sklearn.semi_supervised.LabelPropagation" title="sklearn.semi_supervised.LabelPropagation"><code>LabelPropagation</code></a> uses the raw similarity matrix constructed from the data with no modifications. In contrast, <a class="reference internal" href="../generated/sklearn.semi_supervised.labelspreading/#sklearn.semi_supervised.LabelSpreading" title="sklearn.semi_supervised.LabelSpreading"><code>LabelSpreading</code></a> minimizes a loss function that has regularization properties, as such it is often more robust to noise. The algorithm iterates on a modified version of the original graph and normalizes the edge weights by computing the normalized graph Laplacian matrix. This procedure is also used in <a class="reference internal" href="../clustering/#spectral-clustering"><span class="std std-ref">Spectral clustering</span></a>.</p> <p>Label propagation models have two built-in kernel methods. Choice of kernel effects both scalability and performance of the algorithms. The following are available:</p>  <ul class="simple"> <li>rbf (<img class="math" src="http://scikit-learn.org/stable/_images/math/75b478a3e5ee14c3c099721d9947e3997a81ddd9.png" alt="\exp(-\gamma |x-y|^2), \gamma &gt; 0">). <img class="math" src="http://scikit-learn.org/stable/_images/math/3666981dc77862de77b6ecfcb64aad59b425cbaf.png" alt="\gamma"> is specified by keyword gamma.</li> <li>knn (<img class="math" src="http://scikit-learn.org/stable/_images/math/2780f555444b4f508969dafda2dbf8f85cedf4d8.png" alt="1[x' \in kNN(x)]">). <img class="math" src="http://scikit-learn.org/stable/_images/math/0b7c1e16a3a8a849bb8ffdcdbf86f65fd1f30438.png" alt="k"> is specified by keyword n_neighbors.</li> </ul>  <p>The RBF kernel will produce a fully connected graph which is represented in memory by a dense matrix. This matrix may be very large and combined with the cost of performing a full matrix multiplication calculation for each iteration of the algorithm can lead to prohibitively long running times. On the other hand, the KNN kernel will produce a much more memory-friendly sparse matrix which can drastically reduce running times.</p> <div class="topic"> <p class="topic-title first">Examples</p> <ul class="simple"> <li><a class="reference internal" href="../../auto_examples/semi_supervised/plot_label_propagation_versus_svm_iris/#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-versus-svm-iris-py"><span class="std std-ref">Decision boundary of label propagation versus SVM on the Iris dataset</span></a></li> <li><a class="reference internal" href="../../auto_examples/semi_supervised/plot_label_propagation_structure/#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-structure-py"><span class="std std-ref">Label Propagation learning a complex structure</span></a></li> <li><a class="reference internal" href="../../auto_examples/semi_supervised/plot_label_propagation_digits_active_learning/#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-digits-active-learning-py"><span class="std std-ref">Label Propagation digits active learning</span></a></li> </ul> </div> <div class="topic"> <p class="topic-title first">References</p> <p>[1] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216</p> <p>[2] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 <a class="reference external" href="http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf" target="_blank">http://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf</a></p> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/label_propagation.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/label_propagation.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
