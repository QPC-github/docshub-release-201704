
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>2.8. Density Estimation - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content="Density estimation walks the line between unsupervised learning, feature engineering, and data modeling. Some of the most popular and useful density &hellip;">
  <meta name="keywords" content="density, estimation, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/density/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="id1">2.8. Density Estimation</h1> <p id="density-estimation">Density estimation walks the line between unsupervised learning, feature engineering, and data modeling. Some of the most popular and useful density estimation techniques are mixture models such as Gaussian Mixtures (<a class="reference internal" href="../generated/sklearn.mixture.gaussianmixture/#sklearn.mixture.GaussianMixture" title="sklearn.mixture.GaussianMixture"><code>sklearn.mixture.GaussianMixture</code></a>), and neighbor-based approaches such as the kernel density estimate (<a class="reference internal" href="../generated/sklearn.neighbors.kerneldensity/#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><code>sklearn.neighbors.KernelDensity</code></a>). Gaussian Mixtures are discussed more fully in the context of <a class="reference internal" href="../clustering/#clustering"><span class="std std-ref">clustering</span></a>, because the technique is also useful as an unsupervised clustering scheme.</p> <p>Density estimation is a very simple concept, and most people are already familiar with one common density estimation technique: the histogram.</p>  <h2 id="density-estimation-histograms">2.8.1. Density Estimation: Histograms</h2> <p>A histogram is a simple visualization of data where bins are defined, and the number of data points within each bin is tallied. An example of a histogram can be seen in the upper-left panel of the following figure:</p> <p class="centered"> <strong><a class="reference external" href="../../auto_examples/neighbors/plot_kde_1d/"><img alt="hist_to_kde" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_0011.png" style="width: 640.0px; height: 480.0px;"></a></strong></p>
<p>A major problem with histograms, however, is that the choice of binning can have a disproportionate effect on the resulting visualization. Consider the upper-right panel of the above figure. It shows a histogram over the same data, with the bins shifted right. The results of the two visualizations look entirely different, and might lead to different interpretations of the data.</p> <p>Intuitively, one can also think of a histogram as a stack of blocks, one block per point. By stacking the blocks in the appropriate grid space, we recover the histogram. But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location? This idea leads to the lower-left visualization. It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data.</p> <p>This visualization is an example of a <em>kernel density estimation</em>, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.</p>   <h2 id="kernel-density">2.8.2. Kernel Density Estimation</h2> <p id="kernel-density-estimation">Kernel density estimation in scikit-learn is implemented in the <a class="reference internal" href="../generated/sklearn.neighbors.kerneldensity/#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><code>sklearn.neighbors.KernelDensity</code></a> estimator, which uses the Ball Tree or KD Tree for efficient queries (see <a class="reference internal" href="../neighbors/#neighbors"><span class="std std-ref">Nearest Neighbors</span></a> for a discussion of these). Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions.</p> <p>In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:</p> <p class="centered"> <strong><a class="reference external" href="../../auto_examples/neighbors/plot_kde_1d/"><img alt="kde_1d_distribution" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_0031.png" style="width: 640.0px; height: 480.0px;"></a></strong></p>
<p>It’s clear how the kernel shape affects the smoothness of the resulting distribution. The scikit-learn kernel density estimator can be used as follows:</p> <pre data-language="python">&gt;&gt;&gt; from sklearn.neighbors.kde import KernelDensity
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
&gt;&gt;&gt; kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)
&gt;&gt;&gt; kde.score_samples(X)
array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698,
       -0.41076071])
</pre> <p>Here we have used <code>kernel='gaussian'</code>, as seen above. Mathematically, a kernel is a positive function <img class="math" src="http://scikit-learn.org/stable/_images/math/88f86c9420421950f3a197f506d070a739926642.png" alt="K(x;h)"> which is controlled by the bandwidth parameter <img class="math" src="http://scikit-learn.org/stable/_images/math/293fb39e1b93282c804a86186e721b32f829f1b2.png" alt="h">. Given this kernel form, the density estimate at a point <img class="math" src="http://scikit-learn.org/stable/_images/math/276f7e256cbddeb81eee42e1efc348f3cb4ab5f8.png" alt="y"> within a group of points <img class="math" src="http://scikit-learn.org/stable/_images/math/bf1873c9355f4409a0f498ba584399616319829b.png" alt="x_i; i=1\cdots N"> is given by:</p> <div class="math"> <p><img src="http://scikit-learn.org/stable/_images/math/d1d4fad62d41386f5af602f68f5dd53f03bf92fa.png" alt="\rho_K(y) = \sum_{i=1}^{N} K((y - x_i) / h)"></p> </div>
<p>The bandwidth here acts as a smoothing parameter, controlling the tradeoff between bias and variance in the result. A large bandwidth leads to a very smooth (i.e. high-bias) density distribution. A small bandwidth leads to an unsmooth (i.e. high-variance) density distribution.</p> <p><a class="reference internal" href="../generated/sklearn.neighbors.kerneldensity/#sklearn.neighbors.KernelDensity" title="sklearn.neighbors.KernelDensity"><code>sklearn.neighbors.KernelDensity</code></a> implements several common kernel forms, which are shown in the following figure:</p> <p class="centered"> <strong><a class="reference external" href="../../auto_examples/neighbors/plot_kde_1d/"><img alt="kde_kernels" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kde_1d_0021.png" style="width: 640.0px; height: 480.0px;"></a></strong></p>
<p>The form of these kernels is as follows:</p> <ul> <li>
<p class="first">Gaussian kernel (<code>kernel = 'gaussian'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/d45a22c5dc8427e67f5a8dca0497cea40c8697cb.png" alt="K(x; h) \propto \exp(- \frac{x^2}{2h^2} )"></p> </li> <li>
<p class="first">Tophat kernel (<code>kernel = 'tophat'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/437c6b42e24e4b12c4496e13d2a8b1c0729b7200.png" alt="K(x; h) \propto 1"> if <img class="math" src="http://scikit-learn.org/stable/_images/math/b88c5390caf5c99c8e17425b19992fdce1198245.png" alt="x &lt; h"></p> </li> <li>
<p class="first">Epanechnikov kernel (<code>kernel = 'epanechnikov'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/2c199098c419390c0f6a3c7db8ba2e6b6fb42f73.png" alt="K(x; h) \propto 1 - \frac{x^2}{h^2}"></p> </li> <li>
<p class="first">Exponential kernel (<code>kernel = 'exponential'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/fe779ad27d62c80a58b5978c79fe875da4ad1cc2.png" alt="K(x; h) \propto \exp(-x/h)"></p> </li> <li>
<p class="first">Linear kernel (<code>kernel = 'linear'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/0bcc52b28358eb00cbf5055745472d37864687fb.png" alt="K(x; h) \propto 1 - x/h"> if <img class="math" src="http://scikit-learn.org/stable/_images/math/b88c5390caf5c99c8e17425b19992fdce1198245.png" alt="x &lt; h"></p> </li> <li>
<p class="first">Cosine kernel (<code>kernel = 'cosine'</code>)</p> <p><img class="math" src="http://scikit-learn.org/stable/_images/math/e94d029cc9ea0177d30872920460c3f03a571a48.png" alt="K(x; h) \propto \cos(\frac{\pi x}{2h})"> if <img class="math" src="http://scikit-learn.org/stable/_images/math/b88c5390caf5c99c8e17425b19992fdce1198245.png" alt="x &lt; h"></p> </li> </ul> <p>The kernel density estimator can be used with any of the valid distance metrics (see <a class="reference internal" href="../generated/sklearn.neighbors.distancemetric/#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code>sklearn.neighbors.DistanceMetric</code></a> for a list of available metrics), though the results are properly normalized only for the Euclidean metric. One particularly useful metric is the <a class="reference external" href="https://en.wikipedia.org/wiki/Haversine_formula" target="_blank">Haversine distance</a> which measures the angular distance between points on a sphere. Here is an example of using a kernel density estimate for a visualization of geospatial data, in this case the distribution of observations of two different species on the South American continent:</p> <p class="centered"> <strong><a class="reference external" href="../../auto_examples/neighbors/plot_species_kde/"><img alt="species_kde" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_species_kde_0011.png" style="width: 640.0px; height: 480.0px;"></a></strong></p>
<p>One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:</p> <p class="centered"> <strong><a class="reference external" href="../../auto_examples/neighbors/plot_digits_kde_sampling/"><img alt="digits_kde" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_digits_kde_sampling_0011.png" style="width: 640.0px; height: 480.0px;"></a></strong></p>
<p>The “new” data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model.</p> <div class="topic"> <p class="topic-title first">Examples:</p> <ul class="simple"> <li>
<a class="reference internal" href="../../auto_examples/neighbors/plot_kde_1d/#sphx-glr-auto-examples-neighbors-plot-kde-1d-py"><span class="std std-ref">Simple 1D Kernel Density Estimation</span></a>: computation of simple kernel density estimates in one dimension.</li> <li>
<a class="reference internal" href="../../auto_examples/neighbors/plot_digits_kde_sampling/#sphx-glr-auto-examples-neighbors-plot-digits-kde-sampling-py"><span class="std std-ref">Kernel Density Estimation</span></a>: an example of using Kernel Density estimation to learn a generative model of the hand-written digits data, and drawing new samples from this model.</li> <li>
<a class="reference internal" href="../../auto_examples/neighbors/plot_species_kde/#sphx-glr-auto-examples-neighbors-plot-species-kde-py"><span class="std std-ref">Kernel Density Estimate of Species Distributions</span></a>: an example of Kernel Density estimation using the Haversine distance metric to visualize geospatial data</li> </ul> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/density.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/density.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
