
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>linear_model.BayesianRidge() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Bayesian ridge regression ">
  <meta name="keywords" content="sklearn, linear, model, bayesianridge, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.linear_model.bayesianridge/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-linear-model-bayesianridge">sklearn.linear_model.BayesianRidge</h1> <dl class="class"> <dt id="sklearn.linear_model.BayesianRidge">
<code>class sklearn.linear_model.BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/bayes.py#L22" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Bayesian ridge regression</p> <p>Fit a Bayesian ridge model and optimize the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).</p> <p>Read more in the <a class="reference internal" href="../../linear_model/#bayesian-regression"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>n_iter</strong> : int, optional</p>  <p>Maximum number of iterations. Default is 300.</p>  <p><strong>tol</strong> : float, optional</p>  <p>Stop the algorithm if w has converged. Default is 1.e-3.</p>  <p><strong>alpha_1</strong> : float, optional</p>  <p>Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter. Default is 1.e-6</p>  <p><strong>alpha_2</strong> : float, optional</p>  <p>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter. Default is 1.e-6.</p>  <p><strong>lambda_1</strong> : float, optional</p>  <p>Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter. Default is 1.e-6.</p>  <p><strong>lambda_2</strong> : float, optional</p>  <p>Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter. Default is 1.e-6</p>  <p><strong>compute_score</strong> : boolean, optional</p>  <p>If True, compute the objective function at each step of the model. Default is False</p>  <p><strong>fit_intercept</strong> : boolean, optional</p>  <p>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered). Default is True.</p>  <p><strong>normalize</strong> : boolean, optional, default False</p>  <p>If True, the regressors X will be normalized before regression. This parameter is ignored when <code>fit_intercept</code> is set to False. When the regressors are normalized, note that this makes the hyperparameters learnt more robust and almost independent of the number of samples. The same property is not valid for standardized data. However, if you wish to standardize, please use <code>preprocessing.StandardScaler</code> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p>  <p><strong>copy_X</strong> : boolean, optional, default True</p>  <p>If True, X will be copied; else, it may be overwritten.</p>  <p><strong>verbose</strong> : boolean, optional, default False</p>  <p>Verbose mode when fitting the model.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>coef_</strong> : array, shape = (n_features)</p>  <p>Coefficients of the regression model (mean of distribution)</p>  <p><strong>alpha_</strong> : float</p>  <p>estimated precision of the noise.</p>  <p><strong>lambda_</strong> : float</p>  <p>estimated precision of the weights.</p>  <p><strong>scores_</strong> : float</p>  <p>if computed, value of the objective function (to be maximized)</p>  </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>See examples/linear_model/plot_bayesian_ridge.py for an example.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn import linear_model
&gt;&gt;&gt; clf = linear_model.BayesianRidge()
&gt;&gt;&gt; clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
... 
BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False,
        copy_X=True, fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06,
        n_iter=300, normalize=False, tol=0.001, verbose=False)
&gt;&gt;&gt; clf.predict([[1, 1]])
array([ 1.])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.decision_function" title="sklearn.linear_model.BayesianRidge.decision_function"><code>decision_function</code></a>(*args, **kwargs)</td> <td>DEPRECATED: and will be removed in 0.19.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.fit" title="sklearn.linear_model.BayesianRidge.fit"><code>fit</code></a>(X, y)</td> <td>Fit the model</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.get_params" title="sklearn.linear_model.BayesianRidge.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.predict" title="sklearn.linear_model.BayesianRidge.predict"><code>predict</code></a>(X)</td> <td>Predict using the linear model</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.score" title="sklearn.linear_model.BayesianRidge.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the coefficient of determination R^2 of the prediction.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.linear_model.BayesianRidge.set_params" title="sklearn.linear_model.BayesianRidge.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.__init__">
<code>__init__(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/bayes.py#L114" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.decision_function">
<code>decision_function(*args, **kwargs)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/utils/deprecation.py#L69" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>DEPRECATED: and will be removed in 0.19.</p> <p>Decision function of the linear model.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>  <p>Samples.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape = (n_samples,)</p>  <p>Returns predicted values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.fit">
<code>fit(X, y)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/bayes.py#L130" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : numpy array of shape [n_samples,n_features]</p>  <p>Training data</p>  <p><strong>y</strong> : numpy array of shape [n_samples]</p>  <p>Target values</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first last"><strong>self</strong> : returns an instance of self.</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/base.py#L255" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>  <p>Samples.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape = (n_samples,)</p>  <p>Returns predicted values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L357" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the coefficient of determination R^2 of the prediction.</p> <p>The coefficient R^2 is defined as (1 - u/v), where u is the regression sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True values for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>R^2 of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.linear_model.BayesianRidge.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-linear-model-bayesianridge">Examples using <code>sklearn.linear_model.BayesianRidge</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="This example compares 2 dimensionality reduction strategies:">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_feature_agglomeration_vs_univariate_selection_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_feature_agglomeration_vs_univariate_selection_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_feature_agglomeration_vs_univariate_selection/#sphx-glr-auto-examples-cluster-plot-feature-agglomeration-vs-univariate-selection-py"><span class="std std-ref">Feature agglomeration vs. univariate selection</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Computes a Bayesian Ridge Regression on a synthetic dataset.">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_bayesian_ridge_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_bayesian_ridge_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/linear_model/plot_bayesian_ridge/#sphx-glr-auto-examples-linear-model-plot-bayesian-ridge-py"><span class="std std-ref">Bayesian Ridge Regression</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
