
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>svm.SVC() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" C-Support Vector Classification. ">
  <meta name="keywords" content="sklearn, svm, svc, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.svm.svc/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-svm-svc">sklearn.svm.SVC</h1> <dl class="class"> <dt id="sklearn.svm.SVC">
<code>class sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/svm/classes.py#L387" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>C-Support Vector Classification.</p> <p>The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.</p> <p>The multiclass support is handled according to a one-vs-one scheme.</p> <p>For details on the precise mathematical formulation of the provided kernel functions and how <code>gamma</code>, <code>coef0</code> and <code>degree</code> affect each other, see the corresponding section in the narrative documentation: <a class="reference internal" href="../../svm/#svm-kernels"><span class="std std-ref">Kernel functions</span></a>.</p> <p>Read more in the <a class="reference internal" href="../../svm/#svm-classification"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : float, optional (default=1.0)</p>  <p>Penalty parameter C of the error term.</p>  <p><strong>kernel</strong> : string, optional (default=’rbf’)</p>  <p>Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape <code>(n_samples, n_samples)</code>.</p>  <p><strong>degree</strong> : int, optional (default=3)</p>  <p>Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.</p>  <p><strong>gamma</strong> : float, optional (default=’auto’)</p>  <p>Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If gamma is ‘auto’ then 1/n_features will be used instead.</p>  <p><strong>coef0</strong> : float, optional (default=0.0)</p>  <p>Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.</p>  <p><strong>probability</strong> : boolean, optional (default=False)</p>  <p>Whether to enable probability estimates. This must be enabled prior to calling <code>fit</code>, and will slow down that method.</p>  <p><strong>shrinking</strong> : boolean, optional (default=True)</p>  <p>Whether to use the shrinking heuristic.</p>  <p><strong>tol</strong> : float, optional (default=1e-3)</p>  <p>Tolerance for stopping criterion.</p>  <p><strong>cache_size</strong> : float, optional</p>  <p>Specify the size of the kernel cache (in MB).</p>  <p><strong>class_weight</strong> : {dict, ‘balanced’}, optional</p>  <p>Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as <code>n_samples / (n_classes * np.bincount(y))</code></p>  <p><strong>verbose</strong> : bool, default: False</p>  <p>Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.</p>  <p><strong>max_iter</strong> : int, optional (default=-1)</p>  <p>Hard limit on iterations within solver, or -1 for no limit.</p>  <p><strong>decision_function_shape</strong> : ‘ovo’, ‘ovr’ or None, default=None</p>  <p>Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). The default of None will currently behave as ‘ovo’ for backward compatibility and raise a deprecation warning, but will change ‘ovr’ in 0.19.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>decision_function_shape=’ovr’</em> is recommended.</p> </div> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <em>decision_function_shape=’ovo’ and None</em>.</p> </div>  <p><strong>random_state</strong> : int seed, RandomState instance, or None (default)</p>  <p>The seed of the pseudo random number generator to use when shuffling the data for probability estimation.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>support_</strong> : array-like, shape = [n_SV]</p>  <p>Indices of support vectors.</p>  <p><strong>support_vectors_</strong> : array-like, shape = [n_SV, n_features]</p>  <p>Support vectors.</p>  <p><strong>n_support_</strong> : array-like, dtype=int32, shape = [n_class]</p>  <p>Number of support vectors for each class.</p>  <p><strong>dual_coef_</strong> : array, shape = [n_class-1, n_SV]</p>  <p>Coefficients of the support vector in the decision function. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the section about multi-class classification in the SVM section of the User Guide for details.</p>  <p><strong>coef_</strong> : array, shape = [n_class-1, n_features]</p>  <p>Weights assigned to the features (coefficients in the primal problem). This is only available in the case of a linear kernel.</p> <p><code>coef_</code> is a readonly property derived from <code>dual_coef_</code> and <code>support_vectors_</code>.</p>  <p><strong>intercept_</strong> : array, shape = [n_class * (n_class-1) / 2]</p>  <p>Constants in decision function.</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="../sklearn.svm.svr/#sklearn.svm.SVR" title="sklearn.svm.SVR"><code>SVR</code></a>
</dt> <dd>Support Vector Machine for Regression implemented using libsvm.</dd> <dt>
 <a class="reference internal" href="../sklearn.svm.linearsvc/#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code>LinearSVC</code></a>
</dt> <dd>Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See also section of LinearSVC for more comparison element.</dd> </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
&gt;&gt;&gt; y = np.array([1, 1, 2, 2])
&gt;&gt;&gt; from sklearn.svm import SVC
&gt;&gt;&gt; clf = SVC()
&gt;&gt;&gt; clf.fit(X, y) 
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)
&gt;&gt;&gt; print(clf.predict([[-0.8, -1]]))
[1]
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.decision_function" title="sklearn.svm.SVC.decision_function"><code>decision_function</code></a>(X)</td> <td>Distance of the samples X to the separating hyperplane.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.fit" title="sklearn.svm.SVC.fit"><code>fit</code></a>(X, y[, sample_weight])</td> <td>Fit the SVM model according to the given training data.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.get_params" title="sklearn.svm.SVC.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.predict" title="sklearn.svm.SVC.predict"><code>predict</code></a>(X)</td> <td>Perform classification on samples in X.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.score" title="sklearn.svm.SVC.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the mean accuracy on the given test data and labels.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.svm.SVC.set_params" title="sklearn.svm.SVC.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.svm.SVC.__init__">
<code>__init__(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/svm/classes.py#L531" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/svm/base.py#L532" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Distance of the samples X to the separating hyperplane.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p> </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)</p>  <p>Returns the decision function of the sample for each class in the model. If decision_function_shape=’ovr’, the shape is (n_samples, n_classes)</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/svm/base.py#L111" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the SVM model according to the given training data.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape (n_samples, n_features)</p>  <p>Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).</p>  <p><strong>y</strong> : array-like, shape (n_samples,)</p>  <p>Target values (class labels in classification, real numbers in regression)</p>  <p><strong>sample_weight</strong> : array-like, shape (n_samples,)</p>  <p>Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>self</strong> : object</p>  <p>Returns self.</p>  </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.</p> <p>If X is a dense array, then the other methods will not support sparse matrices as input.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/svm/base.py#L557" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform classification on samples in X.</p> <p>For an one-class model, +1 or -1 is returned.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape (n_samples, n_features)</p>  <p>For kernel=”precomputed”, the expected shape of X is [n_samples_test, n_samples_train]</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>y_pred</strong> : array, shape (n_samples,)</p>  <p>Class labels for samples in X.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="sklearn.svm.SVC.predict_log_proba">
<code>predict_log_proba</code> </dt> <dd>
<p>Compute log probabilities of possible outcomes for samples in X.</p> <p>The model need to have probability information computed at training time: fit with attribute <code>probability</code> set to True.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>For kernel=”precomputed”, the expected shape of X is [n_samples_test, n_samples_train]</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>T</strong> : array-like, shape (n_samples, n_classes)</p>  <p>Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute <code>classes_</code>.</p>  </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.</p> </dd>
</dl> <dl class="attribute"> <dt id="sklearn.svm.SVC.predict_proba">
<code>predict_proba</code> </dt> <dd>
<p>Compute probabilities of possible outcomes for samples in X.</p> <p>The model need to have probability information computed at training time: fit with attribute <code>probability</code> set to True.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>For kernel=”precomputed”, the expected shape of X is [n_samples_test, n_samples_train]</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>T</strong> : array-like, shape (n_samples, n_classes)</p>  <p>Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute <code>classes_</code>.</p>  </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L324" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True labels for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>Mean accuracy of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.svm.SVC.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-svm-svc">Examples using <code>sklearn.svm.SVC</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="In many real-world examples, there are many ways to extract features from a dataset. Often it i...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_feature_stacker_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_feature_stacker_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_stacker/#sphx-glr-auto-examples-feature-stacker-py"><span class="std std-ref">Concatenating multiple feature extraction methods</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Datasets can often contain components of that require different feature extraction and processi...">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_hetero_feature_union_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_hetero_feature_union_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/hetero_feature_union/#sphx-glr-auto-examples-hetero-feature-union-py"><span class="std std-ref">Feature Union with Heterogeneous Data Sources</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="An example illustrating the approximation of the feature map of an RBF kernel.">
<div class="figure" id="id3"> <img alt="../../_images/sphx_glr_plot_kernel_approximation_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kernel_approximation_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/plot_kernel_approximation/#sphx-glr-auto-examples-plot-kernel-approximation-py"><span class="std std-ref">Explicit feature map approximation for RBF kernels</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example simulates a multi-label document classification problem. The dataset is generated ...">
<div class="figure" id="id4"> <img alt="../../_images/sphx_glr_plot_multilabel_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_multilabel_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/plot_multilabel/#sphx-glr-auto-examples-plot-multilabel-py"><span class="std std-ref">Multilabel classification</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="The dataset used in this example is a preprocessed excerpt of the " labeled faces in the wild ...>
<div class="figure" id="id5"> <img alt="../../_images/sphx_glr_face_recognition_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_face_recognition_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/applications/face_recognition/#sphx-glr-auto-examples-applications-face-recognition-py"><span class="std std-ref">Faces recognition example using eigenfaces and SVMs</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A simple graphical frontend for Libsvm mainly intended for didactic purposes. You can create da...">
<div class="figure" id="id6"> <img alt="../../_images/sphx_glr_svm_gui_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_svm_gui_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/applications/svm_gui/#sphx-glr-auto-examples-applications-svm-gui-py"><span class="std std-ref">Libsvm GUI</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Plot the classification probability for different classifiers. We use a 3 class dataset, and we...">
<div class="figure" id="id7"> <img alt="../../_images/sphx_glr_plot_classification_probability_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_classification_probability_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/classification/plot_classification_probability/#sphx-glr-auto-examples-classification-plot-classification-probability-py"><span class="std std-ref">Plot classification probability</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this ...">
<div class="figure" id="id8"> <img alt="../../_images/sphx_glr_plot_classifier_comparison_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/classification/plot_classifier_comparison/#sphx-glr-auto-examples-classification-plot-classifier-comparison-py"><span class="std std-ref">Classifier comparison</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="An example showing how the scikit-learn can be used to recognize images of hand-written digits.">
<div class="figure" id="id9"> <img alt="../../_images/sphx_glr_plot_digits_classification_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_digits_classification_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/classification/plot_digits_classification/#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Plot the decision boundaries of a `VotingClassifier` for two features of the Iris dataset.">
<div class="figure" id="id10"> <img alt="../../_images/sphx_glr_plot_voting_decision_regions_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_voting_decision_regions_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/ensemble/plot_voting_decision_regions/#sphx-glr-auto-examples-ensemble-plot-voting-decision-regions-py"><span class="std std-ref">Plot the decision boundaries of a VotingClassifier</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A tutorial exercise using Cross-validation with an SVM on the Digits dataset.">
<div class="figure" id="id11"> <img alt="../../_images/sphx_glr_plot_cv_digits_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_cv_digits_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/exercises/plot_cv_digits/#sphx-glr-auto-examples-exercises-plot-cv-digits-py"><span class="std std-ref">Cross-validation on Digits Dataset Exercise</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A tutorial exercise for using different SVM kernels.">
<div class="figure" id="id12"> <img alt="../../_images/sphx_glr_plot_iris_exercise_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_iris_exercise_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/exercises/plot_iris_exercise/#sphx-glr-auto-examples-exercises-plot-iris-exercise-py"><span class="std std-ref">SVM Exercise</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Simple usage of Pipeline that runs successively a univariate feature selection with anova and t...">
<div class="figure" id="id13"> <img alt="../../_images/sphx_glr_feature_selection_pipeline_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_feature_selection_pipeline_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_selection/feature_selection_pipeline/#sphx-glr-auto-examples-feature-selection-feature-selection-pipeline-py"><span class="std std-ref">Pipeline Anova SVM</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="An example showing univariate feature selection.">
<div class="figure" id="id14"> <img alt="../../_images/sphx_glr_plot_feature_selection_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_feature_selection_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_selection/plot_feature_selection/#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py"><span class="std std-ref">Univariate Feature Selection</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="In order to test if a classification score is significative a technique in repeating the classi...">
<div class="figure" id="id15"> <img alt="../../_images/sphx_glr_plot_permutation_test_for_classification_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_permutation_test_for_classification_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_selection/plot_permutation_test_for_classification/#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py"><span class="std std-ref">Test with permutations the significance of a classification score</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A recursive feature elimination example showing the relevance of pixels in a digit classificati...">
<div class="figure" id="id16"> <img alt="../../_images/sphx_glr_plot_rfe_digits_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_rfe_digits_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_selection/plot_rfe_digits/#sphx-glr-auto-examples-feature-selection-plot-rfe-digits-py"><span class="std std-ref">Recursive feature elimination</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A recursive feature elimination example with automatic tuning of the number of features selecte...">
<div class="figure" id="id17"> <img alt="../../_images/sphx_glr_plot_rfe_with_cross_validation_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_rfe_with_cross_validation_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/feature_selection/plot_rfe_with_cross_validation/#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This examples shows how a classifier is optimized by cross-validation, which is done using the ...">
<div class="figure" id="id18"> <img alt="../../_images/sphx_glr_grid_search_digits_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_grid_search_digits_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/grid_search_digits/#sphx-glr-auto-examples-model-selection-grid-search-digits-py"><span class="std std-ref">Parameter estimation using grid search with cross-validation</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Example of confusion matrix usage to evaluate the quality of the output of a classifier on the ...">
<div class="figure" id="id19"> <img alt="../../_images/sphx_glr_plot_confusion_matrix_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_confusion_matrix/#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="On the left side the learning curve of a naive Bayes classifier is shown for the digits dataset...">
<div class="figure" id="id20"> <img alt="../../_images/sphx_glr_plot_learning_curve_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_learning_curve_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_learning_curve/#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"><span class="std std-ref">Plotting Learning Curves</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example compares non-nested and nested cross-validation strategies on a classifier of the ...">
<div class="figure" id="id21"> <img alt="../../_images/sphx_glr_plot_nested_cross_validation_iris_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_nested_cross_validation_iris_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_nested_cross_validation_iris/#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py"><span class="std std-ref">Nested versus non-nested cross-validation</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Example of Precision-Recall metric to evaluate classifier output quality.">
<div class="figure" id="id22"> <img alt="../../_images/sphx_glr_plot_precision_recall_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_precision_recall_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_precision_recall/#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"><span class="std std-ref">Precision-Recall</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Example of Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality...">
<div class="figure" id="id23"> <img alt="../../_images/sphx_glr_plot_roc_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_roc_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_roc/#sphx-glr-auto-examples-model-selection-plot-roc-py"><span class="std std-ref">Receiver Operating Characteristic (ROC)</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Example of Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality...">
<div class="figure" id="id24"> <img alt="../../_images/sphx_glr_plot_roc_crossval_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_roc_crossval_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_roc_crossval/#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="In this plot you can see the training scores and validation scores of an SVM for different valu...">
<div class="figure" id="id25"> <img alt="../../_images/sphx_glr_plot_validation_curve_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_validation_curve_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/model_selection/plot_validation_curve/#sphx-glr-auto-examples-model-selection-plot-validation-curve-py"><span class="std std-ref">Plotting Validation Curves</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Comparison for decision boundary generated on iris dataset between Label Propagation and SVM.">
<div class="figure" id="id26"> <img alt="../../_images/sphx_glr_plot_label_propagation_versus_svm_iris_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_label_propagation_versus_svm_iris_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/semi_supervised/plot_label_propagation_versus_svm_iris/#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-versus-svm-iris-py"><span class="std std-ref">Decision boundary of label propagation versus SVM on the Iris dataset</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Simple usage of Support Vector Machines to classify a sample. It will plot the decision surface...">
<div class="figure" id="id27"> <img alt="../../_images/sphx_glr_plot_custom_kernel_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_custom_kernel_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_custom_kernel/#sphx-glr-auto-examples-svm-plot-custom-kernel-py"><span class="std std-ref">SVM with custom kernel</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Comparison of different linear SVM classifiers on a 2D projection of the iris dataset. We only ...">
<div class="figure" id="id28"> <img alt="../../_images/sphx_glr_plot_iris_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_iris_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_iris/#sphx-glr-auto-examples-svm-plot-iris-py"><span class="std std-ref">Plot different SVM classifiers in the iris dataset</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates the effect of the parameters ``gamma`` and ``C`` of the Radial Basis F...">
<div class="figure" id="id29"> <img alt="../../_images/sphx_glr_plot_rbf_parameters_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_rbf_parameters_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_rbf_parameters/#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"><span class="std std-ref">RBF SVM parameters</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Plot the maximum margin separating hyperplane within a two-class separable dataset using a Supp...">
<div class="figure" id="id30"> <img alt="../../_images/sphx_glr_plot_separating_hyperplane_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_separating_hyperplane/#sphx-glr-auto-examples-svm-plot-separating-hyperplane-py"><span class="std std-ref">SVM: Maximum margin separating hyperplane</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Find the optimal separating hyperplane using an SVC for classes that are unbalanced.">
<div class="figure" id="id31"> <img alt="../../_images/sphx_glr_plot_separating_hyperplane_unbalanced_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_unbalanced_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_separating_hyperplane_unbalanced/#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py"><span class="std std-ref">SVM: Separating hyperplane for unbalanced classes</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example shows how to perform univariate feature selection before running a SVC (support ve...">
<div class="figure" id="id32"> <img alt="../../_images/sphx_glr_plot_svm_anova_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_svm_anova_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_svm_anova/#sphx-glr-auto-examples-svm-plot-svm-anova-py"><span class="std std-ref">SVM-Anova: SVM with univariate feature selection</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Three different types of SVM-Kernels are displayed below. The polynomial and RBF are especially...">
<div class="figure" id="id33"> <img alt="../../_images/sphx_glr_plot_svm_kernels_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_svm_kernels_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_svm_kernels/#sphx-glr-auto-examples-svm-plot-svm-kernels-py"><span class="std std-ref">SVM-Kernels</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="A small value of `C` includes more/all the observations, allowing the margins to be calculated ...">
<div class="figure" id="id34"> <img alt="../../_images/sphx_glr_plot_svm_margin_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_svm_margin_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_svm_margin/#sphx-glr-auto-examples-svm-plot-svm-margin-py"><span class="std std-ref">SVM Margins Example</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Plot decision function of a weighted dataset, where the size of points is proportional to its w...">
<div class="figure" id="id35"> <img alt="../../_images/sphx_glr_plot_weighted_samples_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_weighted_samples_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/svm/plot_weighted_samples/#sphx-glr-auto-examples-svm-plot-weighted-samples-py"><span class="std std-ref">SVM: Weighted samples</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
