
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>ensemble.RandomTreesEmbedding() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" An ensemble of totally random trees. ">
  <meta name="keywords" content="sklearn, ensemble, randomtreesembedding, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.ensemble.randomtreesembedding/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-ensemble-randomtreesembedding">sklearn.ensemble.RandomTreesEmbedding</h1> <dl class="class"> <dt id="sklearn.ensemble.RandomTreesEmbedding">
<code>class sklearn.ensemble.RandomTreesEmbedding(n_estimators=10, max_depth=5, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_leaf_nodes=None, min_impurity_split=1e-07, sparse_output=True, n_jobs=1, random_state=None, verbose=0, warm_start=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L1511" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>An ensemble of totally random trees.</p> <p>An unsupervised transformation of a dataset to a high-dimensional sparse representation. A datapoint is coded according to which leaf of each tree it is sorted into. Using a one-hot encoding of the leaves, this leads to a binary coding with as many ones as there are trees in the forest.</p> <p>The dimensionality of the resulting representation is <code>n_out &lt;= n_estimators * max_leaf_nodes</code>. If <code>max_leaf_nodes == None</code>, the number of leaf nodes is at most <code>n_estimators * 2 ** max_depth</code>.</p> <p>Read more in the <a class="reference internal" href="../../ensemble/#random-trees-embedding"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>n_estimators</strong> : integer, optional (default=10)</p>  <p>Number of trees in the forest.</p>  <p><strong>max_depth</strong> : integer, optional (default=5)</p>  <p>The maximum depth of each tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.</p>  <p><strong>min_samples_split</strong> : int, float, optional (default=2)</p>  <p>The minimum number of samples required to split an internal node:</p> <ul class="simple"> <li>If int, then consider <code>min_samples_split</code> as the minimum number.</li> <li>If float, then <code>min_samples_split</code> is a percentage and <code>ceil(min_samples_split * n_samples)</code> is the minimum number of samples for each split.</li> </ul> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p> </div>  <p><strong>min_samples_leaf</strong> : int, float, optional (default=1)</p>  <p>The minimum number of samples required to be at a leaf node:</p> <ul class="simple"> <li>If int, then consider <code>min_samples_leaf</code> as the minimum number.</li> <li>If float, then <code>min_samples_leaf</code> is a percentage and <code>ceil(min_samples_leaf * n_samples)</code> is the minimum number of samples for each node.</li> </ul> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p> </div>  <p><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)</p>  <p>The minimum weighted fraction of the input samples required to be at a leaf node.</p>  <p><strong>max_leaf_nodes</strong> : int or None, optional (default=None)</p>  <p>Grow trees with <code>max_leaf_nodes</code> in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.</p>  <p><strong>min_impurity_split</strong> : float, optional (default=1e-7)</p>  <p>Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.18.</span></p> </div>  <p><strong>sparse_output</strong> : bool, optional (default=True)</p>  <p>Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.</p>  <p><strong>n_jobs</strong> : integer, optional (default=1)</p>  <p>The number of jobs to run in parallel for both <code>fit</code> and <code>predict</code>. If -1, then the number of jobs is set to the number of cores.</p>  <p><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)</p>  <p>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p>  <p><strong>verbose</strong> : int, optional (default=0)</p>  <p>Controls the verbosity of the tree building process.</p>  <p><strong>warm_start</strong> : bool, optional (default=False)</p>  <p>When set to <code>True</code>, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>estimators_</strong> : list of DecisionTreeClassifier</p>  <p>The collection of fitted sub-estimators.</p>  </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r165" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id1">[R165]</a></td>
<td>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r166" rules="none">   <tr>
<td class="label"><a class="fn-backref" href="#id2">[R166]</a></td>
<td>Moosmann, F. and Triggs, B. and Jurie, F. “Fast discriminative visual codebooks using randomized clustering forests” NIPS 2007</td>
</tr>  </table> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.apply" title="sklearn.ensemble.RandomTreesEmbedding.apply"><code>apply</code></a>(X)</td> <td>Apply trees in the forest to X, return leaf indices.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.decision_path" title="sklearn.ensemble.RandomTreesEmbedding.decision_path"><code>decision_path</code></a>(X)</td> <td>Return the decision path in the forest</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.fit" title="sklearn.ensemble.RandomTreesEmbedding.fit"><code>fit</code></a>(X[, y, sample_weight])</td> <td>Fit estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.fit_transform" title="sklearn.ensemble.RandomTreesEmbedding.fit_transform"><code>fit_transform</code></a>(X[, y, sample_weight])</td> <td>Fit estimator and transform dataset.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.get_params" title="sklearn.ensemble.RandomTreesEmbedding.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.set_params" title="sklearn.ensemble.RandomTreesEmbedding.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.RandomTreesEmbedding.transform" title="sklearn.ensemble.RandomTreesEmbedding.transform"><code>transform</code></a>(X)</td> <td>Transform dataset.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.__init__">
<code>__init__(n_estimators=10, max_depth=5, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_leaf_nodes=None, min_impurity_split=1e-07, sparse_output=True, n_jobs=1, random_state=None, verbose=0, warm_start=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L1610" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.apply">
<code>apply(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L160" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Apply trees in the forest to X, return leaf indices.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like or sparse matrix, shape = [n_samples, n_features]</p>  <p>The input samples. Internally, its dtype will be converted to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be converted into a sparse <code>csr_matrix</code>.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_leaves</strong> : array_like, shape = [n_samples, n_estimators]</p>  <p>For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.decision_path">
<code>decision_path(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L184" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the decision path in the forest</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.18.</span></p> </div> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like or sparse matrix, shape = [n_samples, n_features]</p>  <p>The input samples. Internally, its dtype will be converted to <code>dtype=np.float32</code>. If a sparse matrix is provided, it will be converted into a sparse <code>csr_matrix</code>.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>indicator</strong> : sparse csr array, shape = [n_samples, n_nodes]</p>  <p>Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes.</p>  <p><strong>n_nodes_ptr</strong> : array of size (n_estimators + 1, )</p>  <p>The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="sklearn.ensemble.RandomTreesEmbedding.feature_importances_">
<code>feature_importances_</code> </dt> <dd>
<dl class="docutils"> <dt>Return the feature importances (the higher, the more important the</dt> <dd>feature).</dd> </dl> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>feature_importances_</strong> : array, shape = [n_features]</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.fit">
<code>fit(X, y=None, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L1650" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like or sparse matrix, shape=(n_samples, n_features)</p>  <p>The input samples. Use <code>dtype=np.float32</code> for maximum efficiency. Sparse matrices are also supported, use sparse <code>csc_matrix</code> for maximum efficiency.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>self</strong> : object</p>  <p>Returns self.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.fit_transform">
<code>fit_transform(X, y=None, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L1669" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit estimator and transform dataset.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like or sparse matrix, shape=(n_samples, n_features)</p>  <p>Input data used to build forests. Use <code>dtype=np.float32</code> for maximum efficiency.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_transformed</strong> : sparse matrix, shape=(n_samples, n_out)</p>  <p>Transformed dataset.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.RandomTreesEmbedding.transform">
<code>transform(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/forest.py#L1699" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Transform dataset.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like or sparse matrix, shape=(n_samples, n_features)</p>  <p>Input data to be transformed. Use <code>dtype=np.float32</code> for maximum efficiency. Sparse matrices are also supported, use sparse <code>csr_matrix</code> for maximum efficiency.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_transformed</strong> : sparse matrix, shape=(n_samples, n_out)</p>  <p>Transformed dataset.</p>  </td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-ensemble-randomtreesembedding">Examples using <code>sklearn.ensemble.RandomTreesEmbedding</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="Transform your features into a higher dimensional, sparse space. Then train a linear model on t...">
<div class="figure" id="id3"> <img alt="../../_images/sphx_glr_plot_feature_transformation_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_feature_transformation_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/ensemble/plot_feature_transformation/#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py"><span class="std std-ref">Feature transformations with ensembles of trees</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="RandomTreesEmbedding provides a way to map data to a very high-dimensional, sparse representati...">
<div class="figure" id="id4"> <img alt="../../_images/sphx_glr_plot_random_forest_embedding_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_random_forest_embedding_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/ensemble/plot_random_forest_embedding/#sphx-glr-auto-examples-ensemble-plot-random-forest-embedding-py"><span class="std std-ref">Hashing feature transformation using Totally Random Trees</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="An illustration of various embeddings on the digits dataset.">
<div class="figure" id="id5"> <img alt="../../_images/sphx_glr_plot_lle_digits_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_lle_digits_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/manifold/plot_lle_digits/#sphx-glr-auto-examples-manifold-plot-lle-digits-py"><span class="std std-ref">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomTreesEmbedding.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomTreesEmbedding.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
