
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>covariance.GraphLassoCV() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Sparse inverse covariance w&#47; cross-validated choice of the l1 penalty ">
  <meta name="keywords" content="sklearn, covariance, graphlassocv, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.covariance.graphlassocv/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-covariance-graphlassocv">sklearn.covariance.GraphLassoCV</h1> <dl class="class"> <dt id="sklearn.covariance.GraphLassoCV">
<code>class sklearn.covariance.GraphLassoCV(alphas=4, n_refinements=4, cv=None, tol=0.0001, enet_tol=0.0001, max_iter=100, mode='cd', n_jobs=1, verbose=False, assume_centered=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/graph_lasso_.py#L451" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Sparse inverse covariance w/ cross-validated choice of the l1 penalty</p> <p>Read more in the <a class="reference internal" href="../../covariance/#sparse-inverse-covariance"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>alphas</strong> : integer, or list positive float, optional</p>  <p>If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details.</p>  <p><strong>n_refinements: strictly positive integer</strong> :</p>  <p>The number of times the grid is refined. Not used if explicit values of alphas are passed.</p>  <p><strong>cv</strong> : int, cross-validation generator or an iterable, optional</p>  <p>Determines the cross-validation splitting strategy. Possible inputs for cv are:</p> <ul class="simple"> <li>None, to use the default 3-fold cross-validation,</li> <li>integer, to specify the number of folds.</li> <li>An object to be used as a cross-validation generator.</li> <li>An iterable yielding train/test splits.</li> </ul> <p>For integer/None inputs <code>KFold</code> is used.</p> <p>Refer <a class="reference internal" href="../../cross_validation/#cross-validation"><span class="std std-ref">User Guide</span></a> for the various cross-validation strategies that can be used here.</p>  <p><strong>tol: positive float, optional</strong> :</p>  <p>The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped.</p>  <p><strong>enet_tol</strong> : positive float, optional</p>  <p>The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=’cd’.</p>  <p><strong>max_iter: integer, optional</strong> :</p>  <p>Maximum number of iterations.</p>  <p><strong>mode: {‘cd’, ‘lars’}</strong> :</p>  <p>The Lasso solver to use: coordinate descent or LARS. Use LARS for very sparse underlying graphs, where number of features is greater than number of samples. Elsewhere prefer cd which is more numerically stable.</p>  <p><strong>n_jobs: int, optional</strong> :</p>  <p>number of jobs to run in parallel (default 1).</p>  <p><strong>verbose: boolean, optional</strong> :</p>  <p>If verbose is True, the objective function and duality gap are printed at each iteration.</p>  <p><strong>assume_centered</strong> : Boolean</p>  <p>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>covariance_</strong> : numpy.ndarray, shape (n_features, n_features)</p>  <p>Estimated covariance matrix.</p>  <p><strong>precision_</strong> : numpy.ndarray, shape (n_features, n_features)</p>  <p>Estimated precision matrix (inverse covariance).</p>  <p><strong>alpha_</strong> : float</p>  <p>Penalization parameter selected.</p>  <p><strong>cv_alphas_</strong> : list of float</p>  <p>All penalization parameters explored.</p>  <p><strong>`grid_scores`: 2D numpy.ndarray (n_alphas, n_folds)</strong> :</p>  <p>Log-likelihood score on left-out data across folds.</p>  <p><strong>n_iter_</strong> : int</p>  <p>Number of iterations run for the optimal alpha.</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <p class="last"><a class="reference internal" href="../sklearn.covariance.graph_lasso/#sklearn.covariance.graph_lasso" title="sklearn.covariance.graph_lasso"><code>graph_lasso</code></a>, <a class="reference internal" href="../sklearn.covariance.graphlasso/#sklearn.covariance.GraphLasso" title="sklearn.covariance.GraphLasso"><code>GraphLasso</code></a></p> </div> <h4 class="rubric">Notes</h4> <p>The search for the optimal penalization parameter (alpha) is done on an iteratively refined grid: first the cross-validated scores on a grid are computed, then a new refined grid is centered around the maximum, and so on.</p> <p>One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.</p> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.error_norm" title="sklearn.covariance.GraphLassoCV.error_norm"><code>error_norm</code></a>(comp_cov[, norm, scaling, squared])</td> <td>Computes the Mean Squared Error between two covariance estimators.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.fit" title="sklearn.covariance.GraphLassoCV.fit"><code>fit</code></a>(X[, y])</td> <td>Fits the GraphLasso covariance model to X.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.get_params" title="sklearn.covariance.GraphLassoCV.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.get_precision" title="sklearn.covariance.GraphLassoCV.get_precision"><code>get_precision</code></a>()</td> <td>Getter for the precision matrix.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.mahalanobis" title="sklearn.covariance.GraphLassoCV.mahalanobis"><code>mahalanobis</code></a>(observations)</td> <td>Computes the squared Mahalanobis distances of given observations.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.score" title="sklearn.covariance.GraphLassoCV.score"><code>score</code></a>(X_test[, y])</td> <td>Computes the log-likelihood of a Gaussian data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.GraphLassoCV.set_params" title="sklearn.covariance.GraphLassoCV.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.__init__">
<code>__init__(alphas=4, n_refinements=4, cv=None, tol=0.0001, enet_tol=0.0001, max_iter=100, mode='cd', n_jobs=1, verbose=False, assume_centered=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/graph_lasso_.py#L551" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.error_norm">
<code>error_norm(comp_cov, norm='frobenius', scaling=True, squared=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L213" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the Mean Squared Error between two covariance estimators. (In the sense of the Frobenius norm).</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>comp_cov</strong> : array-like, shape = [n_features, n_features]</p>  <p>The covariance to compare with.</p>  <p><strong>norm</strong> : str</p>  <p>The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error <code>(comp_cov - self.covariance_)</code>.</p>  <p><strong>scaling</strong> : bool</p>  <p>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</p>  <p><strong>squared</strong> : bool</p>  <p>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>The Mean Squared Error (in the sense of the Frobenius norm) between</strong> :</p> <p class="last"><strong>`self` and `comp_cov` covariance estimators.</strong> :</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.fit">
<code>fit(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/graph_lasso_.py#L567" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fits the GraphLasso covariance model to X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : ndarray, shape (n_samples, n_features)</p>  <p>Data from which to compute the covariance estimate</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.get_precision">
<code>get_precision()</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L140" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Getter for the precision matrix.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>precision_</strong> : array-like,</p>  <p>The precision matrix associated to the current covariance object.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.mahalanobis">
<code>mahalanobis(observations)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L265" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the squared Mahalanobis distances of given observations.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>observations</strong> : array-like, shape = [n_observations, n_features]</p>  <p>The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>mahalanobis_distance</strong> : array, shape = [n_observations,]</p>  <p>Squared Mahalanobis distances of the observations.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.score">
<code>score(X_test, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L184" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the log-likelihood of a Gaussian data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X_test</strong> : array-like, shape = [n_samples, n_features]</p>  <p>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</p>  <p><strong>y</strong> : not used, present for API consistence purpose.</p> </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>res</strong> : float</p>  <p>The likelihood of the data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.GraphLassoCV.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-covariance-graphlassocv">Examples using <code>sklearn.covariance.GraphLassoCV</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="This example employs several unsupervised learning techniques to extract the stock market struc...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_stock_market_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_stock_market_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/applications/plot_stock_market/#sphx-glr-auto-examples-applications-plot-stock-market-py"><span class="std std-ref">Visualizing the stock market structure</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Using the GraphLasso estimator to learn a covariance and sparse precision from a small number o...">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_sparse_cov_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_sparse_cov_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/covariance/plot_sparse_cov/#sphx-glr-auto-examples-covariance-plot-sparse-cov-py"><span class="std std-ref">Sparse inverse covariance estimation</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphLassoCV.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphLassoCV.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
