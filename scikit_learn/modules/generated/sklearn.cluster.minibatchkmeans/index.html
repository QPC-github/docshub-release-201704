
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>cluster.MiniBatchKMeans() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Mini-Batch K-Means clustering ">
  <meta name="keywords" content="sklearn, cluster, minibatchkmeans, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.cluster.minibatchkmeans/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-cluster-minibatchkmeans">sklearn.cluster.MiniBatchKMeans</h1> <dl class="class"> <dt id="sklearn.cluster.MiniBatchKMeans">
<code>class sklearn.cluster.MiniBatchKMeans(n_clusters=8, init='k-means++', max_iter=100, batch_size=100, verbose=0, compute_labels=True, random_state=None, tol=0.0, max_no_improvement=10, init_size=None, n_init=3, reassignment_ratio=0.01)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L1184" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Mini-Batch K-Means clustering</p> <p>Read more in the <a class="reference internal" href="../../clustering/#mini-batch-kmeans"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>n_clusters</strong> : int, optional, default: 8</p>  <p>The number of clusters to form as well as the number of centroids to generate.</p>  <p><strong>max_iter</strong> : int, optional</p>  <p>Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.</p>  <p><strong>max_no_improvement</strong> : int, default: 10</p>  <p>Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed inertia.</p> <p>To disable convergence detection based on inertia, set max_no_improvement to None.</p>  <p><strong>tol</strong> : float, default: 0.0</p>  <p>Control early stopping based on the relative center changes as measured by a smoothed, variance-normalized of the mean center squared position changes. This early stopping heuristics is closer to the one used for the batch variant of the algorithms but induces a slight computational and memory overhead over the inertia heuristic.</p> <p>To disable convergence detection based on normalized center change, set tol to 0.0 (default).</p>  <p><strong>batch_size</strong> : int, optional, default: 100</p>  <p>Size of the mini batches.</p>  <p><strong>init_size</strong> : int, optional, default: 3 * batch_size</p>  <p>Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.</p>  <p><strong>init</strong> : {‘k-means++’, ‘random’ or an ndarray}, default: ‘k-means++’</p>  <p>Method for initialization, defaults to ‘k-means++’:</p> <p>‘k-means++’ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. See section Notes in k_init for more details.</p> <p>‘random’: choose k observations (rows) at random from data for the initial centroids.</p> <p>If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.</p>  <p><strong>n_init</strong> : int, default=3</p>  <p>Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the <code>n_init</code> initializations as measured by inertia.</p>  <p><strong>compute_labels</strong> : boolean, default=True</p>  <p>Compute label assignment and inertia for the complete dataset once the minibatch optimization has converged in fit.</p>  <p><strong>random_state</strong> : integer or numpy.RandomState, optional</p>  <p>The generator used to initialize the centers. If an integer is given, it fixes the seed. Defaults to the global numpy random number generator.</p>  <p><strong>reassignment_ratio</strong> : float, default: 0.01</p>  <p>Control the fraction of the maximum number of counts for a center to be reassigned. A higher value means that low count centers are more easily reassigned, which means that the model will take longer to converge, but should converge in a better clustering.</p>  <p><strong>verbose</strong> : boolean, optional</p>  <p>Verbosity mode.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>cluster_centers_</strong> : array, [n_clusters, n_features]</p>  <p>Coordinates of cluster centers</p>  <p><strong>labels_ :</strong> :</p>  <p>Labels of each point (if compute_labels is set to True).</p>  <p><strong>inertia_</strong> : float</p>  <p>The value of the inertia criterion associated with the chosen partition (if compute_labels is set to True). The inertia is defined as the sum of square distances of samples to their nearest neighbor.</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="../sklearn.cluster.kmeans/#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code>KMeans</code></a>
</dt> <dd>The classic implementation of the clustering method based on the Lloyd’s algorithm. It consumes the whole set of input data at each iteration.</dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>See <a class="reference external" href="http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf" target="_blank">http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf</a></p> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.fit" title="sklearn.cluster.MiniBatchKMeans.fit"><code>fit</code></a>(X[, y])</td> <td>Compute the centroids on X by chunking it into mini-batches.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.fit_predict" title="sklearn.cluster.MiniBatchKMeans.fit_predict"><code>fit_predict</code></a>(X[, y])</td> <td>Compute cluster centers and predict cluster index for each sample.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.fit_transform" title="sklearn.cluster.MiniBatchKMeans.fit_transform"><code>fit_transform</code></a>(X[, y])</td> <td>Compute clustering and transform X to cluster-distance space.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.get_params" title="sklearn.cluster.MiniBatchKMeans.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.partial_fit" title="sklearn.cluster.MiniBatchKMeans.partial_fit"><code>partial_fit</code></a>(X[, y])</td> <td>Update k means estimate on a single mini-batch X.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.predict" title="sklearn.cluster.MiniBatchKMeans.predict"><code>predict</code></a>(X)</td> <td>Predict the closest cluster each sample in X belongs to.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.score" title="sklearn.cluster.MiniBatchKMeans.score"><code>score</code></a>(X[, y])</td> <td>Opposite of the value of X on the K-means objective.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.set_params" title="sklearn.cluster.MiniBatchKMeans.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.cluster.MiniBatchKMeans.transform" title="sklearn.cluster.MiniBatchKMeans.transform"><code>transform</code></a>(X[, y])</td> <td>Transform X to a cluster-distance space.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.__init__">
<code>__init__(n_clusters=8, init='k-means++', max_iter=100, batch_size=100, verbose=0, compute_labels=True, random_state=None, tol=0.0, max_no_improvement=10, init_size=None, n_init=3, reassignment_ratio=0.01)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L1293" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.fit">
<code>fit(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L1308" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute the centroids on X by chunking it into mini-batches.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>  <p>Coordinates of the data points to cluster</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.fit_predict">
<code>fit_predict(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L893" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute cluster centers and predict cluster index for each sample.</p> <p>Convenience method; equivalent to calling fit(X) followed by predict(X).</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.fit_transform">
<code>fit_transform(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L901" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compute clustering and transform X to cluster-distance space.</p> <p>Equivalent to fit(X).transform(X), but more efficiently implemented.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.partial_fit">
<code>partial_fit(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L1470" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Update k means estimate on a single mini-batch X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>  <p>Coordinates of the data points to cluster.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L1523" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict the closest cluster each sample in X belongs to.</p> <p>In the vector quantization literature, <code>cluster_centers_</code> is called the code book and each value returned by <code>predict</code> is the index of the closest code in the code book.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>New data to predict.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>labels</strong> : array, shape [n_samples,]</p>  <p>Index of the cluster each sample belongs to.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.score">
<code>score(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L962" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Opposite of the value of X on the K-means objective.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>New data.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>Opposite of the value of X on the K-means objective.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.cluster.MiniBatchKMeans.transform">
<code>transform(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/cluster/k_means_.py#L913" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Transform X to a cluster-distance space.</p> <p>In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by <code>transform</code> will typically be dense.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>New data to transform.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_new</strong> : array, shape [n_samples, k]</p>  <p>X transformed in the new space.</p>  </td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-cluster-minibatchkmeans">Examples using <code>sklearn.cluster.MiniBatchKMeans</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="This example demonstrates the Spectral Co-clustering algorithm on the twenty newsgroups dataset...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_bicluster_newsgroups_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_bicluster_newsgroups_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/bicluster/bicluster_newsgroups/#sphx-glr-auto-examples-bicluster-bicluster-newsgroups-py"><span class="std std-ref">Biclustering documents with the Spectral Co-clustering algorithm</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example compares the timing of Birch (with and without the global clustering step) and Min...">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_birch_vs_minibatchkmeans_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_birch_vs_minibatchkmeans_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_birch_vs_minibatchkmeans/#sphx-glr-auto-examples-cluster-plot-birch-vs-minibatchkmeans-py"><span class="std std-ref">Compare BIRCH and MiniBatchKMeans</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example aims at showing characteristics of different clustering algorithms on datasets tha...">
<div class="figure" id="id3"> <img alt="../../_images/sphx_glr_plot_cluster_comparison_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_cluster_comparison/#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py"><span class="std std-ref">Comparing different clustering algorithms on toy datasets</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example uses a large dataset of faces to learn a set of 20 x 20 images patches that consti...">
<div class="figure" id="id4"> <img alt="../../_images/sphx_glr_plot_dict_face_patches_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_dict_face_patches_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_dict_face_patches/#sphx-glr-auto-examples-cluster-plot-dict-face-patches-py"><span class="std std-ref">Online learning of a dictionary of parts of faces</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Evaluate the ability of k-means initializations strategies to make the algorithm convergence ro...">
<div class="figure" id="id5"> <img alt="../../_images/sphx_glr_plot_kmeans_stability_low_dim_dense_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kmeans_stability_low_dim_dense_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_kmeans_stability_low_dim_dense/#sphx-glr-auto-examples-cluster-plot-kmeans-stability-low-dim-dense-py"><span class="std std-ref">Empirical evaluation of the impact of k-means initialization</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="We want to compare the performance of the MiniBatchKMeans and KMeans: the MiniBatchKMeans is fa...">
<div class="figure" id="id6"> <img alt="../../_images/sphx_glr_plot_mini_batch_kmeans_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_mini_batch_kmeans_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/cluster/plot_mini_batch_kmeans/#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py"><span class="std std-ref">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This example applies to :ref:`olivetti_faces` different unsupervised matrix decomposition (dime...">
<div class="figure" id="id7"> <img alt="../../_images/sphx_glr_plot_faces_decomposition_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_faces_decomposition_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/decomposition/plot_faces_decomposition/#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py"><span class="std std-ref">Faces dataset decompositions</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="This is an example showing how the scikit-learn can be used to cluster documents by topics usin...">
<div class="figure" id="id8"> <img alt="../../_images/sphx_glr_document_clustering_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_document_clustering_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/text/document_clustering/#sphx-glr-auto-examples-text-document-clustering-py"><span class="std std-ref">Clustering text documents using k-means</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
