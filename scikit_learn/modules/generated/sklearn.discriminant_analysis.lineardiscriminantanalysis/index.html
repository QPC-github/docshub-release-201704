
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>discriminant_analysis.LinearDiscriminantAnalysis() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Linear Discriminant Analysis ">
  <meta name="keywords" content="sklearn, discriminant, analysis, lineardiscriminantanalysis, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.discriminant_analysis.lineardiscriminantanalysis/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-discriminant-analysis-lineardiscriminantanalysis">sklearn.discriminant_analysis.LinearDiscriminantAnalysis</h1> <dl class="class"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis">
<code>class sklearn.discriminant_analysis.LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L130" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Linear Discriminant Analysis</p> <p>A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.</p> <p>The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.</p> <p>The fitted model can also be used to reduce the dimensionality of the input by projecting it to the most discriminative directions.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>LinearDiscriminantAnalysis</em>.</p> </div> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <code>lda.LDA</code> have been moved to <a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis"><code>LinearDiscriminantAnalysis</code></a>.</p> </div> <p>Read more in the <a class="reference internal" href="../../lda_qda/#lda-qda"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>solver</strong> : string, optional</p>  <dl class="docutils"> <dt>Solver to use, possible values:</dt> <dd>
<ul class="first last simple"> <li>‘svd’: Singular value decomposition (default). Does not compute the covariance matrix, therefore this solver is recommended for data with a large number of features.</li> <li>‘lsqr’: Least squares solution, can be combined with shrinkage.</li> <li>‘eigen’: Eigenvalue decomposition, can be combined with shrinkage.</li> </ul> </dd> </dl>  <p><strong>shrinkage</strong> : string or float, optional</p>  <dl class="docutils"> <dt>Shrinkage parameter, possible values:</dt> <dd>
<ul class="first last simple"> <li>None: no shrinkage (default).</li> <li>‘auto’: automatic shrinkage using the Ledoit-Wolf lemma.</li> <li>float between 0 and 1: fixed shrinkage parameter.</li> </ul> </dd> </dl> <p>Note that shrinkage works only with ‘lsqr’ and ‘eigen’ solvers.</p>  <p><strong>priors</strong> : array, optional, shape (n_classes,)</p>  <p>Class priors.</p>  <p><strong>n_components</strong> : int, optional</p>  <p>Number of components (&lt; n_classes - 1) for dimensionality reduction.</p>  <p><strong>store_covariance</strong> : bool, optional</p>  <p>Additionally compute class covariance matrix (default False).</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17.</span></p> </div>  <p><strong>tol</strong> : float, optional</p>  <p>Threshold used for rank estimation in SVD solver.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17.</span></p> </div>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>coef_</strong> : array, shape (n_features,) or (n_classes, n_features)</p>  <p>Weight vector(s).</p>  <p><strong>intercept_</strong> : array, shape (n_features,)</p>  <p>Intercept term.</p>  <p><strong>covariance_</strong> : array-like, shape (n_features, n_features)</p>  <p>Covariance matrix (shared by all classes).</p>  <p><strong>explained_variance_ratio_</strong> : array, shape (n_components,)</p>  <p>Percentage of variance explained by each of the selected components. If <code>n_components</code> is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.</p>  <p><strong>means_</strong> : array-like, shape (n_classes, n_features)</p>  <p>Class means.</p>  <p><strong>priors_</strong> : array-like, shape (n_classes,)</p>  <p>Class priors (sum to 1).</p>  <p><strong>scalings_</strong> : array-like, shape (rank, n_classes - 1)</p>  <p>Scaling of the features in the space spanned by the class centroids.</p>  <p><strong>xbar_</strong> : array-like, shape (n_features,)</p>  <p>Overall mean.</p>  <p><strong>classes_</strong> : array-like, shape (n_classes,)</p>  <p>Unique class labels.</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
 <a class="reference internal" href="../sklearn.discriminant_analysis.quadraticdiscriminantanalysis/#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis" title="sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis"><code>sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis</code></a>
</dt> <dd>Quadratic Discriminant Analysis</dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>The default solver is ‘svd’. It can perform both classification and transform, and it does not rely on the calculation of the covariance matrix. This can be an advantage in situations where the number of features is large. However, the ‘svd’ solver cannot be used with shrinkage.</p> <p>The ‘lsqr’ solver is an efficient algorithm that only works for classification. It supports shrinkage.</p> <p>The ‘eigen’ solver is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classification and transform, and it supports shrinkage. However, the ‘eigen’ solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
&gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2])
&gt;&gt;&gt; clf = LinearDiscriminantAnalysis()
&gt;&gt;&gt; clf.fit(X, y)
LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
&gt;&gt;&gt; print(clf.predict([[-0.8, -1]]))
[1]
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function"><code>decision_function</code></a>(X)</td> <td>Predict confidence scores for samples.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit"><code>fit</code></a>(X, y[, store_covariance, tol])</td> <td>Fit LinearDiscriminantAnalysis model according to the given training data and parameters.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform"><code>fit_transform</code></a>(X[, y])</td> <td>Fit to data, then transform it.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict"><code>predict</code></a>(X)</td> <td>Predict class labels for samples in X.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba"><code>predict_log_proba</code></a>(X)</td> <td>Estimate log probability.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba"><code>predict_proba</code></a>(X)</td> <td>Estimate probability.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the mean accuracy on the given test data and labels.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform"><code>transform</code></a>(X)</td> <td>Project data to maximize class separation.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__">
<code>__init__(solver='svd', shrinkage=None, priors=None, n_components=None, store_covariance=False, tol=0.0001)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L251" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/base.py#L290" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict confidence scores for samples.</p> <p>The confidence score for a sample is the signed distance of that sample to the hyperplane.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>  <p>Samples.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</strong> :</p>  <p>Confidence scores per (sample, class) combination. In the binary case, confidence score for self.classes_[1] where &gt;0 means this class would be predicted.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit">
<code>fit(X, y, store_covariance=None, tol=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L412" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="docutils"> <dt>Fit LinearDiscriminantAnalysis model according to the given</dt> <dd>
<p class="first">training data and parameters.</p> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <em>store_covariance</em> have been moved to main constructor.</p> </div> <div class="last versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <em>tol</em> have been moved to main constructor.</p> </div> </dd> </dl> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>Training data.</p>  <p><strong>y</strong> : array, shape (n_samples,)</p>  <p>Target values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform">
<code>fit_transform(X, y=None, **fit_params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L470" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit to data, then transform it.</p> <p>Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>  <p>Training set.</p>  <p><strong>y</strong> : numpy array of shape [n_samples]</p>  <p>Target values.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>  <p>Transformed array.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/linear_model/base.py#L323" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class labels for samples in X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>Samples.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape = [n_samples]</p>  <p>Predicted class label per sample.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba">
<code>predict_log_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L529" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate log probability.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>Input data.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape (n_samples, n_classes)</p>  <p>Estimated log probabilities.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L504" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate probability.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>Input data.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape (n_samples, n_classes)</p>  <p>Estimated probabilities.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L324" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True labels for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>Mean accuracy of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform">
<code>transform(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/discriminant_analysis.py#L477" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Project data to maximize class separation.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>  <p>Input data.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X_new</strong> : array, shape (n_samples, n_components)</p>  <p>Transformed data.</p>  </td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-discriminant-analysis-lineardiscriminantanalysis">Examples using <code>sklearn.discriminant_analysis.LinearDiscriminantAnalysis</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="Shows how shrinkage improves classification. ">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_lda_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_lda_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/classification/plot_lda/#sphx-glr-auto-examples-classification-plot-lda-py"><span class="std std-ref">Normal and Shrinkage Linear Discriminant Analysis for classification</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Plot the confidence ellipsoids of each class and decision boundary ">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_lda_qda_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_lda_qda_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/classification/plot_lda_qda/#sphx-glr-auto-examples-classification-plot-lda-qda-py"><span class="std std-ref">Linear and Quadratic Discriminant Analysis with confidence ellipsoid</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 a...">
<div class="figure" id="id3"> <img alt="../../_images/sphx_glr_plot_pca_vs_lda_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_pca_vs_lda_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/decomposition/plot_pca_vs_lda/#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py"><span class="std std-ref">Comparison of LDA and PCA 2D projection of Iris dataset</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="An illustration of various embeddings on the digits dataset.">
<div class="figure" id="id4"> <img alt="../../_images/sphx_glr_plot_lle_digits_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_lle_digits_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/manifold/plot_lle_digits/#sphx-glr-auto-examples-manifold-plot-lle-digits-py"><span class="std std-ref">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
