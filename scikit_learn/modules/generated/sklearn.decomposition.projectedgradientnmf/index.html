
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>decomposition.ProjectedGradientNMF() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Non-Negative Matrix Factorization (NMF) ">
  <meta name="keywords" content="sklearn, decomposition, projectedgradientnmf, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.decomposition.projectedgradientnmf/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-decomposition-projectedgradientnmf">sklearn.decomposition.ProjectedGradientNMF</h1> <dl class="class"> <dt id="sklearn.decomposition.ProjectedGradientNMF">
<code>class sklearn.decomposition.ProjectedGradientNMF(*args, **kwargs)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/decomposition/nmf.py#L1133" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Non-Negative Matrix Factorization (NMF)</p> <p>Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.</p> <p>The objective function is:</p> <pre data-language="python">0.5 * ||X - WH||_Fro^2
+ alpha * l1_ratio * ||vec(W)||_1
+ alpha * l1_ratio * ||vec(H)||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2
</pre> <p>Where:</p> <pre data-language="python">||A||_Fro^2 = \sum_{i,j} A_{ij}^2 (Frobenius norm)
||vec(A)||_1 = \sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)
</pre> <p>The objective function is minimized with an alternating minimization of W and H.</p> <p>Read more in the <a class="reference internal" href="../../decomposition/#nmf"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>n_components</strong> : int or None</p>  <p>Number of components, if n_components is not set all features are kept.</p>  <p><strong>init</strong> : ‘random’ | ‘nndsvd’ | ‘nndsvda’ | ‘nndsvdar’ | ‘custom’</p>  <p>Method used to initialize the procedure. Default: ‘nndsvdar’ if n_components &lt; n_features, otherwise random. Valid options:</p> <ul> <li>
<dl class="first docutils"> <dt>‘random’: non-negative random matrices, scaled with:</dt> <dd>
<p class="first last">sqrt(X.mean() / n_components)</p> </dd> </dl> </li> <li>
<dl class="first docutils"> <dt>‘nndsvd’: Nonnegative Double Singular Value Decomposition (NNDSVD)</dt> <dd>
<p class="first last">initialization (better for sparseness)</p> </dd> </dl> </li> <li>
<dl class="first docutils"> <dt>‘nndsvda’: NNDSVD with zeros filled with the average of X</dt> <dd>
<p class="first last">(better when sparsity is not desired)</p> </dd> </dl> </li> <li>
<dl class="first docutils"> <dt>‘nndsvdar’: NNDSVD with zeros filled with small random values</dt> <dd>
<p class="first last">(generally faster, less accurate alternative to NNDSVDa for when sparsity is not desired)</p> </dd> </dl> </li> <li>‘custom’: use custom matrices W and H </li> </ul>  <p><strong>solver</strong> : ‘pg’ | ‘cd’</p>  <p>Numerical solver to use: ‘pg’ is a Projected Gradient solver (deprecated). ‘cd’ is a Coordinate Descent solver (recommended).</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span>Coordinate Descent solver.</p> </div> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated Projected Gradient solver.</p> </div>  <p><strong>tol</strong> : double, default: 1e-4</p>  <p>Tolerance value used in stopping conditions.</p>  <p><strong>max_iter</strong> : integer, default: 200</p>  <p>Number of iterations to compute.</p>  <p><strong>random_state</strong> : integer seed, RandomState instance, or None (default)</p>  <p>Random number generator seed control.</p>  <p><strong>alpha</strong> : double, default: 0.</p>  <p>Constant that multiplies the regularization terms. Set it to zero to have no regularization.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>alpha</em> used in the Coordinate Descent solver.</p> </div>  <p><strong>l1_ratio</strong> : double, default: 0.</p>  <p>The regularization mixing parameter, with 0 &lt;= l1_ratio &lt;= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 &lt; l1_ratio &lt; 1, the penalty is a combination of L1 and L2.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span>Regularization parameter <em>l1_ratio</em> used in the Coordinate Descent solver.</p> </div>  <p><strong>shuffle</strong> : boolean, default: False</p>  <p>If true, randomize the order of coordinates in the CD solver.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>shuffle</em> parameter used in the Coordinate Descent solver.</p> </div>  <p><strong>nls_max_iter</strong> : integer, default: 2000</p>  <p>Number of iterations in NLS subproblem. Used only in the deprecated ‘pg’ solver.</p> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated Projected Gradient solver. Use Coordinate Descent solver instead.</p> </div>  <p><strong>sparseness</strong> : ‘data’ | ‘components’ | None, default: None</p>  <p>Where to enforce sparsity in the model. Used only in the deprecated ‘pg’ solver.</p> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated Projected Gradient solver. Use Coordinate Descent solver instead.</p> </div>  <p><strong>beta</strong> : double, default: 1</p>  <p>Degree of sparseness, if sparseness is not None. Larger values mean more sparseness. Used only in the deprecated ‘pg’ solver.</p> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated Projected Gradient solver. Use Coordinate Descent solver instead.</p> </div>  <p><strong>eta</strong> : double, default: 0.1</p>  <p>Degree of correctness to maintain, if sparsity is not None. Smaller values mean larger error. Used only in the deprecated ‘pg’ solver.</p> <div class="versionchanged"> <p><span class="versionmodified">Changed in version 0.17: </span>Deprecated Projected Gradient solver. Use Coordinate Descent solver instead.</p> </div>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>components_</strong> : array, [n_components, n_features]</p>  <p>Non-negative components of the data.</p>  <p><strong>reconstruction_err_</strong> : number</p>  <p>Frobenius norm of the matrix difference between the training data and the reconstructed data from the fit produced by the model. <code>|| X - WH ||_2</code></p>  <p><strong>n_iter_</strong> : int</p>  <p>Actual number of iterations.</p>  </td> </tr>  </table> <h4 class="rubric">References</h4> <p>C.-J. Lin. Projected gradient methods for non-negative matrix factorization. Neural Computation, 19(2007), 2756-2779. <a class="reference external" href="http://www.csie.ntu.edu.tw/~cjlin/nmf/" target="_blank">http://www.csie.ntu.edu.tw/~cjlin/nmf/</a></p> <p>Cichocki, Andrzej, and P. H. A. N. Anh-Huy. “Fast local algorithms for large scale nonnegative matrix and tensor factorizations.” IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721, 2009.</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
&gt;&gt;&gt; from sklearn.decomposition import NMF
&gt;&gt;&gt; model = NMF(n_components=2, init='random', random_state=0)
&gt;&gt;&gt; model.fit(X) 
NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,
  n_components=2, nls_max_iter=2000, random_state=0, shuffle=False,
  solver='cd', sparseness=None, tol=0.0001, verbose=0)
</pre> <pre data-language="python">&gt;&gt;&gt; model.components_
array([[ 2.09783018,  0.30560234],
       [ 2.13443044,  2.13171694]])
&gt;&gt;&gt; model.reconstruction_err_ 
0.00115993...
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.fit" title="sklearn.decomposition.ProjectedGradientNMF.fit"><code>fit</code></a>(X[, y])</td> <td>Learn a NMF model for the data X.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.fit_transform" title="sklearn.decomposition.ProjectedGradientNMF.fit_transform"><code>fit_transform</code></a>(X[, y, W, H])</td> <td>Learn a NMF model for the data X and returns the transformed data.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.get_params" title="sklearn.decomposition.ProjectedGradientNMF.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.inverse_transform" title="sklearn.decomposition.ProjectedGradientNMF.inverse_transform"><code>inverse_transform</code></a>(W)</td> <td>Transform data back to its original space.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.set_params" title="sklearn.decomposition.ProjectedGradientNMF.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.decomposition.ProjectedGradientNMF.transform" title="sklearn.decomposition.ProjectedGradientNMF.transform"><code>transform</code></a>(X)</td> <td>Transform the data X according to the fitted NMF model</td> </tr>  </table> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.__init__">
<code>__init__(*args, **kwargs)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/utils/deprecation.py#L51" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>DEPRECATED: It will be removed in release 0.19. Use NMF instead.’pg’ solver is still available until release 0.19.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.fit">
<code>fit(X, y=None, **params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/decomposition/nmf.py#L1056" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Learn a NMF model for the data X.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X: {array-like, sparse matrix}, shape (n_samples, n_features)</strong> :</p>  <p>Data matrix to be decomposed</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>self</strong> :</p> </td> </tr> <tr class="field-odd field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>components_</strong> : array-like, shape (n_components, n_features)</p>  <p>Factorization matrix, sometimes called ‘dictionary’.</p>  <p><strong>n_iter_</strong> : int</p>  <p>Actual number of iterations for the transform.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.fit_transform">
<code>fit_transform(X, y=None, W=None, H=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/decomposition/nmf.py#L1003" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Learn a NMF model for the data X and returns the transformed data.</p> <p>This is more efficient than calling fit followed by transform.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X: {array-like, sparse matrix}, shape (n_samples, n_features)</strong> :</p>  <p>Data matrix to be decomposed</p>  <p><strong>W</strong> : array-like, shape (n_samples, n_components)</p>  <p>If init=’custom’, it is used as initial guess for the solution.</p>  <p><strong>H</strong> : array-like, shape (n_components, n_features)</p>  <p>If init=’custom’, it is used as initial guess for the solution.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>W: array, shape (n_samples, n_components)</strong> :</p>  <p>Transformed data.</p>  </td> </tr> <tr class="field-odd field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>components_</strong> : array-like, shape (n_components, n_features)</p>  <p>Factorization matrix, sometimes called ‘dictionary’.</p>  <p><strong>n_iter_</strong> : int</p>  <p>Actual number of iterations for the transform.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.inverse_transform">
<code>inverse_transform(W)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/decomposition/nmf.py#L1112" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Transform data back to its original space.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>W: {array-like, sparse matrix}, shape (n_samples, n_components)</strong> :</p>  <p>Transformed data matrix</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>X: {array-like, sparse matrix}, shape (n_samples, n_features)</strong> :</p>  <p>Data matrix of original shape</p>  <p class="last"><strong>.. versionadded:: 0.18</strong> :</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.decomposition.ProjectedGradientNMF.transform">
<code>transform(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/decomposition/nmf.py#L1079" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Transform the data X according to the fitted NMF model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X: {array-like, sparse matrix}, shape (n_samples, n_features)</strong> :</p>  <p>Data matrix to be transformed by the model</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>W: array, shape (n_samples, n_components)</strong> :</p>  <p>Transformed data</p>  </td> </tr> <tr class="field-odd field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>n_iter_</strong> : int</p>  <p>Actual number of iterations for the transform.</p>  </td> </tr>  </table> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.ProjectedGradientNMF.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.ProjectedGradientNMF.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
