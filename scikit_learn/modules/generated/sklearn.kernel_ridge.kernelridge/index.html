
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>kernel_ridge.KernelRidge() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Kernel ridge regression. ">
  <meta name="keywords" content="sklearn, kernel, ridge, kernelridge, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.kernel_ridge.kernelridge/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-kernel-ridge-kernelridge">sklearn.kernel_ridge.KernelRidge</h1> <dl class="class"> <dt id="sklearn.kernel_ridge.KernelRidge">
<code>class sklearn.kernel_ridge.KernelRidge(alpha=1, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/kernel_ridge.py#L16" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Kernel ridge regression.</p> <p>Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.</p> <p>The form of the model learned by KRR is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting a KRR model can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR, which learns a sparse model for epsilon &gt; 0, at prediction-time.</p> <p>This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).</p> <p>Read more in the <a class="reference internal" href="../../kernel_ridge/#kernel-ridge"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>alpha</strong> : {float, array-like}, shape = [n_targets]</p>  <p>Small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. Alpha corresponds to <code>(2*C)^-1</code> in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.</p>  <p><strong>kernel</strong> : string or callable, default=”linear”</p>  <p>Kernel mapping used internally. A callable should accept two arguments and the keyword arguments passed to this object as kernel_params, and should return a floating point number.</p>  <p><strong>gamma</strong> : float, default=None</p>  <p>Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.</p>  <p><strong>degree</strong> : float, default=3</p>  <p>Degree of the polynomial kernel. Ignored by other kernels.</p>  <p><strong>coef0</strong> : float, default=1</p>  <p>Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.</p>  <p><strong>kernel_params</strong> : mapping of string to any, optional</p>  <p>Additional parameters (keyword arguments) for kernel function passed as callable object.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>dual_coef_</strong> : array, shape = [n_samples] or [n_samples, n_targets]</p>  <p>Representation of weight vector(s) in kernel space</p>  <p><strong>X_fit_</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>Training data, which is also required for prediction</p>  </td> </tr>  </table> <div class="admonition seealso"> <p class="first admonition-title">See also</p> <dl class="last docutils"> <dt>
<code>Ridge</code> </dt> <dd>Linear ridge regression.</dd> <dt>
<code>SVR</code> </dt> <dd>Support Vector Regression implemented using libsvm.</dd> </dl> </div> <h4 class="rubric">References</h4> <ul class="simple"> <li>Kevin P. Murphy “Machine Learning: A Probabilistic Perspective”, The MIT Press chapter 14.4.3, pp. 492-493</li> </ul> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.kernel_ridge import KernelRidge
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; n_samples, n_features = 10, 5
&gt;&gt;&gt; rng = np.random.RandomState(0)
&gt;&gt;&gt; y = rng.randn(n_samples)
&gt;&gt;&gt; X = rng.randn(n_samples, n_features)
&gt;&gt;&gt; clf = KernelRidge(alpha=1.0)
&gt;&gt;&gt; clf.fit(X, y) 
KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='linear',
            kernel_params=None)
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.kernel_ridge.KernelRidge.fit" title="sklearn.kernel_ridge.KernelRidge.fit"><code>fit</code></a>(X[, y, sample_weight])</td> <td>Fit Kernel Ridge regression model</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.kernel_ridge.KernelRidge.get_params" title="sklearn.kernel_ridge.KernelRidge.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.kernel_ridge.KernelRidge.predict" title="sklearn.kernel_ridge.KernelRidge.predict"><code>predict</code></a>(X)</td> <td>Predict using the kernel ridge model</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.kernel_ridge.KernelRidge.score" title="sklearn.kernel_ridge.KernelRidge.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the coefficient of determination R^2 of the prediction.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.kernel_ridge.KernelRidge.set_params" title="sklearn.kernel_ridge.KernelRidge.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.__init__">
<code>__init__(alpha=1, kernel='linear', gamma=None, degree=3, coef0=1, kernel_params=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/kernel_ridge.py#L104" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.fit">
<code>fit(X, y=None, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/kernel_ridge.py#L127" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit Kernel Ridge regression model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>Training data</p>  <p><strong>y</strong> : array-like, shape = [n_samples] or [n_samples, n_targets]</p>  <p>Target values</p>  <p><strong>sample_weight</strong> : float or numpy array of shape [n_samples]</p>  <p>Individual weights for each sample, ignored if None is passed.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first last"><strong>self</strong> : returns an instance of self.</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/kernel_ridge.py#L168" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the kernel ridge model</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>  <p>Samples.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>C</strong> : array, shape = [n_samples] or [n_samples, n_targets]</p>  <p>Returns predicted values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L357" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the coefficient of determination R^2 of the prediction.</p> <p>The coefficient R^2 is defined as (1 - u/v), where u is the regression sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual sum of squares ((y_true - y_true.mean()) ** 2).sum(). Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True values for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>R^2 of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.kernel_ridge.KernelRidge.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-kernel-ridge-kernelridge">Examples using <code>sklearn.kernel_ridge.KernelRidge</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="Both kernel ridge regression (KRR) and SVR learn a non-linear function by employing the kernel ...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_kernel_ridge_regression_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_kernel_ridge_regression_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/plot_kernel_ridge_regression/#sphx-glr-auto-examples-plot-kernel-ridge-regression-py"><span class="std std-ref">Comparison of kernel ridge regression and SVR</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="Both kernel ridge regression (KRR) and Gaussian process regression (GPR) learn a target functio...">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_compare_gpr_krr_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_compare_gpr_krr_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/gaussian_process/plot_compare_gpr_krr/#sphx-glr-auto-examples-gaussian-process-plot-compare-gpr-krr-py"><span class="std std-ref">Comparison of kernel ridge and Gaussian process regression</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
