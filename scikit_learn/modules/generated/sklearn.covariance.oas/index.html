
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>covariance.OAS() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" Oracle Approximating Shrinkage Estimator ">
  <meta name="keywords" content="sklearn, covariance, oas, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.covariance.oas/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-covariance-oas">sklearn.covariance.OAS</h1> <dl class="class"> <dt id="sklearn.covariance.OAS">
<code>class sklearn.covariance.OAS(store_precision=True, assume_centered=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/shrunk_covariance_.py#L477" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Oracle Approximating Shrinkage Estimator</p> <p>Read more in the <a class="reference internal" href="../../covariance/#shrunk-covariance"><span class="std std-ref">User Guide</span></a>.</p> <p>OAS is a particular form of shrinkage described in “Shrinkage Algorithms for MMSE Covariance Estimation” Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</p> <p>The formula used here does not correspond to the one given in the article. It has been taken from the Matlab program available from the authors’ webpage (<a class="reference external" href="http://tbayes.eecs.umich.edu/yilun/covestimation" target="_blank">http://tbayes.eecs.umich.edu/yilun/covestimation</a>). In the original article, formula (23) states that 2/p is multiplied by Trace(cov*cov) in both the numerator and denominator, this operation is omitted in the author’s MATLAB program because for a large p, the value of 2/p is so small that it doesn’t affect the value of the estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>store_precision</strong> : bool, default=True</p>  <p>Specify if the estimated precision is stored.</p>  <p><strong>assume_centered: bool, default=False</strong> :</p>  <p>If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>covariance_</strong> : array-like, shape (n_features, n_features)</p>  <p>Estimated covariance matrix.</p>  <p><strong>precision_</strong> : array-like, shape (n_features, n_features)</p>  <p>Estimated pseudo inverse matrix. (stored only if store_precision is True)</p>  <p><strong>shrinkage_</strong> : float, 0 &lt;= shrinkage &lt;= 1</p>  <p>coefficient in the convex combination used for the computation of the shrunk estimate.</p>  </td> </tr>  </table> <h4 class="rubric">Notes</h4> <p>The regularised covariance is:</p> <pre data-language="python">(1 - shrinkage)*cov
        + shrinkage*mu*np.identity(n_features)
</pre> <p>where mu = trace(cov) / n_features and shrinkage is given by the OAS formula (see References)</p> <h4 class="rubric">References</h4> <p>“Shrinkage Algorithms for MMSE Covariance Estimation” Chen et al., IEEE Trans. on Sign. Proc., Volume 58, Issue 10, October 2010.</p> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.error_norm" title="sklearn.covariance.OAS.error_norm"><code>error_norm</code></a>(comp_cov[, norm, scaling, squared])</td> <td>Computes the Mean Squared Error between two covariance estimators.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.fit" title="sklearn.covariance.OAS.fit"><code>fit</code></a>(X[, y])</td> <td>Fits the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.get_params" title="sklearn.covariance.OAS.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.get_precision" title="sklearn.covariance.OAS.get_precision"><code>get_precision</code></a>()</td> <td>Getter for the precision matrix.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.mahalanobis" title="sklearn.covariance.OAS.mahalanobis"><code>mahalanobis</code></a>(observations)</td> <td>Computes the squared Mahalanobis distances of given observations.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.score" title="sklearn.covariance.OAS.score"><code>score</code></a>(X_test[, y])</td> <td>Computes the log-likelihood of a Gaussian data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.covariance.OAS.set_params" title="sklearn.covariance.OAS.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.covariance.OAS.__init__">
<code>__init__(store_precision=True, assume_centered=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L114" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.error_norm">
<code>error_norm(comp_cov, norm='frobenius', scaling=True, squared=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L213" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the Mean Squared Error between two covariance estimators. (In the sense of the Frobenius norm).</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>comp_cov</strong> : array-like, shape = [n_features, n_features]</p>  <p>The covariance to compare with.</p>  <p><strong>norm</strong> : str</p>  <p>The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error <code>(comp_cov - self.covariance_)</code>.</p>  <p><strong>scaling</strong> : bool</p>  <p>If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.</p>  <p><strong>squared</strong> : bool</p>  <p>Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>The Mean Squared Error (in the sense of the Frobenius norm) between</strong> :</p> <p class="last"><strong>`self` and `comp_cov` covariance estimators.</strong> :</p> </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.fit">
<code>fit(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/shrunk_covariance_.py#L535" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fits the Oracle Approximating Shrinkage covariance model according to the given training data and parameters.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>  <p>Training data, where n_samples is the number of samples and n_features is the number of features.</p>  <p><strong>y</strong> : not used, present for API consistence purpose.</p> </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>self: object</strong> :</p>  <p>Returns self.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.get_precision">
<code>get_precision()</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L140" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Getter for the precision matrix.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>precision_</strong> : array-like,</p>  <p>The precision matrix associated to the current covariance object.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.mahalanobis">
<code>mahalanobis(observations)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L265" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the squared Mahalanobis distances of given observations.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>observations</strong> : array-like, shape = [n_observations, n_features]</p>  <p>The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>mahalanobis_distance</strong> : array, shape = [n_observations,]</p>  <p>Squared Mahalanobis distances of the observations.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.score">
<code>score(X_test, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/covariance/empirical_covariance_.py#L184" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes the log-likelihood of a Gaussian data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X_test</strong> : array-like, shape = [n_samples, n_features]</p>  <p>Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).</p>  <p><strong>y</strong> : not used, present for API consistence purpose.</p> </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>res</strong> : float</p>  <p>The likelihood of the data set with <code>self.covariance_</code> as an estimator of its covariance matrix.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.covariance.OAS.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-covariance-oas">Examples using <code>sklearn.covariance.OAS</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="When working with covariance estimation, the usual approach is to use a maximum likelihood esti...">
<div class="figure" id="id1"> <img alt="../../_images/sphx_glr_plot_covariance_estimation_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_covariance_estimation_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/covariance/plot_covariance_estimation/#sphx-glr-auto-examples-covariance-plot-covariance-estimation-py"><span class="std std-ref">Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood</span></a></span></p> </div> </div>
<div class="sphx-glr-thumbcontainer" tooltip="The usual covariance maximum likelihood estimate can be regularized using shrinkage. Ledoit and...">
<div class="figure" id="id2"> <img alt="../../_images/sphx_glr_plot_lw_vs_oas_thumb.png" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_lw_vs_oas_thumb.png"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../../auto_examples/covariance/plot_lw_vs_oas/#sphx-glr-auto-examples-covariance-plot-lw-vs-oas-py"><span class="std std-ref">Ledoit-Wolf vs OAS estimation</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.covariance.OAS.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.covariance.OAS.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
