
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Example&#58; Restricted Boltzmann Machine Features for Digit Classification - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content="For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, &hellip;">
  <meta name="keywords" content="restricted, boltzmann, machine, features, for, digit, classification, example, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/auto_examples/neural_networks/plot_rbm_logistic_classification/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py">Restricted Boltzmann Machine features for digit classification</h1> <p id="restricted-boltzmann-machine-features-for-digit-classification">For greyscale image data where pixel values can be interpreted as degrees of blackness on a white background, like handwritten digit recognition, the Bernoulli Restricted Boltzmann machine model (<a class="reference internal" href="../../../modules/generated/sklearn.neural_network.bernoullirbm/#sklearn.neural_network.BernoulliRBM" title="sklearn.neural_network.BernoulliRBM"><code>BernoulliRBM</code></a>) can perform effective non-linear feature extraction.</p> <p>In order to learn good latent representations from a small dataset, we artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.</p> <p>This example shows how to build a classification pipeline with a BernoulliRBM feature extractor and a <a class="reference internal" href="../../../modules/generated/sklearn.linear_model.logisticregression/#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code>LogisticRegression</code></a> classifier. The hyperparameters of the entire model (learning rate, hidden layer size, regularization) were optimized by grid search, but the search is not reproduced here because of runtime constraints.</p> <p>Logistic regression on raw pixel values is presented for comparison. The example shows that the features extracted by the BernoulliRBM help improve the classification accuracy.</p> <pre data-language="python">from __future__ import print_function

print(__doc__)

# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve
# License: BSD

import numpy as np
import matplotlib.pyplot as plt

from scipy.ndimage import convolve
from sklearn import linear_model, datasets, metrics
from sklearn.model_selection import train_test_split
from sklearn.neural_network import BernoulliRBM
from sklearn.pipeline import Pipeline
</pre> <p>Setting up</p> <pre data-language="python">def nudge_dataset(X, Y):
    """
    This produces a dataset 5 times bigger than the original one,
    by moving the 8x8 images in X around by 1px to left, right, down, up
    """
    direction_vectors = [
        [[0, 1, 0],
         [0, 0, 0],
         [0, 0, 0]],

        [[0, 0, 0],
         [1, 0, 0],
         [0, 0, 0]],

        [[0, 0, 0],
         [0, 0, 1],
         [0, 0, 0]],

        [[0, 0, 0],
         [0, 0, 0],
         [0, 1, 0]]]

    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',
                                  weights=w).ravel()
    X = np.concatenate([X] +
                       [np.apply_along_axis(shift, 1, X, vector)
                        for vector in direction_vectors])
    Y = np.concatenate([Y for _ in range(5)], axis=0)
    return X, Y

# Load Data
digits = datasets.load_digits()
X = np.asarray(digits.data, 'float32')
X, Y = nudge_dataset(X, digits.target)
X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling

X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                    test_size=0.2,
                                                    random_state=0)

# Models we will use
logistic = linear_model.LogisticRegression()
rbm = BernoulliRBM(random_state=0, verbose=True)

classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])
</pre> <p>Training</p> <pre data-language="python"># Hyper-parameters. These were set by cross-validation,
# using a GridSearchCV. Here we are not performing cross-validation to
# save time.
rbm.learning_rate = 0.06
rbm.n_iter = 20
# More components tend to give better prediction performance, but larger
# fitting time
rbm.n_components = 100
logistic.C = 6000.0

# Training RBM-Logistic Pipeline
classifier.fit(X_train, Y_train)

# Training Logistic regression
logistic_classifier = linear_model.LogisticRegression(C=100.0)
logistic_classifier.fit(X_train, Y_train)
</pre> <p class="sphx-glr-script-out">Out:</p> <pre data-language="python">  [BernoulliRBM] Iteration 1, pseudo-likelihood = -25.39, time = 0.40s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.77, time = 0.53s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.94, time = 0.52s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.91, time = 0.54s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.69, time = 0.52s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.50s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.89, time = 0.50s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.64, time = 0.53s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.36, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.09, time = 0.50s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.08, time = 0.51s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -19.82, time = 0.51s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -19.64, time = 0.50s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.61, time = 0.50s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.57, time = 0.53s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.41, time = 0.51s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.30, time = 0.50s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.25, time = 0.52s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.27, time = 0.51s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.01, time = 0.50s
</pre> <p>Evaluation</p> <pre data-language="python">print()
print("Logistic regression using RBM features:\n%s\n" % (
    metrics.classification_report(
        Y_test,
        classifier.predict(X_test))))

print("Logistic regression using raw pixel features:\n%s\n" % (
    metrics.classification_report(
        Y_test,
        logistic_classifier.predict(X_test))))
</pre> <p class="sphx-glr-script-out">Out:</p> <pre data-language="python">  Logistic regression using RBM features:
             precision    recall  f1-score   support

          0       0.99      0.99      0.99       174
          1       0.92      0.95      0.93       184
          2       0.95      0.98      0.97       166
          3       0.97      0.91      0.94       194
          4       0.97      0.95      0.96       186
          5       0.93      0.93      0.93       181
          6       0.98      0.97      0.97       207
          7       0.95      1.00      0.97       154
          8       0.90      0.88      0.89       182
          9       0.91      0.93      0.92       169

avg / total       0.95      0.95      0.95      1797


Logistic regression using raw pixel features:
             precision    recall  f1-score   support

          0       0.85      0.94      0.89       174
          1       0.57      0.55      0.56       184
          2       0.72      0.85      0.78       166
          3       0.76      0.74      0.75       194
          4       0.85      0.82      0.84       186
          5       0.74      0.75      0.75       181
          6       0.93      0.88      0.91       207
          7       0.86      0.90      0.88       154
          8       0.68      0.55      0.61       182
          9       0.71      0.74      0.72       169

avg / total       0.77      0.77      0.77      1797
</pre> <p>Plotting</p> <pre data-language="python">plt.figure(figsize=(4.2, 4))
for i, comp in enumerate(rbm.components_):
    plt.subplot(10, 10, i + 1)
    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r,
               interpolation='nearest')
    plt.xticks(())
    plt.yticks(())
plt.suptitle('100 components extracted by RBM', fontsize=16)
plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)

plt.show()
</pre> <img alt="../../_images/sphx_glr_plot_rbm_logistic_classification_001.png" class="align-center" src="http://scikit-learn.org/stable/_images/sphx_glr_plot_rbm_logistic_classification_001.png"> <p><strong>Total running time of the script:</strong> (0 minutes 34.021 seconds)</p> <div class="sphx-glr-download container"> <strong>Download Python source code:</strong> <a class="reference download internal" href="http://scikit-learn.org/stable/_downloads/plot_rbm_logistic_classification.py" download="" target="_blank"><code>plot_rbm_logistic_classification.py</code></a>
</div> <div class="sphx-glr-download container"> <strong>Download IPython notebook:</strong> <a class="reference download internal" href="http://scikit-learn.org/stable/_downloads/plot_rbm_logistic_classification.ipynb" download="" target="_blank"><code>plot_rbm_logistic_classification.ipynb</code></a>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
